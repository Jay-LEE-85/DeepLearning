# Perceptron

DL은 **인공신경망(ANN, Articial Neural Network)**이 여러개(Deep)의 층(Layers)로 존재하는 구조를 말하는 것입니다.

여기서 주목할 것은 신경망 입니다. 인공 신경망은 생물학적 신경망을 모방하여 설계된 만큼 이에 대한 작동기전을 이해하는 것이 중요하다고 생각합니다.

본 장에서는 생물학적 신경망의 가장 기초가되는 **뉴런(Neuron)**에 대한 이해를 기반으로 인공 신경망의 가장 기초가되는 **퍼셉트론(Perceptron)**에 대하여 이해해 보고자 합니다.

## What is a 'Perceptron'?

퍼셉트론은 인공신경망의 가장 기초가 되는 구조이고 이를 이해하기 위하여 생물한적 신경망의 가장 기초가 되는 뉴런에 대하여 살펴보고자(@fig-neuron) 합니다.

뉴런의 구조는 다양하게 하지만 우리가 집중하고자 하는 곳은 크게 3가지 부분으로 구성되어 있습니다. 

-   외부 자극등 정보를 수신하는 **수상돌기(Dendrite)**
-   수신된 정보를 신호를 만들어 내는 **핵(Nucleus)**
-   신호를 신경절달 물질로 만들어 내는 **축삭돌기(Axon)+시넵스(Synapse)**

여기서 주목할 것은 뉴런은 정보를 입력받아 내부적인 신호를 생성하여 다음 뉴런에 정보를 전달한 다는 것입니다. 

![Structure of Neuron (source: Wikipedia)](image/neuron.png){#fig-neuron}

이러한 뉴런의 작동기전을 모방하여 만들어진 것이 퍼셉트론(@fig-perceptron1)입니다. 

퍼셉트론은 1957년 프랑크 로젠블라트가 제안한 것으로 퍼셉트론은 이러한 뉴런의 작동기전을 모방하여 정보를 입력(Input)받아 연산을 통해 출력(Output)을 생성하도록 설계되었습니다. 

이러한 정보의 흐름 또는 연산 절차를 다른 말로 **Forward Propagation**이라 합니다, 향후 논의 될 **Back Propagation**과 대비되는(?) 개념입니다.

```{mermaid}
%%| label: fig-perceptron1
%%| fig-cap: "Basic of Perceptron"

flowchart LR
  subgraph node
    direction LR
    node2_1((SUM)) --> node2_2((STEP))
  end
  node1_1((x_1)) --w1--> node2_1
  node1_2((x_2)) --w2--> node2_1
  node2_2 --> node3((y_hat))
```

@fig-perceptron1 에서 원은 **노드(Node)**라고 하면 노드간 연결된 선을 **엣지(Edge)**라고 합니다. 엣지상에 존재하는 `w`는 **가중치(Weight)**하고 합니다.

첫번째 노드의 `x_1`과 `x_2`는 입력값을 말하고, 두번째 노드는 내부적으로 `SUM`과 `STEP`으로 구성된 활성함수를 말하며, 마지막 노드의 `z`는 출력값으로 노드의 활성 정도를 말합니다.

노란색 노드에서는 2단계 계산이 발생합니다. 하나늗 입력값의 뉴런에서는 신호의 세기를 계산하는 **Weighted Sum**(@eq-weightedSum) 과 뉴런의 여부를 계산하는 **Step Function**(@eq-stepFunction) 으로 구성되어 있습니다.

결과적으로 퍼셉트론의 출력값($\hat{y}=h_{w,b}(x)=sign(\textbf{w}^{T}\textbf{x}+b)$)은 (-1, 0, 1)로 3가지를 갖게 됩니다. 이 결과값을 실제의 값($y$)와 비교(Loss Function)하여 가중치($w$)를 업데이트 하여 최적해(?)를 찾는 것이 퍼셉트론입니다.

$$
z = b + w_{1}x_{1} + w_{2}x_{2} + \cdots + w_{n}x_{n} = b + \textbf{w}^{T} \textbf{x}
$$ {#eq-weightedSum}

$$
step(z) = sign(z) = \begin{cases}
-1 & z < 0 \\
0 & z = 0 \\
1 & z > 0
\end{cases}
$$ {#eq-stepFunction}


::: {.callout-note}
## 퍼셉트론에서 사용되는 계단함수
일반적으로 **Sign function**을 가장 많이 사용하지만, 이진값(0, 1)만을 갖는 **Heavisde step function**이 사용되기도 합니다. Clsiffication 문제에서 직선상의 Observation값은 0 , Weight와 같은 방향은 1, 다른 방향은 -1로 처리하는 것이 보다 용이하기에 우리는 **Sign function**을 주로 사용합니다.

$$
heavisde(z) = \begin{cases}
0 & z < 0 \\
1 & z >= 0
\end{cases}
$$
:::

## Classification

앞서 보았던 퍼셉트론을 **분류(Classification)**을 수행해보며 보다 자세하게 살펴보겠습니다. 특히 분류의 문제는 향후 ANN 및 CNN 등 다양한 문제를 해결하는데 사용되는 기법으로 향후 학습을 진행하면서 병렬적으로 작동기전에 대하여 비교하기가 용이할 것으로 생각됩니다.

### Bit-wise operation

분류문제 중 가장 간단한 예시로 Bit-wise operation(단순 논리 회로)에 대한 내용을 살펴보겠습니다. 논리회로는 `0`과 `1`로 구분된 2개의 `input`을 받아 `0`또는 `1`을 출력하는 문제로 퍼셉트론을 이해하기에 가장 쉬운 문제입니다.

단순 논리 회로는 `AND`, `NAND`, `OR` 그리고 `XOR`게이트로 구성되어 있으며 입력에 따른 출력이 다음의 **진리표(@tbl-bitwise )**로 나타낼 수 있습니다.

::: {#tbl-bitwise layout-ncol=4}
| $x_1$ | $x_2$ | $y$ |
| :---: | :---: | :---: |
| 0 | 0 | 0 |
| 1 | 0 | 0 |
| 0 | 1 | 0 |
| 1 | 1 | 1 |

: AND gate {#tbl-AND}

| $x_1$ | $x_2$ | $y$ |
| :---: | :---: | :---: |
| 0 | 0 | 1 |
| 1 | 0 | 0 |
| 0 | 1 | 0 |
| 1 | 1 | 0 |

: NAND gate {#tbl-NAND}

| $x_1$ | $x_2$ | $y$ |
| :---: | :---: | :---: |
| 0 | 0 | 0 |
| 1 | 0 | 1 |
| 0 | 1 | 1 |
| 1 | 1 | 1 |

: OR gate {#tbl-OR}

| $x_1$ | $x_2$ | $y$ |
| :---: | :---: | :---: |
| 0 | 0 | 0 |
| 1 | 0 | 1 |
| 0 | 1 | 1 |
| 1 | 1 | 0 |

: XOR gate {#tbl-XOR}

게이트별 진리표
:::


