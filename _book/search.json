[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DeepLearning x 101",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "DeepLearning x 101",
    "section": "Welcome",
    "text": "Welcome\n최근 전세계적으로 AI에 대한 관심이 증가하고 있습니다. 특히 OPEN AI의 Chat-GPT를 시작으로 다양한 생성형 AI가 발표되고 있습니다다.\n이러한 AI 발전의 기초가되는 기술은 Machinelearning과 Deeplearning이 있습니다. 이중 가장 기초가 되는 Deeplearning을 활용하여 Data에서 사람이 찾을 수 없는 Features와 Patterns을 기계를 활용하여 찾기 위한 기술을 학습하고자 합니다.\n이 사이트는 앞서 말한바와 같이 날로 중요해지는 Deeplearning에 대한 기초적인 이해부터 구현까지 학습하는 과정에 대한 기록물입니다. 나아가 Deeplearning기술을 활용하여 금융분야에 활용할 수 있는 방법을 연구하거나, 현재 다양한 금융공학의 기술과 접목시키고자 합니다.\n또한, Deeplearning과 관련된 사항들 수식과 이론에 기반하여 기초적인 사항들을 가급적 빠짐없이 다룰 예정입니다. 또한, Deeplearning과 관련된 내용을 ’engineering’관점에서 실제 기능을 구현하기 위한 코드를 포함할 예정이며, 이러한 소스 코드를 통해 이해의 폭을 높이고자 합니다. 물론 모든 코드와 그에 따른 결과는 매 페이지에서 확인할 수 있습니다.\n\n\n\n\n\n\nNote\n\n\n\n본 사이트는 Quarto를 기반으로 작성되었으며 실습환경에 관하여는 Table 1 을 참고하기 바랍니다. 본 사이트 구축에 관한 소스 코드는 GitHub에서 확인할 수 있습니다.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#disclaimer",
    "href": "index.html#disclaimer",
    "title": "DeepLearning x 101",
    "section": "Disclaimer",
    "text": "Disclaimer\n이 사이트는 모두에게 무료이며, “Deep Learning from Scratch”를 기반으로 학습자들이 연구한 내용을 담고 있습니다. 모든 내용에 대하여 출처를 밝힐 예정이나, 간혹 출처가 빠져 있는 경우 지속적으로 업데이트 하여, 원작자들의 권리를 침해하지 않고 오류를 수정해 나갈 것입니다.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Learning Path\n필자들의 DL 학습배경에 따라 아래의 경로로 DL을 학습할 계획이며 많은 문헌에서 다루고 있는 학습경로 입니다.\n학습경로가 정확한지? 적절한지? 알 수 없지만, 적어도 A to Z의 관점에서 빠짐없이 모든 내용을 학습해보기로 하였습니다.\n학습경로에 관한 내용은 Figure 1 을 참고하기 바라며, 학습을 수행하는 과정마다 변경되거나 추가되는 사항은 지속적으로 반영해 나갈 예정입니다.\nflowchart LR\n  opt[Optimazation]:::ch --&gt; opt1[Solving Problems]\n  opt --&gt; opt2[Gradient Descent] \n\n  opt1 --&gt; opt_l{{Lab1: Linear Regression}}\n  opt2 --&gt; opt_l:::lab\n\n  per[Perceptron]:::ch --&gt; per1[Classification]\n  per --&gt; per2[Logistic Regression]\n\n  per1 --&gt; per_l1{{Lab2: Classification}}:::lab\n  per2 --&gt; per_l2{{Lab2: Logistic Regression}}:::lab\n\n  %% ann[ANN]:::ch --&gt; ann1[Multi Layer Perceptron] --&gt; ann_l{{Lab3:}}:::lab\n  %% ann --&gt; ann2[Artificial NN?]\n\n  %% ann2 --&gt; ann2_1[Recursive Algorithm]\n  %% ann2 --&gt; ann2_2[Dynamic Programing]\n  %% ann2 --&gt; ann2_3[Neural Networks]\n  \n  %% ann2_3 --&gt; ann2_3_3[Loss Function]\n  %% ann2_3 --&gt; ann2_3_1[Optimization]\n  %% ann2_3 --&gt; ann2_3_2[Activation Function]\n\n  %% ann2_1 & ann2_2 & ann2_3_1 & ann2_3_2 & ann2_3_3 --&gt; ann_l{{Lab3: MNIST Classification}}:::lab\n  \n  %% cnn[Convolution-NN]:::ch --&gt; cnn1[NA]\n\n  %% rnn[Recurrent-NN]:::ch --&gt; rnn[NA]\n\n  classDef ch fill:#ccccff\n  classDef lab fill:#ccffcc\n\n\n\n\nFigure 1: Learning Path",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#environment",
    "href": "intro.html#environment",
    "title": "Introduction",
    "section": "Environment",
    "text": "Environment\n우리가 학습하며 사용한 실습환경에 대하여 간단하게 소개하겠습니다.\n누구나 접근이 가능한 Python을 기반으로 하고 있고, 실습에 사용하는 라이브러리(Table 1 )는 의존도를 최소화 하기 위하여 numpy를 주로 사용하였습니다. 그리고 실습결과를 도식화하기 위하여는 matplotlib을 사용하였습니다.\n이론에 대한 충분한 실습을 완료한 뒤에는 tensorflow 또는 torch를 사용하기로 하였습니다. 이는 NVIDIA의 GPU를 활용하여 보다 Deep한 신경망을 구현하기 위함임을 참고하여 주시고 학습과정에서 본 Framework의 사용은 최소화 할 예정입니다.\n학습경로와 마찬가지로 아래의 테이블에 적시된 라이브러리와 그 버전은 수시로 업데이트 할 예정입니다.\n\n\n\n\n\n\nName\nVersion\n\n\n\n\nnumpy\n#.#.#\n\n\nmatplotlib\n#.#.#\n\n\ntensorflow\n#.#.#\n\n\ntorch\n#.#.#\n\n\n\n\n\nTable 1: List of Packages",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#how-to-read",
    "href": "intro.html#how-to-read",
    "title": "Introduction",
    "section": "How to read",
    "text": "How to read\n이 사이트에서 다루는 내용은 기본적인 이론에 대한 설명과 이와 관련된 코드와 그 실행 결과 들을 보여줄 것입니다.\nCode Example\n\n기본적으로 코드는 아래의 Code Block에서 모든 내용을 표시하였습니다.\n특별히 중요하거나 추가적인 설명이 필요한 경우 Code Annotation에 표시하였습니다.\n\n\n\n\nListing 1: Code Block\n\n\n\ndef add(num1, num2):\n1  result = num1 + num2\n  return  result\n\n\n1\n\nnum1과 num2를 더하여 result에 할당\n\n\n\n\n\n\n\nEquation Example\n\n수식 중 설명이 필요한 경우는 기본적으로 본문에 내용을 표시하였습니다.\n설명이 완료된 수식 중 참고할 사항은 margin컬럼에 표시였습니다.\n\n\n\n\nListing 2: Equation\n\n\n\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\n\n\n\n\n\nWe know from the first fundamental theorem of calculus that for x in [a, b]:\n\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\nCallout Example\n\n학습을 진행해 가는 과정에서 나오는 이슈사항은 Callout으로 표시해 두었습니다,\n각 Callout이 담아야 할 내용은 아래를 참고하여 주시기 바랍니다.\n\n\n\n\nListing 3: Callout\n\n\n\n\n\n\n\n\nNote의 활용법\n\n\n\n\n본문의 내용과 직접관련된 내용으로 부가적인 설명을 담고 있습니다.\n관련 문헌이나 자료들에서 중요한 부분을 발췌한 내용을 담고 있습니다.\n필자가 보다 효율적이라고 판단한 내용들을 보여주고자 합니다.\n\n\n\n\n\n\n\n\n\nTip의 활용법\n\n\n\n\n본문의 내용과 직접관련 없지만 알아두면 좋은 내용을 담고 있습니다.\n코드의 작성방법 등 유용한 정보를 답고 있습니다.\n실습과정에서 발견한 문제의 해결방법을 보여주고자 합니다.\n\n\n\n\n\n\n\n\n\nWarning의 활용법법\n\n\n\n\n이해하기 어려운 내용에 대하여 그 문제를 적시하고자 합니다.\n실습과정에서 경험한 문제 및 해결되지 않은 오류 등을 적시하고자 합니다.\n해결이 완료된 경우 note 또는 tip으로 전환될 수 있습니다.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "perceptron-intro.html",
    "href": "perceptron-intro.html",
    "title": "1  Perceptron",
    "section": "",
    "text": "1.1 What is a ‘Perceptron’?\n퍼셉트론은 인공신경망의 가장 기초가 되는 개념이고 이를 이해하기 위하여 생물학적 신경망의 가장 기초가 되는 뉴런(Figure 1.1)에 대하여 이해할 필요가 있습니다.\n뉴런의 구조는 다양하게 하지만 우리가 집중하고자 하는 곳은 크게 3가지 부분으로 구성되어 있습니다.\n여기서 주목할 것은 뉴런은 정보를 입력받아 내부적인 신호를 생성하여 다음 뉴런에 정보를 전달한 다는 것입니다.\n이러한 뉴런의 작동기전을 모방하여 만들어진 것이 퍼셉트론(Figure 1.2)입니다.\n퍼셉트론은 1957년 프랑크 로젠블라트가 제안한 것으로 퍼셉트론은 이러한 뉴런의 작동기전을 모방하여 정보를 입력(Input)받아 연산을 통해 출력(Output)을 생성하도록 설계되었습니다.\n이러한 정보의 흐름 또는 연산 절차를 다른 말로 Forward Propagation이라 합니다, 향후 논의 될 Back Propagation과 대비되는(?) 개념입니다.\nflowchart LR\n  subgraph node\n    direction LR\n    node2_1((SUM)) --&gt; node2_2((STEP))\n  end\n  node1_1((x_1)) --w1--&gt; node2_1\n  node1_2((x_2)) --w2--&gt; node2_1\n  node2_2 --&gt; node3((y_hat))\n\n\n\n\nFigure 1.2: Basic of Perceptron\nFigure 1.2 에서 원은 노드(Node)라고 하면 노드간 연결된 선을 엣지(Edge)라고 합니다. 엣지상에 존재하는 w는 가중치(Weight)하고 합니다.\n첫번째 노드의 x_1과 x_2는 입력값을 말하고, 두번째 노드는 내부적으로 SUM과 STEP으로 구성된 활성함수를 말하며, 마지막 노드의 z는 출력값으로 노드의 활성 정도를 말합니다.\n노란색 노드에서는 2단계 계산이 발생합니다. 하나늗 입력값의 뉴런에서는 신호의 세기를 계산하는 Weighted Sum(Equation 1.1) 과 뉴런의 여부를 계산하는 Step Function(Equation 1.2) 으로 구성되어 있습니다.\n결과적으로 퍼셉트론의 출력값(\\hat{y}=h_{w,b}(x)=sign(\\textbf{w}^{T}\\textbf{x}+b))은 (-1, 0, 1)로 3가지를 갖게 됩니다. 이 결과값을 실제의 값(y)와 비교(Loss Function)하여 가중치(w)를 업데이트 하여 최적해가 아닌 단순 solution(?)을 찾는 것이 퍼셉트론입니다.\nz = b + w_{1}x_{1} + w_{2}x_{2} + \\cdots + w_{n}x_{n} = b + \\textbf{w}^{T} \\textbf{x}\n\\tag{1.1}\nstep(z) = sign(z) = \\begin{cases}\n-1 & z &lt; 0 \\\\\n0 & z = 0 \\\\\n1 & z &gt; 0\n\\end{cases}\n\\tag{1.2}",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#what-is-a-perceptron",
    "href": "perceptron-intro.html#what-is-a-perceptron",
    "title": "1  Perceptron",
    "section": "",
    "text": "외부 자극등 정보를 수신하는 수상돌기(Dendrite)\n수신된 정보를 신호를 만들어 내는 핵(Nucleus)\n신호를 신경절달 물질로 만들어 내는 축삭돌기(Axon)+시넵스(Synapse)\n\n\n\n\n\n\n\n\nFigure 1.1: Structure of Neuron (source: Wikipedia)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n퍼셉트론에서 사용되는 계단함수\n\n\n\n일반적으로 Sign function을 가장 많이 사용하지만, 이진값(0, 1)만을 갖는 Heavisde step function이 사용되기도 합니다. Clsiffication 문제에서 직선상의 Observation값은 0 , Weight와 같은 방향은 1, 다른 방향은 -1로 처리하는 것이 보다 용이하기에 우리는 Sign function을 주로 사용합니다.\n\nheavisde(z) = \\begin{cases}\n0 & z &lt; 0 \\\\\n1 & z &gt;= 0\n\\end{cases}",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#bit-wise-operator단순-논리-회로",
    "href": "perceptron-intro.html#bit-wise-operator단순-논리-회로",
    "title": "1  Perceptron",
    "section": "1.2 Bit-wise operator(단순 논리 회로)",
    "text": "1.2 Bit-wise operator(단순 논리 회로)\n앞서 보았던 퍼셉트론을 분류(Classification)을 수행해보며 보다 자세하게 살펴보겠습니다. 특히 분류의 문제는 향후 ANN 및 CNN 등 다양한 문제를 해결하는데 사용되는 기법으로 향후 학습을 진행하면서 병렬적으로 작동기전에 대하여 비교하기가 용이할 것으로 생각됩니다.\n분류문제 중 가장 간단한 예시로 Bit-wise operator(단순 논리 회로)에 대한 내용을 살펴보겠습니다. 논리회로는 0과 1로 구분된 2개의 input을 받아 0또는 1을 output으로 출력하는 회로입니다.\n단순 논리 회로는 AND, NAND, OR 그리고 XOR게이트로 구성되어 있으며 입력에 따른 출력이 다음의 진리표(Table 1.1 )로 나타낼 수 있습니다.\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n0\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n1\n1\n1\n\n\n\n\n\n(a) AND gate\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n1\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n1\n1\n0\n\n\n\n\n\n(b) NAND gate\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n0\n\n\n1\n0\n1\n\n\n0\n1\n1\n\n\n1\n1\n1\n\n\n\n\n\n(c) OR gate\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n0\n\n\n1\n0\n1\n\n\n0\n1\n1\n\n\n1\n1\n0\n\n\n\n\n\n(d) XOR gate\n\n\n\n\n\n\n\nTable 1.1: 게이트별 진리표",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#perceptron-으로-구현",
    "href": "perceptron-intro.html#perceptron-으로-구현",
    "title": "1  Perceptron",
    "section": "1.3 Perceptron 으로 구현",
    "text": "1.3 Perceptron 으로 구현\n위의 진리표(Table 1.1 )의 내용을 퍼셉트론으로 구현해보겠습니다. 이를 위해 AND게이트를 예를 들도록 하겠습니다.\nAND게이트는 x_1 과 x_2가 모두 1인 경우 y를 1로 출력하는 논리 회로 입니다. 이를 퍼셉트론으로 표현하면 w_1, w_2, \\theta로 표현할 수 있고 이러한 선형판별식(Equation 1.3) 식은 아래와 같습니다.\n\n\n\ny = \\begin{cases}\n0 & w_1*x_1 + w_2*x_2 \\leq \\theta \\\\\n1 & w_1*x_1 + w_2*x_2 &gt; \\theta  \n\\end{cases}\n\\tag{1.3}\n위의 선형판별식은 아래와 같이 그림으로 표현이 가능합니다. 다만, 가중치 w 와 임계치 \\theta 의 조합은 무수히 많이 존재함을 유의해야 합니다.((?fig-egAndGate ) 의 적색선은 임의로 표현한 직선이고 이 직선이 무수히 많다는 의미)\n\n\n\n\n\n\n\n\nFigure 1.3: AND gate\n\n\n\n\n\n단순 논리 회로(XOR게이트 제외)의 선형판별식을 코드로 구현하면 다음과 같습니다. 여기서 일반적으로 향후 Deeplearning의 표현방법을 따라 임계치인 \\theta 를 편향(bias)인 -b로 치환한 수식을 사용하겠습니다.\n\n\n\ny = \\begin{cases}\n0 & b + w_1*x_1 + w_2*x_2 \\leq 0 \\\\\n1 & b + w_1*x_1 + w_2*x_2 &gt; 0\n\\end{cases}\n\\tag{1.4}\n변형된 수식(Equation 1.4 )에 기초하여 진리표(Table 1.1 )상의 게이트를 코드로 구현하면 아래와 같습니다.\n\n1import numpy as np\n\n# AND gate\ndef AND(x1, x2):\n  x = np.array([x1, x2])\n2  w = np.array([0.5, 0.5])\n  b = -0.7\n3  tmp = np.sum(w*x) + b\n  if tmp &lt;= 0:\n    return 0\n  elif tmp &gt; 0:\n    return 1\n\n# NAND gate\ndef NAND(x1, x2):\n  x = np.array([x1, x2])\n  w = np.array([-0.5, -0.5])\n  b = 0.7\n  tmp = np.sum(w*x) + b \n  if tmp &lt;= 0:\n    return 0\n  elif tmp &gt; 0:\n    return 1\n\n# OR gate\ndef OR(x1, x2):\n  x = np.array([x1, x2])\n  w = np.array([0.5, 0.5])\n  b = -0.7\n  tmp = np.sum(w*x) + b \n  if tmp &lt;= 0:\n    return 0\n  elif tmp &gt; 0:\n    return 1\n\n\n1\n\nVector 연산의 최적화를 위하여 numpy를 기본적으로 사용한다.\n\n2\n\nw와 b는 임의로 할당한다. 다만, NAND 및 OR 는 AND의 부호와 다름에 주의하자.\n\n3\n\nweighted sum은 가중치를 곱하여 더한 값으로 내적과 유사함을 유의하자.",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#다층-퍼셉트론",
    "href": "perceptron-intro.html#다층-퍼셉트론",
    "title": "1  Perceptron",
    "section": "1.4 다층 퍼셉트론",
    "text": "1.4 다층 퍼셉트론\n다중 퍼셉트론은 퍼셉트론이 여러층으로 구현된 형태를 말합니다. 층을 여러개 쌓아서 보다 복잡한 문제를 해결할 수 있고, 추후 Deeplearning에서 여러층의 신경망을 쌓는 방식의 기초라고만 이해해 두겠습니다.\n앞서 1층 퍼셉트론으로는 단순 논리 회로 중 선형적인 게이트만을 구현할 수 있었습니다. 그렇다면 XOR게이트는 해결할 수 없을까요? 이를 해결하기 위한 것이 다층 퍼셉트론 입니다.\n가령 XOR게이트 문제를 NAND와 OR게이트를 조합한 출력값을 AND게이트의 입력값으로 받게 된다면 XOR게이트를 구현할 수 있습니다. 국소적인 문제해결을 결합하여 전체 문제를 해결하는 방식으로 이해됩니다.\n\n\n\n\n\n\nflowchart LR\n  x1((x1)) & x2((x2)) ---&gt; nand[NAND] & or[OR] \n  nand --s1---&gt; AND ---&gt; y[y]\n  or --s2---&gt; AND\n\n\n\n\nFigure 1.4: XOR Gate: Composition of NAND, OR, AND\n\n\n\n\n\nXOR의 게이트를 다른 게이트의 조합을 활용한 진리표는 아래와 같습니다. 위의 그림에서 보듯이 x1과 x2의 입력값을 받아 NAND게이트는 s1의 출력값을 OR게이트는 s2의 출력값을 생성하며, 다시 s1과 s2를 입력값으로 받아 AND를 통과시켜 최종적으로 XOR게이트의 진리표를 다시 그릴 수 있습니다.\n\n\n\n\n\n\nx_1\nx_2\ns_1\ns_2\ny\n\n\n\n\n0\n0\n1\n0\n0\n\n\n1\n0\n1\n1\n1\n\n\n0\n1\n1\n1\n1\n\n\n1\n1\n0\n1\n0\n\n\n\n\n\nTable 1.2: XOR게이트의 진리표\n\n\n\n위의 진리표(Table 1.2 )를 코드로 구현하면 아래와 같습니다. 앞서 구현한 게이트들을 코드내에서 사용하여 단순하게 구현할 수 있습니다.\n\ndef XOR(x1, x2):\n  s1 = NAND(x1, x2)\n  s2 = OR(x1, x2)\n  y = AND(s1, s2)\n  return y",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-lab_classification.html",
    "href": "perceptron-lab_classification.html",
    "title": "2  Lab: Classification with Perceptron",
    "section": "",
    "text": "2.1 Classification\n우리가 실습할 분류 문제는 선형 판별 분석(Linear Discriminant Analysis)입니다. 수치형 입력변수를 받아 범주형 타겟 변수를 예측하는 분류 방법으로 퍼셈트론을 활용하여 해결하기 좋은 문제 입니다.\nFigure 2.1: Example of LDA\n위 산점도(Figure 2.1 )와 같은 산점도에서 C1과 C0을 구분하는 문제를 퍼셉트론을 이용하여 해결해 보겠습니다.\n전장에서 살펴본 퍼셉트론(Figure 1.2)에 따라 설명하고자 합니다. 우선 입력받는 변수는 x, 가중치는 \\omega로 둘수 있습니다.\n\\begin{align}\nx = \\begin{bmatrix}x_1\\\\ \\vdots\\\\ x_d \\end{bmatrix} \\qquad\n\\omega = \\begin{bmatrix}\\omega_1\\\\ \\vdots\\\\ \\omega_d \\end{bmatrix}\n\\end{align}\n\\tag{2.1}\n여기서 Weighted Sum의 결과가 특정 임계치(\\theta)를 초과하는 지에 따라 클래스1(C_1) 또는 클래스0(C_0)으로 구분하고자 합니다.\n\\begin{align}\nC_1 \\quad if\\, \\sum_{i=1}^{d}\\omega_{i}x_{i} &gt; \\theta \\\\\nC_0 \\quad if\\, \\sum_{i=1}^{d}\\omega_{i}x_{i} &lt; \\theta\n\\end{align}\n\\tag{2.2}\n이를 다시 Step function을 활용하여 Figure 1.2 의 노란색 박스(h(x))에 해당하는 노드를 다음의 식으로 변형하여 표현할 수 있습니다.\n여기서 임계치(\\theta)는 편향에 해당하는 값으로 변형하고 이를 다시 입력변수 \\omega_0으로 간단하게 표현할 수 있습니다.\n\\begin{align}\nh(x) &= \\text{sign} \\left(\\left( \\sum\\limits_{i=1}^{d}\\omega_ix_i \\right)- \\theta \\right) \\\\\n&= \\text{sign}\\left(\\left( \\sum\\limits_{i=1}^{d}\\omega_ix_i \\right)+ \\omega_0\\right)\n\\end{align}\n\\tag{2.3}\n\\omega_0=1로 두고 이를 벡터 형식(vector form)으로 표현하고, Step function을 Sign function으로 정의하면 아래와 같이 식을 수정할 수 있습니다.\n\\begin{align}\nh(x) &= \\text{sign}(\\sum_{i=0}^{d}\\omega_{i}x_{i})\n=\\text{sign}(\\omega^{T}x) \\\\\n\\text{sign}(x) &= \\begin{cases}\n1, &\\text{if }\\; x &gt; 0\\\\\n0, &\\text{if }\\; x = 0\\\\\n-1, &\\text{if }\\; x &lt; 0\n\\end{cases}\n\\end{align}\n\\tag{2.4}\nPerceptron Learning Algorithm(PLA)\n위의 식을 실제 퍼셉트론에 적용하기 위하여 위 산점도(Figure 2.1 )의 개별 값들을 활용하여 \\text{sign}(\\omega^Tx_n) = \\hat{y}_n을 산출하여 실제 라벨(y_n)과 비교하며 두 라벨값이 다를 경우 \\omega를 업데이트 하도록 합니다.\n\\begin{align}\n\\omega \\leftarrow\n\\begin{cases}\n\\omega+y_nx_n & \\hat{y_n} \\neq y_n \\\\\n\\omega &\\hat{y_n} = y_n \\\\\n\\end{cases}\n\\end{align}\n\\tag{2.5}\n위의 절차를 Training Set을 이용하여 Iterative하게 반복하여 \\omega를 업데이트 하도록 하여 PLA를 수행합니다.\nPerceptron Loss Function\nPLA를 수행하는 과정에서 학습을 종결시키기 위하여 Loss function이 필요합니다. 산출값 \\hat{y}_n과 y_n을 비교하여 Loss들의 합(\\mathscr{L}(\\omega))이 0이 되도록 하는 조건으로 설정할 수 있습니다.\n\\begin{align}\n\\mathscr{L}(\\omega) = \\sum_{n =1}^{m} \\max \\left\\{ 0, -y_n \\cdot \\left(\\omega^T x_n \\right)\\right\\}\n\\end{align}\n\\tag{2.6}",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lab: Classification with Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-lab_classification.html#solving-with-perceptron-algorithm",
    "href": "perceptron-lab_classification.html#solving-with-perceptron-algorithm",
    "title": "2  Lab: Classification with Perceptron",
    "section": "2.2 Solving with perceptron algorithm",
    "text": "2.2 Solving with perceptron algorithm\n위에서 살펴본 내용을 이제 코드로 작성해 보겠습니다. 기본적인 입력변수 x를 x1과 x2로 라벨값 y를 C1과 C0로 생성하였습니다. 그에 따른 산점도 데이터는 아래와 같습니다.\n\n#training data gerneration\nm = 100\nx1 = 8*np.random.rand(m, 1)\nx2 = 7*np.random.rand(m, 1) - 4\n\ng = 0.8*x1 + x2 -3\n\nC1 = np.where(g &gt;= 1)[0]\nC0 = np.where(g &lt; -1)[0]\n\n\n\n\n\n\n\n\n\n\n각각의 입력값을 numpy로 연산할 수 있도록 Vectorize를 진행합니다.\n\n\\begin{align}\nx &= \\begin{bmatrix} \\left(x^{(1)}\\right)^T \\\\ \\left(x^{(2)}\\right)^T \\\\ \\left(x^{(3)}\\right)^T\\\\ \\vdots \\\\ \\left(x^{(m)}\\right)^T \\end{bmatrix} = \\begin{bmatrix} 1 & x_1^{(1)} & x_2^{(1)} \\\\ 1 & x_1^{(2)} & x_2^{(2)} \\\\ 1 & x_1^{(3)} & x_2^{(3)}\\\\\\vdots & \\vdots & \\vdots \\\\ 1 & x_1^{(m)} & x_2^{(m)}\\end{bmatrix} \\\\\ny &= \\begin{bmatrix}y^{(1)} \\\\ y^{(2)} \\\\ y^{(3)}\\\\ \\vdots \\\\ y^{(m)} \\end{bmatrix}\n\\end{align}\n\n\nX1 = np.hstack([np.ones([C1.shape[0],1]), x1[C1], x2[C1]])\nX0 = np.hstack([np.ones([C0.shape[0],1]), x1[C0], x2[C0]])\n\nX = np.vstack([X1, X0])\ny = np.vstack([np.ones([C1.shape[0],1]), -np.ones([C0.shape[0],1])])\n\nX = np.asmatrix(X)\ny = np.asmatrix(y)\n\n가중치 \\omega를 1로 초깃값을 설정하고, 각각의 입력값을 이용하여 PLA를 실행하며 가중치 업데이트(\\omega \\leftarrow \\omega + yx)를 실행합니다.\n\nw = np.ones([3,1])\nw = np.asmatrix(w)\n\nn_iter = y.shape[0]\nflag = 0\n\nwhile flag == 0:\n    flag = 1\n    for i in range(n_iter):\n        if y[i,0] != np.sign(X[i,:]*w)[0,0]:\n            w += y[i,0]*X[i,:].T\n            flag = 0\n\n위의 절차를 실행하여 산출한 결정 경계(Dicision Boundary)는 아래와 같습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerceptron과 최적화의 문제\n\n\n\n\n여기서 중요한 것은 퍼셉트론은 구분하는 경계 산출에 촛점을 두고 있으므로 우리가 예상하는 최적 경계에 해당하지 않을 수 있습니다.\n가령 최적 경계는 두 그룹의 중간쯤 위치해야 할 것으로 생각이 됩니다. 그래야 향후 입력값이 추가 되었을 때 경계가 유효할 가능성이 높기 때문입니다.\n이를 해결하기 위하여는 내적을 통한 거리의 개념이 들어가고, Loss Function도 Logistic Regression의 방법으로 해결해야 하지 않을까라고 예상할 수 있습니다.",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lab: Classification with Perceptron</span>"
    ]
  },
  {
    "objectID": "ANN-intro.html",
    "href": "ANN-intro.html",
    "title": "3  Artificial Neural Networks",
    "section": "",
    "text": "인공신경망(ANN, Artificial Neural Networks)은 퍼셉트론과 유사한 메커니즘을 갖고 있습니다. Figure 4.1 에서 가장 왼쪽이 입력층(Input), 중간이 은닉층(Hidden), 가장 오른쪽이 출력층(Output)으로 구성되어 있습니다.\n\n\n\n\n\n\ngraph LR\n  subgraph Input\n      direction LR\n      x1((x1)) & x2((x2)) \n  end\n  \n  subgraph Hidden\n      direction LR\n      h1((h1)) & h2((h2)) & h3((h3))\n  end \n\n  subgraph Output\n      direction LR\n      y1((y1)) & y2((y2))\n  end\n\n    x1((x1)) & x2((x2))  ---&gt; h1((h1)) & h2((h2)) & h3((h3))\n    h1((h1)) & h2((h2)) & h3((h3)) ---&gt; y1((y1)) & y2((y2))\n\n\n\n\nFigure 3.1: Example of ANN\n\n\n\n\n\n다만, 퍼셉트론과 다른 점이 있따면, 신호를 전달 받는 과정에서 편향에 해당하는 b가 명시적으로 존재하여 이 또한 신호로 처리한다는 부분입니다.\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n  x1((x1)) --w1---&gt; y((y))\n  x2((x2)) --w2---&gt; y\n\n\n\n\n(a) Perceptron\n\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n  x0((1)):::bias --b---&gt; y((y))\n  x1((x1))  --w1---&gt; y((y))\n  x2((x2))  --w2---&gt; y\n  classDef bias fill:#f96\n\n\n\n\n(b) ANN\n\n\n\n\n\n\n\n\n\nFigure 3.2: 퍼셉트론과 ANN의 비교\n\n\n\nFigure 3.2 에는 잘 나타나 있지 않지만 Perceptron의 경우 입력신호를 받아 y를 바로 출력하지만, ANN의 경우 입력신호와 가중치를 곱하여 총합을 산출하는 함수와 이 산출값을 이용하여 조건 분기의 동작(0을 넘으면 1을 출력하고 그렇지 않으면 0을 출력)을 나타내는 함수로 구성되어 있으며 이를 구현한 산식은 Equation 3.1 과 같이 나타낼 수 있다.\n\n\\begin{align}\n&y = h(b + w_{1}x_{1} + w_{2}x_{2}) \\\\ \\\\\n&h(x) =\n  \\begin{cases}\n  0 & (x \\leq 0) \\\\\n  1 & (x &gt; 1)\n  \\end{cases}\n\\end{align}\n\\tag{3.1}\n\n\n\n\n\n\n펴셉트론과 Deeplearning의 차이\n\n\n\n\n퍼셉트론에 사용되는 선형판별식에 가중치 및 임계치의 조합은 무수히 많고, 가중치 및 임계치는 인간이 설정해야 함\nDeeplearning의 경우 가중치 및 임계치를 컴퓨터가 학습하여 설정해게 됨",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Artificial Neural Networks</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html",
    "href": "ANN-activation.html",
    "title": "4  Activation Function",
    "section": "",
    "text": "4.1 Sigmoid Function",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html#relu-function",
    "href": "ANN-activation.html#relu-function",
    "title": "4  Activation Function",
    "section": "4.2 ReLU Function",
    "text": "4.2 ReLU Function",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html#softmax-function",
    "href": "ANN-activation.html#softmax-function",
    "title": "4  Activation Function",
    "section": "4.3 Softmax Function",
    "text": "4.3 Softmax Function",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  }
]