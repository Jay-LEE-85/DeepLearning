[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DeepLearning x 101",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "DeepLearning x 101",
    "section": "Welcome",
    "text": "Welcome\n최근 전세계적으로 AI에 대한 관심이 증가하고 있습니다. 특히 OPEN AI의 Chat-GPT를 시작으로 다양한 생성형 AI가 발표되고 있습니다다.\n이러한 AI 발전의 기초가되는 기술은 Machinelearning과 Deeplearning이 있습니다. 이중 가장 기초가 되는 Deeplearning을 활용하여 Data에서 사람이 찾을 수 없는 Features와 Patterns을 기계를 활용하여 찾기 위한 기술을 학습하고자 합니다.\n이 사이트는 앞서 말한바와 같이 날로 중요해지는 Deeplearning에 대한 기초적인 이해부터 구현까지 학습하는 과정에 대한 기록물입니다. 나아가 Deeplearning기술을 활용하여 금융분야에 활용할 수 있는 방법을 연구하거나, 현재 다양한 금융공학의 기술과 접목시키고자 합니다.\n또한, Deeplearning과 관련된 사항들 수식과 이론에 기반하여 기초적인 사항들을 가급적 빠짐없이 다룰 예정입니다. 또한, Deeplearning과 관련된 내용을 ’engineering’관점에서 실제 기능을 구현하기 위한 코드를 포함할 예정이며, 이러한 소스 코드를 통해 이해의 폭을 높이고자 합니다. 물론 모든 코드와 그에 따른 결과는 매 페이지에서 확인할 수 있습니다.\n\n\n\n\n\n\nNote\n\n\n\n본 사이트는 Quarto를 기반으로 작성되었으며 실습환경에 관하여는 Table 1 을 참고하기 바랍니다. 본 사이트 구축에 관한 소스 코드는 GitHub에서 확인할 수 있습니다.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#disclaimer",
    "href": "index.html#disclaimer",
    "title": "DeepLearning x 101",
    "section": "Disclaimer",
    "text": "Disclaimer\n이 사이트는 모두에게 무료이며, “Deep Learning from Scratch”를 기반으로 학습자들이 연구한 내용을 담고 있습니다. 모든 내용에 대하여 출처를 밝힐 예정이나, 간혹 출처가 빠져 있는 경우 지속적으로 업데이트 하여, 원작자들의 권리를 침해하지 않고 오류를 수정해 나갈 것입니다.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Learning Path\n필자들의 DL 학습배경에 따라 아래의 경로로 DL을 학습할 계획이며 많은 문헌에서 다루고 있는 학습경로 입니다.\n학습경로가 정확한지? 적절한지? 알 수 없지만, 적어도 A to Z의 관점에서 빠짐없이 모든 내용을 학습해보기로 하였습니다.\n학습경로에 관한 내용은 Figure 1 을 참고하기 바라며, 학습을 수행하는 과정마다 변경되거나 추가되는 사항은 지속적으로 반영해 나갈 예정입니다.\nflowchart LR\n  per[Perceptron]:::ch --&gt; per1[Classification]\n  per --&gt; per2[Logistic Regression]\n\n  per1 --&gt; per_l1{{Lab1: Classification}}:::lab\n\n  ann(Artificial Neural Net):::ch --&gt; ann1[Intro of ANN] & ann2[Activation Function] & ann3[Forward Propagation] & ann4[Learning Process] & ann5[Back Propagation]\n\n  ann1 & ann2 & ann3 & ann4 --&gt; ann_l{{Lab2: Classification with MNIST}}:::lab\n\n  classDef ch fill:#ccccff\n  classDef lab fill:#ccffcc\n\n\n\n\nFigure 1: Learning Path",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#environment",
    "href": "intro.html#environment",
    "title": "Introduction",
    "section": "Environment",
    "text": "Environment\n우리가 학습하며 사용한 실습환경에 대하여 간단하게 소개하겠습니다.\n누구나 접근이 가능한 Python을 기반으로 하고 있고, 실습에 사용하는 라이브러리(Table 1 )는 의존도를 최소화 하기 위하여 numpy를 주로 사용하였습니다. 그리고 실습결과를 도식화하기 위하여는 matplotlib을 사용하였습니다.\n이론에 대한 충분한 실습을 완료한 뒤에는 tensorflow 또는 torch를 사용하기로 하였습니다. 이는 NVIDIA의 GPU를 활용하여 보다 Deep한 신경망을 구현하기 위함임을 참고하여 주시고 학습과정에서 본 Framework의 사용은 최소화 할 예정입니다.\n학습경로와 마찬가지로 아래의 테이블에 적시된 라이브러리와 그 버전은 수시로 업데이트 할 예정입니다.\n\n\n\n\n\n\nName\nVersion\n\n\n\n\nnumpy\n#.#.#\n\n\nmatplotlib\n#.#.#\n\n\ntensorflow\n#.#.#\n\n\ntorch\n#.#.#\n\n\n\n\n\nTable 1: List of Packages",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#how-to-read",
    "href": "intro.html#how-to-read",
    "title": "Introduction",
    "section": "How to read",
    "text": "How to read\n이 사이트에서 다루는 내용은 기본적인 이론에 대한 설명과 이와 관련된 코드와 그 실행 결과 들을 보여줄 것입니다.\nCode Example\n\n기본적으로 코드는 아래의 Code Block에서 모든 내용을 표시하였습니다.\n특별히 중요하거나 추가적인 설명이 필요한 경우 Code Annotation에 표시하였습니다.\n\n\n\n\nListing 1: Code Block\n\n\n\ndef add(num1, num2):\n1  result = num1 + num2\n  return  result\n\n\n1\n\nnum1과 num2를 더하여 result에 할당\n\n\n\n\n\n\n\nEquation Example\n\n수식 중 설명이 필요한 경우는 기본적으로 본문에 내용을 표시하였습니다.\n설명이 완료된 수식 중 참고할 사항은 margin컬럼에 표시였습니다.\n\n\n\n\nListing 2: Equation\n\n\n\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\n\n\n\n\n\nWe know from the first fundamental theorem of calculus that for x in [a, b]:\n\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\nCallout Example\n\n학습을 진행해 가는 과정에서 나오는 이슈사항은 Callout으로 표시해 두었습니다,\n각 Callout이 담아야 할 내용은 아래를 참고하여 주시기 바랍니다.\n\n\n\n\nListing 3: Callout\n\n\n\n\n\n\n\n\nNote의 활용법\n\n\n\n\n본문의 내용과 직접관련된 내용으로 부가적인 설명을 담고 있습니다.\n관련 문헌이나 자료들에서 중요한 부분을 발췌한 내용을 담고 있습니다.\n필자가 보다 효율적이라고 판단한 내용들을 보여주고자 합니다.\n\n\n\n\n\n\n\n\n\nTip의 활용법\n\n\n\n\n본문의 내용과 직접관련 없지만 알아두면 좋은 내용을 담고 있습니다.\n코드의 작성방법 등 유용한 정보를 답고 있습니다.\n실습과정에서 발견한 문제의 해결방법을 보여주고자 합니다.\n\n\n\n\n\n\n\n\n\nWarning의 활용법법\n\n\n\n\n이해하기 어려운 내용에 대하여 그 문제를 적시하고자 합니다.\n실습과정에서 경험한 문제 및 해결되지 않은 오류 등을 적시하고자 합니다.\n해결이 완료된 경우 note 또는 tip으로 전환될 수 있습니다.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "perceptron-intro.html",
    "href": "perceptron-intro.html",
    "title": "1  Perceptron",
    "section": "",
    "text": "1.1 What is a ‘Perceptron’?\n퍼셉트론은 인공신경망의 가장 기초가 되는 개념이고 이를 이해하기 위하여 생물학적 신경망의 가장 기초가 되는 뉴런(Figure 1.1)에 대하여 이해할 필요가 있습니다.\n뉴런의 구조는 다양하게 하지만 우리가 집중하고자 하는 곳은 크게 3가지 부분으로 구성되어 있습니다.\n여기서 주목할 것은 뉴런은 정보를 입력받아 내부적인 신호를 생성하여 다음 뉴런에 정보를 전달한 다는 것입니다.\n이러한 뉴런의 작동기전을 모방하여 만들어진 것이 퍼셉트론(Figure 1.2)입니다.\n퍼셉트론은 1957년 프랑크 로젠블라트가 제안한 것으로 퍼셉트론은 이러한 뉴런의 작동기전을 모방하여 정보를 입력(Input)받아 연산을 통해 출력(Output)을 생성하도록 설계되었습니다.\n이러한 정보의 흐름 또는 연산 절차를 다른 말로 Forward Propagation이라 합니다, 향후 논의 될 Back Propagation과 대비되는(?) 개념입니다.\nflowchart LR\n  subgraph node\n    direction LR\n    node2_1((SUM)) --&gt; node2_2((STEP))\n  end\n  node1_1((x_1)) --w1--&gt; node2_1\n  node1_2((x_2)) --w2--&gt; node2_1\n  node2_2 --&gt; node3((y_hat))\n\n\n\n\nFigure 1.2: Basic of Perceptron\nFigure 1.2 에서 원은 노드(Node)라고 하면 노드간 연결된 선을 엣지(Edge)라고 합니다. 엣지상에 존재하는 w는 가중치(Weight)하고 합니다.\n첫번째 노드의 x_1과 x_2는 입력값을 말하고, 두번째 노드는 내부적으로 SUM과 STEP으로 구성된 활성함수를 말하며, 마지막 노드의 z는 출력값으로 노드의 활성 정도를 말합니다.\n노란색 노드에서는 2단계 계산이 발생합니다. 하나늗 입력값의 뉴런에서는 신호의 세기를 계산하는 Weighted Sum(Equation 1.1) 과 뉴런의 여부를 계산하는 Step Function(Equation 1.2) 으로 구성되어 있습니다.\n결과적으로 퍼셉트론의 출력값(\\hat{y}=h_{w,b}(x)=sign(\\textbf{w}^{T}\\textbf{x}+b))은 (-1, 0, 1)로 3가지를 갖게 됩니다. 이 결과값을 실제의 값(y)와 비교(Loss Function)하여 가중치(w)를 업데이트 하여 최적해가 아닌 단순 solution(?)을 찾는 것이 퍼셉트론입니다.\nz = b + w_{1}x_{1} + w_{2}x_{2} + \\cdots + w_{n}x_{n} = b + \\textbf{w}^{T} \\textbf{x}\n\\tag{1.1}\nstep(z) = sign(z) = \\begin{cases}\n-1 & z &lt; 0 \\\\\n0 & z = 0 \\\\\n1 & z &gt; 0\n\\end{cases}\n\\tag{1.2}",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#what-is-a-perceptron",
    "href": "perceptron-intro.html#what-is-a-perceptron",
    "title": "1  Perceptron",
    "section": "",
    "text": "외부 자극등 정보를 수신하는 수상돌기(Dendrite)\n수신된 정보를 신호를 만들어 내는 핵(Nucleus)\n신호를 신경절달 물질로 만들어 내는 축삭돌기(Axon)+시넵스(Synapse)\n\n\n\n\n\n\n\n\nFigure 1.1: Structure of Neuron (source: Wikipedia)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n퍼셉트론에서 사용되는 계단함수\n\n\n\n일반적으로 Sign function을 가장 많이 사용하지만, 이진값(0, 1)만을 갖는 Heavisde step function이 사용되기도 합니다. Clsiffication 문제에서 직선상의 Observation값은 0 , Weight와 같은 방향은 1, 다른 방향은 -1로 처리하는 것이 보다 용이하기에 우리는 Sign function을 주로 사용합니다.\n\nheavisde(z) = \\begin{cases}\n0 & z &lt; 0 \\\\\n1 & z &gt;= 0\n\\end{cases}",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#bit-wise-operator단순-논리-회로",
    "href": "perceptron-intro.html#bit-wise-operator단순-논리-회로",
    "title": "1  Perceptron",
    "section": "1.2 Bit-wise operator(단순 논리 회로)",
    "text": "1.2 Bit-wise operator(단순 논리 회로)\n앞서 보았던 퍼셉트론을 분류(Classification)을 수행해보며 보다 자세하게 살펴보겠습니다. 특히 분류의 문제는 향후 ANN 및 CNN 등 다양한 문제를 해결하는데 사용되는 기법으로 향후 학습을 진행하면서 병렬적으로 작동기전에 대하여 비교하기가 용이할 것으로 생각됩니다.\n분류문제 중 가장 간단한 예시로 Bit-wise operator(단순 논리 회로)에 대한 내용을 살펴보겠습니다. 논리회로는 0과 1로 구분된 2개의 input을 받아 0또는 1을 output으로 출력하는 회로입니다.\n단순 논리 회로는 AND, NAND, OR 그리고 XOR게이트로 구성되어 있으며 입력에 따른 출력이 다음의 진리표(Table 1.1 )로 나타낼 수 있습니다.\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n0\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n1\n1\n1\n\n\n\n\n\n(a) AND gate\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n1\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n1\n1\n0\n\n\n\n\n\n(b) NAND gate\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n0\n\n\n1\n0\n1\n\n\n0\n1\n1\n\n\n1\n1\n1\n\n\n\n\n\n(c) OR gate\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n0\n\n\n1\n0\n1\n\n\n0\n1\n1\n\n\n1\n1\n0\n\n\n\n\n\n(d) XOR gate\n\n\n\n\n\n\n\nTable 1.1: 게이트별 진리표",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#perceptron-으로-구현",
    "href": "perceptron-intro.html#perceptron-으로-구현",
    "title": "1  Perceptron",
    "section": "1.3 Perceptron 으로 구현",
    "text": "1.3 Perceptron 으로 구현\n위의 진리표(Table 1.1 )의 내용을 퍼셉트론으로 구현해보겠습니다. 이를 위해 AND게이트를 예를 들도록 하겠습니다.\nAND게이트는 x_1 과 x_2가 모두 1인 경우 y를 1로 출력하는 논리 회로 입니다. 이를 퍼셉트론으로 표현하면 w_1, w_2, \\theta로 표현할 수 있고 이러한 선형판별식(Equation 1.3) 식은 아래와 같습니다.\n\n\n\ny = \\begin{cases}\n0 & w_1*x_1 + w_2*x_2 \\leq \\theta \\\\\n1 & w_1*x_1 + w_2*x_2 &gt; \\theta  \n\\end{cases}\n\\tag{1.3}\n위의 선형판별식은 아래와 같이 그림으로 표현이 가능합니다. 다만, 가중치 w 와 임계치 \\theta 의 조합은 무수히 많이 존재함을 유의해야 합니다.((?fig-egAndGate ) 의 적색선은 임의로 표현한 직선이고 이 직선이 무수히 많다는 의미)\n\n\n\n\n\n\n\n\nFigure 1.3: AND gate\n\n\n\n\n\n단순 논리 회로(XOR게이트 제외)의 선형판별식을 코드로 구현하면 다음과 같습니다. 여기서 일반적으로 향후 Deeplearning의 표현방법을 따라 임계치인 \\theta 를 편향(bias)인 -b로 치환한 수식을 사용하겠습니다.\n\n\n\ny = \\begin{cases}\n0 & b + w_1*x_1 + w_2*x_2 \\leq 0 \\\\\n1 & b + w_1*x_1 + w_2*x_2 &gt; 0\n\\end{cases}\n\\tag{1.4}\n변형된 수식(Equation 1.4 )에 기초하여 진리표(Table 1.1 )상의 게이트를 코드로 구현하면 아래와 같습니다.\n\n1import numpy as np\n\n# AND gate\ndef AND(x1, x2):\n  x = np.array([x1, x2])\n2  w = np.array([0.5, 0.5])\n  b = -0.7\n3  tmp = np.sum(w*x) + b\n  if tmp &lt;= 0:\n    return 0\n  elif tmp &gt; 0:\n    return 1\n\n# NAND gate\ndef NAND(x1, x2):\n  x = np.array([x1, x2])\n  w = np.array([-0.5, -0.5])\n  b = 0.7\n  tmp = np.sum(w*x) + b \n  if tmp &lt;= 0:\n    return 0\n  elif tmp &gt; 0:\n    return 1\n\n# OR gate\ndef OR(x1, x2):\n  x = np.array([x1, x2])\n  w = np.array([0.5, 0.5])\n  b = -0.7\n  tmp = np.sum(w*x) + b \n  if tmp &lt;= 0:\n    return 0\n  elif tmp &gt; 0:\n    return 1\n\n\n1\n\nVector 연산의 최적화를 위하여 numpy를 기본적으로 사용한다.\n\n2\n\nw와 b는 임의로 할당한다. 다만, NAND 및 OR 는 AND의 부호와 다름에 주의하자.\n\n3\n\nweighted sum은 가중치를 곱하여 더한 값으로 내적과 유사함을 유의하자.",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#mlp",
    "href": "perceptron-intro.html#mlp",
    "title": "1  Perceptron",
    "section": "1.4 MLP",
    "text": "1.4 MLP\n다중 퍼셉트론은 퍼셉트론이 여러층으로 구현된 형태를 말합니다. 층을 여러개 쌓아서 보다 복잡한 문제를 해결할 수 있고, 추후 Deeplearning에서 여러층의 신경망을 쌓는 방식의 기초라고만 이해해 두겠습니다.\n앞서 1층 퍼셉트론으로는 단순 논리 회로 중 선형적인 게이트만을 구현할 수 있었습니다. 그렇다면 XOR게이트는 해결할 수 없을까요? 이를 해결하기 위한 것이 다층 퍼셉트론 입니다.\n가령 XOR게이트 문제를 NAND와 OR게이트를 조합한 출력값을 AND게이트의 입력값으로 받게 된다면 XOR게이트를 구현할 수 있습니다. 국소적인 문제해결을 결합하여 전체 문제를 해결하는 방식으로 이해됩니다.\n\n\n\n\n\n\nflowchart LR\n  x1((x1)) & x2((x2)) ---&gt; nand[NAND] & or[OR] \n  nand --s1---&gt; AND ---&gt; y[y]\n  or --s2---&gt; AND\n\n\n\n\nFigure 1.4: XOR Gate: Composition of NAND, OR, AND\n\n\n\n\n\nXOR의 게이트를 다른 게이트의 조합을 활용한 진리표는 아래와 같습니다. 위의 그림에서 보듯이 x1과 x2의 입력값을 받아 NAND게이트는 s1의 출력값을 OR게이트는 s2의 출력값을 생성하며, 다시 s1과 s2를 입력값으로 받아 AND를 통과시켜 최종적으로 XOR게이트의 진리표를 다시 그릴 수 있습니다.\n\n\n\n\n\n\nx_1\nx_2\ns_1\ns_2\ny\n\n\n\n\n0\n0\n1\n0\n0\n\n\n1\n0\n1\n1\n1\n\n\n0\n1\n1\n1\n1\n\n\n1\n1\n0\n1\n0\n\n\n\n\n\nTable 1.2: XOR게이트의 진리표\n\n\n\n위의 진리표(Table 1.2 )를 코드로 구현하면 아래와 같습니다. 앞서 구현한 게이트들을 코드내에서 사용하여 단순하게 구현할 수 있습니다.\n\ndef XOR(x1, x2):\n  s1 = NAND(x1, x2)\n  s2 = OR(x1, x2)\n  y = AND(s1, s2)\n  return y",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#wrap-up",
    "href": "perceptron-intro.html#wrap-up",
    "title": "1  Perceptron",
    "section": "Wrap up",
    "text": "Wrap up\n지금까지 퍼셈트론에 대하여 살펴 보았습니다. 단순히 퍼셥트론이 뭐다라는 단순한 이야기 이지만, 딥러닝에 있어 가장 기초가 되는 부분입니다. 다만, 퍼셉트론 자체를 더 깊이 알아보기 보다 하나의 뉴런이 여러개의 뉴런이 되는 MLP(Multi-Layers Perceptron)가 여러개의 층으로 이루어 지는 NN(Neural Network)으로 발전된다 정도로 이해해 보도록 하겠습니다.\n자세한 사항은 다음장에서 여러개의 뉴런들이 층을 이루는 인공신경망(ANN, Articial Neural Network)에서 설명하도록 하며 주요 주제는 아래와 같습니다.\n\nActivation function & Forward Propagation\nLoss Function(Loss Optimization) & Back Propagation\nNN in Practice: Adaptive Learning, Mini-batches, Overfitting(Regularization)\n\n이후 ANN을 Foundation으로 Sequential Data Modelling을 위한 RNN 및 이미 처리를 위한 CNN 등에 대하여 학습할 예정입니다.",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-lab_classification.html",
    "href": "perceptron-lab_classification.html",
    "title": "2  Lab: Classification with Perceptron",
    "section": "",
    "text": "2.1 Classification\n우리가 실습할 분류 문제는 선형 판별 분석(LDA, Linear Discriminant Analysis)입니다. 수치형 입력변수를 받아 범주형 타겟 변수를 예측하는 분류 방법으로 퍼셈트론을 활용하여 해결하기 좋은 문제 입니다.\nFigure 2.1: Example of LDA\n위 산점도(Figure 2.1 )와 같은 산점도에서 C1과 C0을 구분하는 문제를 퍼셉트론을 이용하여 해결해 보겠습니다.\n전장에서 살펴본 퍼셉트론(Figure 1.2)에 따라 설명하고자 합니다. 우선 입력받는 변수는 x, 가중치는 \\omega로 둘수 있습니다.\n\\begin{align}\nx = \\begin{bmatrix}x_1\\\\ \\vdots\\\\ x_d \\end{bmatrix} \\qquad\n\\omega = \\begin{bmatrix}\\omega_1\\\\ \\vdots\\\\ \\omega_d \\end{bmatrix}\n\\end{align}\n\\tag{2.1}\n여기서 Weighted Sum의 결과가 특정 임계치(\\theta)를 초과하는 지에 따라 클래스1(C_1) 또는 클래스0(C_0)으로 구분하고자 합니다.\n\\begin{align}\nC_1 \\quad if\\, \\sum_{i=1}^{d}\\omega_{i}x_{i} &gt; \\theta \\\\\nC_0 \\quad if\\, \\sum_{i=1}^{d}\\omega_{i}x_{i} &lt; \\theta\n\\end{align}\n\\tag{2.2}\n이를 다시 Step function을 활용하여 Figure 1.2 의 노란색 박스(h(x))에 해당하는 노드를 다음의 식으로 변형하여 표현할 수 있습니다.\n여기서 임계치(\\theta)는 편향에 해당하는 값으로 변형하고 이를 다시 입력변수 \\omega_0으로 간단하게 표현할 수 있습니다.\n\\begin{align}\nh(x) &= \\text{sign} \\left(\\left( \\sum\\limits_{i=1}^{d}\\omega_ix_i \\right)- \\theta \\right) \\\\\n&= \\text{sign}\\left(\\left( \\sum\\limits_{i=1}^{d}\\omega_ix_i \\right)+ \\omega_0\\right)\n\\end{align}\n\\tag{2.3}\n\\omega_0=1로 두고 이를 벡터 형식(vector form)으로 표현하고, Step function을 Sign function으로 정의하면 아래와 같이 식을 수정할 수 있습니다.\n\\begin{align}\nh(x) &= \\text{sign}(\\sum_{i=0}^{d}\\omega_{i}x_{i})\n=\\text{sign}(\\omega^{T}x) \\\\\n\\text{sign}(x) &= \\begin{cases}\n1, &\\text{if }\\; x &gt; 0\\\\\n0, &\\text{if }\\; x = 0\\\\\n-1, &\\text{if }\\; x &lt; 0\n\\end{cases}\n\\end{align}\n\\tag{2.4}\nPerceptron Learning Algorithm(PLA)\n위의 식을 실제 퍼셉트론에 적용하기 위하여 위 산점도(Figure 2.1 )의 개별 값들을 활용하여 \\text{sign}(\\omega^Tx_n) = \\hat{y}_n을 산출하여 실제 라벨(y_n)과 비교하며 두 라벨값이 다를 경우 \\omega를 업데이트 하도록 합니다.\n\\begin{align}\n\\omega \\leftarrow\n\\begin{cases}\n\\omega+y_nx_n & \\hat{y_n} \\neq y_n \\\\\n\\omega &\\hat{y_n} = y_n \\\\\n\\end{cases}\n\\end{align}\n\\tag{2.5}\n위의 절차를 Training Set을 이용하여 Iterative하게 반복하여 \\omega를 업데이트 하도록 하여 PLA를 수행합니다.\nPerceptron Loss Function\nPLA를 수행하는 과정에서 학습을 종결시키기 위하여 Loss function이 필요합니다. 산출값 \\hat{y}_n과 y_n을 비교하여 Loss들의 합(\\mathscr{L}(\\omega))이 0이 되도록 하는 조건으로 설정할 수 있습니다.\n\\begin{align}\n\\mathscr{L}(\\omega) = \\sum_{n =1}^{m} \\max \\left\\{ 0, -y_n \\cdot \\left(\\omega^T x_n \\right)\\right\\}\n\\end{align}\n\\tag{2.6}",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lab: Classification with Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-lab_classification.html#solving-with-perceptron-algorithm",
    "href": "perceptron-lab_classification.html#solving-with-perceptron-algorithm",
    "title": "2  Lab: Classification with Perceptron",
    "section": "2.2 Solving with perceptron algorithm",
    "text": "2.2 Solving with perceptron algorithm\n위에서 살펴본 내용을 이제 코드로 작성해 보겠습니다. 기본적인 입력변수 x를 x1과 x2로 라벨값 y를 C1과 C0로 생성하였습니다. 그에 따른 산점도 데이터는 아래와 같습니다.\n\n#training data gerneration\nm = 100\nx1 = 8*np.random.rand(m, 1)\nx2 = 7*np.random.rand(m, 1) - 4\n\ng = 0.8*x1 + x2 -3\n\nC1 = np.where(g &gt;= 1)[0]\nC0 = np.where(g &lt; -1)[0]\n\n\n\n\n\n\nLinearly Separable Classes with no dicision boundary\n\n\n\n\n각각의 입력값을 numpy로 연산할 수 있도록 Vectorize를 진행합니다.\n\n\\begin{align}\nx &= \\begin{bmatrix} \\left(x^{(1)}\\right)^T \\\\ \\left(x^{(2)}\\right)^T \\\\ \\left(x^{(3)}\\right)^T\\\\ \\vdots \\\\ \\left(x^{(m)}\\right)^T \\end{bmatrix} = \\begin{bmatrix} 1 & x_1^{(1)} & x_2^{(1)} \\\\ 1 & x_1^{(2)} & x_2^{(2)} \\\\ 1 & x_1^{(3)} & x_2^{(3)}\\\\\\vdots & \\vdots & \\vdots \\\\ 1 & x_1^{(m)} & x_2^{(m)}\\end{bmatrix} \\\\\ny &= \\begin{bmatrix}y^{(1)} \\\\ y^{(2)} \\\\ y^{(3)}\\\\ \\vdots \\\\ y^{(m)} \\end{bmatrix}\n\\end{align}\n\n\nX1 = np.hstack([np.ones([C1.shape[0],1]), x1[C1], x2[C1]])\nX0 = np.hstack([np.ones([C0.shape[0],1]), x1[C0], x2[C0]])\n\nX = np.vstack([X1, X0])\ny = np.vstack([np.ones([C1.shape[0],1]), -np.ones([C0.shape[0],1])])\n\nX = np.asmatrix(X)\ny = np.asmatrix(y)\n\n가중치 \\omega를 1로 초깃값을 설정하고, 각각의 입력값을 이용하여 PLA를 실행하며 가중치 업데이트(\\omega \\leftarrow \\omega + yx)를 실행합니다.\n\nw = np.ones([3,1])\nw = np.asmatrix(w)\n\nn_iter = y.shape[0]\nflag = 0\n\nwhile flag == 0:\n    flag = 1\n    for i in range(n_iter):\n        if y[i,0] != np.sign(X[i,:]*w)[0,0]:\n            w += y[i,0]*X[i,:].T\n            flag = 0\n\n위의 절차를 실행하여 산출한 결정 경계(Dicision Boundary)는 아래와 같습니다.\n\n\n\n\n\nLinearly Separable Classes with dicision boundary\n\n\n\n\n\n\n\n\n\n\nPerceptron과 최적화의 문제\n\n\n\n\n여기서 중요한 것은 퍼셉트론은 구분하는 경계 산출에 촛점을 두고 있으므로 우리가 예상하는 최적 경계에 해당하지 않을 수 있습니다.\n가령 최적 경계는 두 그룹의 중간쯤 위치해야 할 것으로 생각이 됩니다. 그래야 향후 입력값이 추가 되었을 때 경계가 유효할 가능성이 높기 때문입니다.\n이를 해결하기 위하여는 내적을 통한 거리의 개념이 들어가고, Loss Function도 Logistic Regression의 방법으로 해결해야 하지 않을까라고 예상할 수 있습니다.",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lab: Classification with Perceptron</span>"
    ]
  },
  {
    "objectID": "ANN-intro.html",
    "href": "ANN-intro.html",
    "title": "3  Artificial Neural Networks",
    "section": "",
    "text": "인공신경망(ANN, Artificial Neural Networks)은 퍼셉트론과 유사한 메커니즘을 갖고 있습니다. Figure 4.1 에서 가장 왼쪽이 입력층(Input), 중간이 은닉층(Hidden), 가장 오른쪽이 출력층(Output)으로 구성되어 있습니다.\n\n\n\n\n\n\ngraph LR\n  subgraph Input\n      direction LR\n      x1((x1)) & x2((x2)) \n  end\n  \n  subgraph Hidden\n      direction LR\n      h1((h1)) & h2((h2)) & h3((h3))\n  end \n\n  subgraph Output\n      direction LR\n      y1((y1)) & y2((y2))\n  end\n\n    x1((x1)) & x2((x2))  ---&gt; h1((h1)) & h2((h2)) & h3((h3))\n    h1((h1)) & h2((h2)) & h3((h3)) ---&gt; y1((y1)) & y2((y2))\n\n\n\n\nFigure 3.1: Example of ANN\n\n\n\n\n\n다만, 퍼셉트론과 다른 점이 있따면, 신호를 전달 받는 과정에서 편향에 해당하는 b가 명시적으로 존재하여 이 또한 신호로 처리한다는 부분입니다.\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n  x1((x1)) --w1---&gt; y((y))\n  x2((x2)) --w2---&gt; y\n\n\n\n\n(a) Perceptron\n\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n  x0((1)):::bias --b---&gt; y((y))\n  x1((x1))  --w1---&gt; y((y))\n  x2((x2))  --w2---&gt; y\n  classDef bias fill:#f96\n\n\n\n\n(b) ANN\n\n\n\n\n\n\n\n\n\nFigure 3.2: 퍼셉트론과 ANN의 비교\n\n\n\nFigure 3.2 에는 잘 나타나 있지 않지만 Perceptron의 경우 입력신호를 받아 y를 바로 출력하지만, ANN의 경우 입력신호와 가중치를 곱하여 총합을 산출하는 함수와 이 산출값을 이용하여 조건 분기의 동작(0을 넘으면 1을 출력하고 그렇지 않으면 0을 출력)을 나타내는 함수로 구성되어 있으며 이를 구현한 산식은 Equation 3.1 과 같이 나타낼 수 있다.\n\n\\begin{align}\n&y = h(b + w_{1}x_{1} + w_{2}x_{2}) \\\\ \\\\\n&h(x) =\n  \\begin{cases}\n  0 & (x \\leq 0) \\\\\n  1 & (x &gt; 1)\n  \\end{cases}\n\\end{align}\n\\tag{3.1}\n\n\n\n\n\n\n펴셉트론과 Deeplearning의 차이\n\n\n\n\n퍼셉트론에 사용되는 선형판별식에 가중치 및 임계치의 조합은 무수히 많고, 가중치 및 임계치는 인간이 설정해야 함. 결국 Domain Knowledge를 갖고 있어야 한다는 의미임\nDeeplearning의 경우 가중치 및 임계치를 컴퓨터가 학습하여 설정해게 됨\n또한. Activation Function의 경우 미분가능해야 하고, Loss Function의 결과 Back propagation의 활용하여 \\omega를 최적화하는 절차가 존재함",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Artificial Neural Networks</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html",
    "href": "ANN-activation.html",
    "title": "4  Activation Function",
    "section": "",
    "text": "4.1 Sigmoid Function\n시그모이드 함수(sigmoid function)는 계단함수와 달리 ’S자 모양’으로 Non-linear한 함수이고 그 식은 아래와 같습니다.\n\\begin{align}\nh(x) = \\frac{1}{1+exp(-x)}\n\\end{align}\n시그모이드 함수를 python 코드로 아래와 같이 간다하게 구현할 수 있습니다. 이를 활용하여 시그모이드 함수를 실행하면 아래와 같은 그래프(Figure 4.2 )를 볼 수 있습니다.\ndef sigmoid(x):\n  return 1 / (1 + np.exp(-x))",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html#sigmoid-function",
    "href": "ANN-activation.html#sigmoid-function",
    "title": "4  Activation Function",
    "section": "",
    "text": "Figure 4.2: Plot of Sigmoid Function",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html#relu-function",
    "href": "ANN-activation.html#relu-function",
    "title": "4  Activation Function",
    "section": "4.2 ReLU Function",
    "text": "4.2 ReLU Function\n**ReLU 함수(Rectified Linear Unit funcion)는 시그모이드를 넘어 최근에 많이 사용되는 함수 입니다. 입력값을 0을 넘으면 그 입력값을 그대로 출력하고 그 이하이면 0을 출력하는 함수로 그 식은 아래와 같습니다.\n\n\\begin{align}\nh(x) =\n\\begin{cases}\nx & (x &gt; 0) \\\\\n0 & (x \\leq 0)\n\\end{cases}\n\\end{align}\n\nReLU 함수를 python 코드로 아래와 같이 간다하게 구현할 수 있습니다. 이를 활용하여 시그모이드 함수를 실행하면 아래와 같은 그래프(Figure 4.3 )를 볼 수 있습니다.\n\ndef relu(x):\n  return np.maximum(0, x)\n\n\n\n\n\n\n\nFigure 4.3: Plot of ReLU Function",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html#others",
    "href": "ANN-activation.html#others",
    "title": "4  Activation Function",
    "section": "4.3 others",
    "text": "4.3 others\n위에 소개한 활성화 함수 외에도 많은 종류의 활성화 함수가 존재합니다. 이에 대하여 자세한 사항은 Wiki페이지를 참고하시기 바랍니다.\n학습을 진행하는 과정에서 필요한 내용들을 지속적으로 업데이트 할 예정입니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-forward.html",
    "href": "ANN-forward.html",
    "title": "5  Forward Propagation",
    "section": "",
    "text": "5.1 Layer-by-Layer signaling\n3층 신경망의 신호 전달과정은 아래와 같이 Weighted Sum에 기반하며 그 값을 다시 화성화 함수(가령 Sigmoid)를 통하여 노드의 값이 최종 산출됩니다.\n또한, 이전층의 값들을 받아 산출된 값은 다시 입력값으로 하여 다음층으로 전달되는 과정을 거쳐 최종적으로 출력층까지 이 과정을 반복하게 됩니다. 이 과정이 신호 전달 또는 Forward propagation 입니다.\ninput to hidden\n최초 입력층(0층)의 신호 전달 체계는 입력값(노드)은 2개인 1차원 배열이고 다음의 은닉층(1층)은 노드 3계로 이루어진 1차원 배열입니다. 2개의 노드 값을 받아 3개의 노드로 전달해야 하므로 노드간의 간선은 총 6개(6 = 2 \\times 3)입니다.\n입력값 및 편향값을 a에 전달하고 a값을 활성화 함수(Sigmoid 함수를 사용) h()를 이용하여 신호 z를 산출하도록 합니다. 결과적으로 은닉층(1층)에 해당하는 3개의 노드의 신호를 확인할 수 있습닏.\n# 입력값, 편향, 가중치\nX  = np.array([1.0, 0.5])\nB1 = np.array([0.1,0.2,0.3])\nW1 = np.array([[0.1,0.3,0.5], [0.2,0.4,0.6]])\n\n# Weighted Sum\nA1 = np.dot(X, W1) + B1\n\n# Activation Function\nZ1 = sigmoid(A1)\n\nprint(A1)\nprint(Z1)\n\n[0.3 0.7 1.1]\n[0.57444252 0.66818777 0.75026011]\nhidden to hidden\n은닉층(1층)이 다시 입력층으로 하여 다음의 은닉층(2층)으로 신호를 전달하도록 해야 합니다. 앞서 진행한 신호 전달 과정과 동일합니다.\n다만, 입력 노드가 편향을 포함하여 4개가 다음 층인 2개의 노드로 전달됨에 따라 이전 과정과 달리 간선은 총 8개 입니다. 편향은 2개 간선을 갖고 가중치는 입력 노드별 2개 총 6개로 이루어 집니다.\n# 편향, 가중치\nB2 = np.array([0.1,0.2])\nW2 = np.array([[0.1,0.4], [0.2,0.5], [0.3,0.6]])\n\n# Weighted Sum & Activation Function\nA2 = np.dot(Z1, W2) + B2\nZ2 = sigmoid(A2)\n\nprint(A2)\nprint(Z2)\n\n[0.51615984 1.21402696]\n[0.62624937 0.7710107 ]\nhidden to output\n은닉층(2층)이 다시 입력층으로 하여 다음의 출력층(3층)으로 신호를 전달하도록 해야 합니다. 앞서 진행한 신호 전달 과정과 동일합니다.\n주의할 것은 출력층의 경우 해결하고자 하는 문제의 성질에 맞게 설정되어야 합니다. 여기서는 입력되는 값을 그대로 출력하는 항등함수(Identity Function)알 사용하도록 하겠습니다.\n# 항등함수\ndef identity_function(x):\n  return x\n\n# 편향, 가중치\nB3 = np.array([0.1,0.2])\nW3 = np.array([[0.1,0.3], [0.2,0.4]])\n\n# Weighted Sum & Activation Function\nA3 = np.dot(Z2, W3) + B3\nY  = identity_function(A3) # Y = A3\n\nprint(Y)\n\n[0.31682708 0.69627909]\nWrap-up\n앞서 정리한 내용을 하나의 모듈로 작성하도록 하겠습니다. 이 신경망의 신호 전달 과정은 순방향의 연산 과정만을 익히기 위함이고 가장 처음에 실행되는 과정입니다.\n1def init_network():\n  network = {}\n  network['W1'] = np.array([[0.1,0.3,0.5], [0.2,0.4,0.6]]) # 입력2 출력3\n  network['b1'] = np.array([0.1,0.2,0.3])\n  network['W2'] = np.array([[0.1,0.4], [0.2,0.5], [0.3,0.6]]) # 입력3, 출력2\n  network['b2'] = np.array([0.1,0.2])\n  network['W3'] = np.array([[0.1,0.3], [0.2,0.4]]) # 입력2, 출력2\n  network['b3'] = np.array([0.1,0.2])\n\n  return network\n\n2def forward(network, x):\n  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n\n  a1 = np.dot(x, W1) + b1\n  z1 = sigmoid(a1)\n  a2 = np.dot(z1, W2) + b2\n  z2 = sigmoid(a2)\n  a3 = np.dot(z2, W3) + b3\n  y  = identity_function(a3)\n\n  return Y\n\nnetwork = init_network()\nx = np.array([1.0,5.0])\ny = forward(network, x)\n\nprint(y)\n\n\n1\n\n가중치와 편향을 초기화하고 이들을 닉셔너리 변수인 network에 저장\n\n2\n\n입력신호를 출력으로 변환하는 처리과정\n\n\n\n\n[0.31682708 0.69627909]",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-forward.html#layer-by-layer-signaling",
    "href": "ANN-forward.html#layer-by-layer-signaling",
    "title": "5  Forward Propagation",
    "section": "",
    "text": "(a) input-hidden\n\n\n\n\n\n\n\n\n\n\n\n(b) hidden-hidden\n\n\n\n\n\n\n\n\n\n\n\n(c) hidden-output\n\n\n\n\n\n\n\nFigure 5.2: Process of Forward Propagation(souce: Deeplearning from Scratch)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n출력층의 활성화 함수\n\n\n\n\n출력층의 활성화 함수는 문제의 성질에 맞춰야 한다고 하였습니다.\n문제의 성질은 크게 2가지로 나누어 볼 수 있는데 하나는 분류(classfication), 다른 하나나는 회귀(regression)입니다.\n각각의 문제에 맞는 활성화 함수는 다양하며 자세한 사항은 지속적으로 Chapter 4 에 내용을 추가하도록 하겠습니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-forward.html#disign-output-layer",
    "href": "ANN-forward.html#disign-output-layer",
    "title": "5  Forward Propagation",
    "section": "5.2 Disign Output layer",
    "text": "5.2 Disign Output layer\n신경망의 경우 통상 회귀의 경우 항등 함수를, 분류의 경우는 소프트맥스 함수(softmax function)를 사용합니다. 소프트맥스 함수의 식은 아래와 같습니다.\n\ny_k = \\frac{exp(a_k)}{\\sum^{n}_{i=1}exp(a_i)}\n\\tag{5.2}\n위 식에서 exp(x)는 e^x를 지수함수를 의미하며, n은 출력층의 뉴런수, y_k는 출력노드 중 k번째를 의미합니다. 분자는 k번째 출력노드의 값을 분모는 전체 출력노드의 합을 의미합니다.\n\n\n\n\n\nflowchart LR\n  subgraph h [\"sigma()\"]\n    direction LR\n    a1((a1)) & a2((a2)) & a3((a3))\n    y1((y1)) & y2((y2)) & y3((y3))\n  end\n\n  a1 & a2 & a3 ---&gt; y1 & y2 & y3\n\n\n\n\n\n\nCautions for implementing the Softmax function\nEquation 5.2 식을 코드로 구현하기 이전에 주의할 사항이 필요합니다.\n하나는 오퍼플로(overflow), 즉 컴퓨터의 특성상 너무 큰 수의 경우 Inf가 나오게 된다는 점입니다.\n이러한 문제를 해결하기 위하여 참고한 자료에는 임의 상수 C를 분모와 분자에 모두 곱해주는 방식으로 이 문제를 해결 할수 있다고 하며 C는 다시 exp의 지수항으로 옮기고 C'로 변경할 수 있습니다.\n\n\\begin{align}\ny_k = \\frac{exp(a_k)}{\\sum^{n}_{i=1}exp(a_i)} &= \\frac{C\\,exp(a_k)}{C\\,\\sum^{n}_{i=1}exp(a_i)} \\\\\n&= \\frac{exp(a_k+log C)}{\\sum^{n}_{i=1}exp(a_i+log C)} \\\\\n&= \\frac{exp(a_k+C')}{\\sum^{n}_{i=1}exp(a_i+C')}\n\\end{align}\n\\tag{5.3}\n위의 식에 따라 출력층에 사용할 소프트맥스 함수를 아래와 같이 구현할 수 있으며, 개선된 식의 C는 통상 입력값의 최대값으로 설정하도록 하겠습니다.\n\ndef softmax(a):\n  c = np.max(a)\n  exp_a = np.exp(a-c)\n  sum_exp_a = np.sum(exp_a)\n  y = exp_a / sum_exp_a\n\n  return y\n\na = np.array([0.3, 2.9, 4.0])\ny = softmax(a)\n\nprint(y)\n\nnp.sum(y)\n\n[0.01821127 0.24519181 0.73659691]\n\n\n1.0\n\n\n위이 함수를 실행하면 출력값의 총합은 1임을 알 수 있습니다. 이것은 출력된 개별 값들을 확률로 해석할 수 있음을 의미합니다. 다만, 지수합수인 exp()계산시 자원이 많이 소비됨에 따라 추론 단계에서는 소프트맥스 함수를 생랙하기도 한다고 합니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-forward.html#lab-number-recognition-with-mnist",
    "href": "ANN-forward.html#lab-number-recognition-with-mnist",
    "title": "5  Forward Propagation",
    "section": "5.3 Lab : Number recognition with MNIST",
    "text": "5.3 Lab : Number recognition with MNIST\n현재 우리가 진행하고 있는 과정은 학습과 추론 중 추론(inference)에 해당하는 순전파(forward propagation)입니다. 학습의 경우 역전파(back propagation)를 통하여 가중치를 업데이트 하나 추론의 경우는 설정된 가중치를 이용하여 문제를 해결하는 과정입니다.\n\n\n\n\n\n\nMNIST 데이터셋\n\n\n\nMNIST1 데이터셋은 기계 학습 분야에서 널리 사용되는 손으로 쓴 숫자 이미지 데이터셋입니다. 이 데이터셋은 0부터 9까지의 숫자를 손으로 쓴 28x28 픽셀 크기의 이미지로 구성되어 있습니다. 주로 숫자 인식 및 분류 알고리즘의 테스트 및 훈련에 사용됩니다.\n\n크기: 28x28 픽셀\n포맷: 흑백 이미지(1채널)\n이미지 개수: - 훈련 데이터: 60,000개 - 테스트 데이터: 10,000개\n픽셀 값 범위: 0부터 255까지\n\n\n\n1 ANN 및 CNN 까지 다양한 예제에 활용될 예정\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nimport numpy as np\nfrom dataset.mnist import load_mnist\nfrom PIL import Image\n\n# MNIST 데이터셋 로드\n(x_train, t_train), (x_test, t_test) = \\\n  load_mnist(\n1    flatten = True,\n2    normalize = False,\n3    one_hot_label = False\n    ) \n\ndef img_show(img):\n    pil_img = Image.fromarray(np.uint8(img))\n    pil_img.show()\n\nimg = x_train[0]\nlabel = t_train[0]\nprint(label)  # 5\n\nprint(img.shape)  # (784,)\nimg = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\nprint(img.shape)  # (28, 28)\n\nimg_show(img)\n\n\n1\n\nflatten은 28x28의 2D-배열을 784x1 1D배열로 만들지 말지 결정하는 변수\n\n2\n\nnormalize는 픽셀값의 범위를 기존 [0, 255]에서 [0.0, 1.0]으로 변환할지 말지를 결정하는 변수\n\n3\n\none_hot_label은 레이블의 값을 정수(False, 예:5)로 할지, 한 원소만을 1로 갖는 배열(True, 예:[0,0,0,0,0,1,0,0,0,0,0])로 할지 결정하는 변수\n\n\n\n\n5\n(784,)\n(28, 28)\n\n\n\n5.3.1 Inference processing\nANN을 활용하여 MNIST 데이터셋을 가지고 추론과정을 신경망으로 구현하면 아래와 같습니다. 입력층의 뉴런은 28\\times28의 데이터를 받아 Flatten하게 784개의 뉴런으로 갖도록 합니다. 그리고 출력층의 뉴런은 0~9까지 10개로 분류해야 하므로 10개의 뉴런을 갖도록 합니다.\n입력과 출력사이의 은닉층은 2개의 층으로 구성하도록 하고 각각 50개 100개의 뉴런을 갖도록 합니다. 은닉층의 뉴런의 갯수는 임의로 정한 것이고 본 사전에 학습된 \\omega 를 사용하여 추론의 정확도를 평가해 보도록 하겠습니다.\n\n# coding: utf-8\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nimport numpy as np\nimport pickle\nfrom dataset.mnist import load_mnist\nfrom common.functions import sigmoid, softmax\n\n\ndef get_data():\n    (x_train, t_train), (x_test, t_test) = load_mnist(\n4      normalize=True,\n      flatten=True, \n      one_hot_label=False)\n    return x_test, t_test\n\n\ndef init_network():\n    with open(\"dataset/sample_weight.pkl\", 'rb') as f:\n        network = pickle.load(f)\n    return network\n\n\ndef predict(network, x):\n    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n\n    a1 = np.dot(x, W1) + b1\n    z1 = sigmoid(a1)\n    a2 = np.dot(z1, W2) + b2\n    z2 = sigmoid(a2)\n    a3 = np.dot(z2, W3) + b3\n    y = softmax(a3)\n\n    return y\n\n\nx, t = get_data()\nnetwork = init_network()\naccuracy_cnt = 0\n1for i in range(len(x)):\n    y = predict(network, x[i])\n2    p= np.argmax(y)\n3    if p == t[i]:\n        accuracy_cnt += 1\n\nprint(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))\n\n\n1\n\nfor문 안에서 이미지 1장씩 꺼내어 predict()함수로 분류(0~9)를 실행하여 레이블의 확률을 Numpy 배열로 반환\n\n2\n\nnp.argmax로 반환된 레이블 배열에서 가장 높은 값(확률)의 인덱스를 산출\n\n3\n\n정답 레이블과 산출 레이블의 비교하여 일치하면 accuracy_cnt로 정답 갯수 업데이트\n\n4\n\nload_mnist함수의 인자 중 normalize가 True는 데이터를 0~1사이의 값으로 정규화 한다는 의미\n\n\n\n\nAccuracy:0.9352\n\n\n위의 과정을 통해 분류의 정확도는 93.52%임을 확인 할 수 있습니다. 이후에 이 정확도를 향상시키기 위한 신경망의 학습 등에 대하여 살펴볼 예정입니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-learning.html",
    "href": "ANN-learning.html",
    "title": "6  Learning process",
    "section": "",
    "text": "6.1 Loss Function\n손실함수는 인공신경에 입력되어 산출되는 값과 실제 값을 비교하여 정확도를 측정하는 하나의 지표라고 할 수 있다. ANN은 이러한 지표를 기준으로 최적의 가중치와 편향을 탐색하는 방식으로 학습을 진행합니다.\n손실함수로는 일반적으로 오차제곱합(SSE, sum of squares for error)과 교차 엔트로피 오차(CEE, cross entropy error)를 사용합니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Learning process</span>"
    ]
  },
  {
    "objectID": "ANN-learning.html#loss-function",
    "href": "ANN-learning.html#loss-function",
    "title": "6  Learning process",
    "section": "",
    "text": "6.1.1 SSE(sum of squares for error)\n오차제곱합(Equation 6.1 )은 신경말의 출력값(y_k)과 실제값(t_k) 사이의 차이인 오차를 계산하고 이 오차를 제곱하여 모두 더한 값을 말하며 이 값이 작아질 수록 모델이 더 좋은 예측능력을 보유한다고 판단합니다.\n\nE = \\frac{1}{2}\\sum^{}_{k}(y_k - t_k)^2\n\\tag{6.1}\n오차제곱합의 작동원리를 이해하기 위하여 임의로 원-핫 인코딩된 레이블(t_k)과 임의로 소프트맥수 합수의 출력값(y_k)을 생성하여 코드로 구현해 보겠습니다.1\n1 CEE에서도 동일한 예제를 사용 예정\n# 정답 레이블은 2\nt = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n\ndef sum_squres_error(y, t):\n  return 0.5 * np.sum((y-t)**2)\n\n# 예1: 2일 확률이 제일 높음(60%)\ny = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\nl1 = sum_squres_error(np.array(y), np.array(t))\n\n# 예2: 7일 확률이 제일 높음(60%)\ny = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\nl2 = sum_squres_error(np.array(y), np.array(t))\n\nprint(\"1번예제: %3f, 2번예제:%3f\" % (l1, l2))\n\n1번예제: 0.097500, 2번예제:0.597500\n\n\n정답 레이블인 2를 높은 확률로 산출한 1번 예제의 손실값이 0.09로 0에 근접하고, 7를 높은 확률로 산출한 2번 예제의 손실값이 0.59로 0에 멀게 산출됨을 확인 할 수 있습니다.\n\n\n6.1.2 CEE(cross entropy error)\n교차 엔트로피(Equation 6.2 )는 신경망의 출력값(y_k)이 소프트 맥스 함수를 거쳐 확률로 [0.0, 1.0]의 값을 갖는 다는 점을 고려하여 확률값이 높을 수록 0에 수렴하는 손실값을 산출합니다.\n\nE = -\\sum^{}_{k}t_k\\log{y_k}\n\\tag{6.2}\n\n\n\n\n\n\nFigure 6.2: Graph of y=lox(x)\n\n\n\n위의 그래프(Figure 6.2 )에서 보듯 x가 1일때 y는 0이 되고 x가 0에 근접시 y는 점점 작아집니다. 교차 엔트로피는 여기에 음(-)의 부호를 붙여 활률값인 x가 작아질수록 손실값인 y가 크게 나오도록 하였습니다.\n위의 식(Equation 6.2 )을 코드로 구현해 보겠습니다.\n\n# 정답 레이블은 2\nt = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n\ndef corss_entropy_error(y, t):\n1  delta = 1e-7\n  return -np.sum(t * np.log(y + delta))\n\n# 예1: 2일 확률이 제일 높음(60%)\ny = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\nl1 = corss_entropy_error(np.array(y), np.array(t))\n\n# 예2: 7일 확률이 제일 높음(60%)\ny = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\nl2 = corss_entropy_error(np.array(y), np.array(t))\n\nprint(\"1번예제: %3f, 2번예제:%3f\" % (l1, l2))\n\n\n1\n\ndelta를 설정한 이유는 y가 0이면 np,log함수는 무한대인 inf값을 출력하는데 이를 방지하기 위함\n\n\n\n\n1번예제: 0.510825, 2번예제:2.302584\n\n\n1번 예제의 손실값이 0.51로 2번 예제의 손실값보다 낮은 값을 출력하여 오차제곱합의 결과와 일치함을 확인할 수 있습니다.\n\n\n6.1.3 CEE with Mini-batch\n손실함수는 주어진 데이터에 대한 모든 손실값의 합을 모델의 평가지표로 산출합니다. 가령 훈련 데이터가 100개이 60,000개 인경우 60,000개의 손실값을 산출해야 합니다.\n이렇게 훈련데이터 모두에 대한 손실값을 산출하는 경우 데이터가 증가할 수록 산출시간이 오래 걸리는 문제가 있습니다. 그렇다면 이를 보다 효율적으로 할 수 있는 방법은 무엇이 있을까요?\n일부 데이터를 추려 근사치를 계산하는 방법을 생각할 수 있습니다. 이러한 방법을 미니배치(mini-batch)라고 하며 훈련데이터 전체에서 임의로 특정 데이터를 뽑아 학습하는 방법입니다.\n우리는 이러한 미니배치 학습을 위해 몇개를 임의 추출할지(batch-size)와 이러한 과정을 몇번 수행할 것인지(number of iteration)에 대한 고민을 해야 합니다, 그 이유는 배치는 전체데이터의 일부만을 대상으로 하기 때문입니다.2\n2 본 문제는 hyper parameter의 설정에 대한 내용으로 overfitting을 방지하려는 문제와 관련이 있습니다.\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nfrom dataset.mnist import load_mnist\n\n# MNIST 데이터셋 로드\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, one_hot_label = True)\n\n# Mini-batch 설정\ntrain_size = x_train.shape[0]\nbatch_size = 10\n1batch_mask = np.random.choice(train_size, batch_size)\n\n# Batch용 데이터 설정\n2x_batch = x_train[batch_mask]\nt_batch = t_train[batch_mask]\n\n\n1\n\nnp.randon.choice는 전체 N개의 데이터(train_size)에서 임의로 몇개(batch_size)를 추출할 것인지 결정\n\n2\n\nbatch_mask는 임의 뽑힌 데이터의 인덱스 값\n\n\n\n\n위에서 우리는 학습을 효율적으로 실시하기 위하여 미니배치를 설정하였습니다. 그렇다면 미니배치로 손실을 어떻게 구해야 할까고민입니다. 앞서 구현한 교차 엔트로피 오차를 아래의 코드와 같이 일부만 수정하면 간단히 해결할 수 있습니다.\n\ndef corss_entropy_error(y, t):\n  if y.ndim == 1:\n    t = t.reshape(1, t.size)\n    y = y.reshape(1, y.size)\n  \n  batch_size = y.shape[0]\n1  return -np.sum(t * np.log(y + 1e-7)) / batch_size\n2  return -np.sum(t * np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n\n\n1\n\n정답 레이블이 원-핫 인코딩 형상인 경우\n\n2\n\n정답 레이블이 숫자 레이블인 경우",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Learning process</span>"
    ]
  },
  {
    "objectID": "ANN-learning.html#gradient-descent",
    "href": "ANN-learning.html#gradient-descent",
    "title": "6  Learning process",
    "section": "6.2 Gradient Descent",
    "text": "6.2 Gradient Descent\nANN은 손실함수의 값을 최소화 하는 방향으로 학습을 진행한다고 하였습니다. 이를 다시 말하면 손실함수가 최소값을 갖도록 하는 최적의 매개변수(가중치와 편향)를 탐색하는 문제입니다.\n그러나 매개변수의 공간은 방대하여 이를 찾는 문제는 쉽지 않습니다. 그래서 기울기를 사용한 최적화 알고리즘인 경사하강법(gradient descent)을 이해할 필요가 있습니다.\n경사하강법은 현재의 위치에서 모든 방향으로 기울기3를 구하고, 기울기의 반대방향으로 일정거리(학습률, learning rate)만큼 이동합니다. 이를 반복수행하면서 함수의 기울기(경사)를 줄여나가는 방법입니다. 이를 식으로 나타내보겠습니다.\n3 경사하강법은 기울기를 구한다는 점에서 미분에 대한 이해, 특히 매개변수별 기울기(모든 방향으로의 기울기)를 구한다는 점에서 편미분이 사용됩니다.\n\\begin{align}\nx_0 &= x_0 - \\eta \\frac{\\partial{f}}{\\partial{x_0}}\nx_1 &= x_1 - \\eta \\frac{\\partial{f}}{\\partial{x_1}}\n\\end{align}\n\\tag{6.3}\n위의 식을 도식화 하면 아래(Figure 6.3 )와 같고 아래의 표에서 학습을 시작한 초기점은 등고선의 1사분면 쪽에서 시작하여 기울기의 반대방향으로 매개변수를 업데이트해 나가는 과정을 보여줍니다.\n\n\n\n\n\n\nFigure 6.3: Example of Gradient Descent\n\n\n\n\n\n\n\n\n\n경사하강법의 한계\n\n\n\n경사하강법은 함수의 기울기는 0인 곳을 찾아가는 최적화 알고리즘입니다. 그러나 함수의 기울기아 0이 되는 곳이 항상 최솟값에 해당하지 않습니다. 가령 함수가 복접하고 찌그러진 모양인 경우 그곳이 최솟값인지 아니면 극솟값인지 또는 안정점인지 알고리즘은 알지 못합니다.\n물론 이러한 문제를 해결하기 위하여 다양한 방법을 사용합니다. 가령 확률의 개념을 도입하거나 배치를 설정할 수 있습니다, 또한, 업데이트 하는 정도인 학습률(learning rate)와 같은 하이퍼파라미터의 설정의 조정하는 방법도 있습니다. 자세한 사항은 뒤에서 설명하겠습니다.\n\n\n아래는 경사하강법을 구현한 예시입니다.\n\n# 기울기 계산\n1def numerical_gradient(f, x):\n2  h = 1e-4\n3  grad = np.zeros_like(x)\n\n  for idx in range(x.size):\n    tmp_val = x[idx]\n    # f(x) 계산\n    x[idx] = tmp_val + h\n    fxh1 = f(x)\n    # f(x-h) 계산\n    x[idx] = tmp_val - h\n    fxh2 = f(x)\n\n4    grad[idx] = (fxh1 - fxh2) / (2*h)\n    x[idx] = tmp_val\n  \n  return grad\n\n# 경사하강\n5def gradient_descent(f, init_x, lr = 0.01, step_num=100):\n  x = init_x\n\n  for i in range(step_num):\n6    grad = numerical_gradient(f, x)\n    x -= lr * grad\n  return x\n\n# 실전 풀이\ndef function_2(x):\n  return x[0]**2 + x[1]**2\n  \nresult = []\n# 학습률이 적정\ninit_x = np.array([-3.0, 4.0])\nresult.append(gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100))\n# 학습률이 과다\ninit_x = np.array([-3.0, 4.0])\nresult.append(gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100))\n# 학습률이 과소\ninit_x = np.array([-3.0, 4.0])\nresult.append(gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100))\n\nprint(\"학습률별 결과:\")\nfor i in range(3):\n    print(f\"Result {i+1}:\", result[i])\n\n\n1\n\nnumerical_gradien는 기울기를 구하는 함수(수치미분 사용)\n\n2\n\nh는 수치미분을 위한 아주 작은 크기의 변화량\n\n3\n\ngrad = np.zeros_list(x)는 x와 형상기 같은 배열을 생성\n\n4\n\nfxh1과 fxh2 사이의 기울기를 구한다는 의미가\n\n5\n\nf 최적화 대상 함수, init_x 초깃값, lr 학습률, step_num 반복시행 횟수\n\n6\n\n1번의 수치미분 함수\n\n\n\n\n학습률별 결과:\nResult 1: [-6.11110793e-10  8.14814391e-10]\nResult 2: [-2.58983747e+13 -1.29524862e+12]\nResult 3: [-2.99999994  3.99999992]\n\n\n\n\n\n\n\n\nFigure 6.4: Results by learning rate\n\n\n\nFigure 6.4 에서 보듯이 학습률의 설정은 ANN 등 신경망의 학습시 하이퍼파라미터 설정의 중요성4을 잘 보여주는 사례입니다.\n4 ANN의 효율성 및 신뢰성을 높이기 위한 기법 및 하이퍼파라미터 설정에 대한 이슈는 개별 이슈가 발생시 추가적으로 정리할 예정입니다.가령 학습률을 적정하게(1번) 설정시 학습이 원활하게 이루어지지만 학습률이 매우 큰경우(2번) 오버슈팅으로 의도한바와 전혀 다른 결과가 나오게 됩니다. 반면 학습률을 너무 작게 설정한 경우(3번) 학습이 잘 이루어지지 않는 문제를 확인할 수 있습니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Learning process</span>"
    ]
  },
  {
    "objectID": "ANN-learning.html#applying-gradient-descent-to-ann",
    "href": "ANN-learning.html#applying-gradient-descent-to-ann",
    "title": "6  Learning process",
    "section": "6.3 Applying gradient descent to ANN",
    "text": "6.3 Applying gradient descent to ANN\n지금까지 우리는 손실함수와 경사하강법에 대하여 학습하였습니다. 다시 정리하면 ANN에서의 손실함수는 신경망의 출력값과 레이블값의 차이를 구하는 도구이고, 경사하강법은 매개변수(가중치 및 편향)에 대한 손실함수의 기울기에 해당합니다.\n여기서 경사하강법을 이용하여 2 \\times 3형상의 가중치 \\textbf{W}에 대한 손실함수 L의 기울기를 기울기5를 구하도록 하겠습니다.(Equation 6.4 )\n5 모든 가중치에 대한 손실함수의 기울기를 구해야 함을 고려시, 모든 가중치에 해당하는 벡터별로 독립적으로 기울기를 구한다는 의미로 편미분으로 처리\n\\begin{align}\n\\textbf{W} &= \\begin{pmatrix}\n    w_{11} & w_{12} & w_{13} \\\\\n    w_{11} & w_{12} & w_{13}\n\\end{pmatrix} \\\\ \\\\\n\\frac{\\partial{L}}{\\partial{\\textbf{W}}}&= \\begin{pmatrix}\n    \\frac{\\partial{L}}{\\partial{w_{11}}} & \\frac{\\partial{L}}{\\partial{w_{12}}} & \\frac{\\partial{L}}{\\partial{w_{13}}} \\\\\n    \\frac{\\partial{L}}{\\partial{w_{11}}} & \\frac{\\partial{L}}{\\partial{w_{12}}} & \\frac{\\partial{L}}{\\partial{w_{13}}}\n\\end{pmatrix}\n\\end{align}\n\\tag{6.4}\n위의 식(Equation 6.4 )을 코드로 구현하여 기울기를 산출해 보도록 하겠습니다. 먼제 간단하게 신경망을 아래와 같이 구현할 수 있습니다.\n\n# 환경설정\nimport sys, os\nsys.path.append(os.pardir)\nimport numpy as np\nfrom common.functions import softmax, cross_entropy_error\nfrom common.gradient import numerical_gradient\n\n# 클래스 구현\nclass simpleNet:\n  def __init__(self):\n    self.W = np.random.randn(2,3)\n\n  def predict(self, x):\n    return np.dot(x, self.W)\n\n  def loss(self, x, t):\n    z = self.predict(x)\n    y = softmax(z)\n    loss = cross_entropy_error(y, t)\n    return loss\n\n# 실습\n1net = simpleNet()\n2x = np.array([0.6, 0.9])\n3p = net.predict(x)\n\n4t = np.array([0, 0, 1])\n5res = net.loss(x, t)\n\n# 결과\nprint(\"가중치 현황\")\nprint(net.W)\nprint(\"출력값\")\nprint(p)\nprint(\"손실값\")\nprint(res)\n\n\n1\n\nsimpleNet 객체생성\n\n2\n\n입력변수 생성\n\n3\n\n가중치와 입력값의 weighted sum 산출\n\n4\n\n정답 레이블\n\n5\n\n손실함수 산출 결과\n\n\n\n\n가중치 현황\n[[ 1.43515604  0.01940693  1.36755061]\n [-2.07574193 -1.91004383 -1.31612413]]\n출력값\n[-1.00707411 -1.70739529 -0.36398135]\n손실값\n0.580323943400203\n\n\n다음으로 기울기는 아래와 같이 구현할 수 있습니다. 가중치에 대한 손실함수의 기울기를 편미분을 이용하여 구하는 경우 본래 가중치가 보유한 형상은 유지됨을 주의하도록 합니다.6\n6 형상이 바뀌는 경우 신경망의 구조가 변하게 되어 에러가 발생합니다.\ndef f(W):\n  return net.loss(x,t)\n\ndW = numerical_gradient(f, net.W)\nprint(dW)\n\n[[ 0.17653384  0.08763596 -0.2641698 ]\n [ 0.26480076  0.13145394 -0.3962547 ]]\n\n\n위의 내용에서 하석할 수 있는 것은 numerical_gradient를 통해 w_{11}를 h만큼 미세하게 변화 시키는 경우 손실함수 값은 print(dW)의 1행x1열의 값만큼 변화한다는 의미7입니다. 또한 w_{11} 보다 w_{23}의 기여도가 더 크다고 이해할 수 있습니다.\n\n\n7 따라서 손실함수 값을 감소시키려면 기울기의 반대방향으로 가중치 \\textbf{W}을 갱신(w_{ij} \\leftarrow w_{ij} - \\eta \\frac{\\partial{L}}{\\partial{w_{ij}}})해야 한다",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Learning process</span>"
    ]
  },
  {
    "objectID": "ANN-lab_MNIST.html",
    "href": "ANN-lab_MNIST.html",
    "title": "7  Lab: Implementing ANN with MINIST dataset",
    "section": "",
    "text": "7.1 STEP1: Two Layer Net\n우리는 지금까지 학습한 내용에 기초하여 아래와 같이 순전파(forward propagation) 과정을 Two Layer Net이라는 클래스로 구현해 보겠습니다.\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nfrom common.functions import *\nfrom common.gradient import numerical_gradient\n\n\nclass TwoLayerNet:\n\n1    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n        # 가중치 초기화\n        self.params = {}\n        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n        self.params['b1'] = np.zeros(hidden_size)\n        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n        self.params['b2'] = np.zeros(output_size)\n\n2    def predict(self, x):\n        W1, W2 = self.params['W1'], self.params['W2']\n        b1, b2 = self.params['b1'], self.params['b2']\n    \n        a1 = np.dot(x, W1) + b1\n        z1 = sigmoid(a1)\n        a2 = np.dot(z1, W2) + b2\n        y = softmax(a2)\n        \n        return y\n        \n    # x : 입력 데이터, t : 정답 레이블\n3    def loss(self, x, t):\n        y = self.predict(x)\n        \n        return cross_entropy_error(y, t)\n    \n4    def accuracy(self, x, t):\n        y = self.predict(x)\n        y = np.argmax(y, axis=1)\n        t = np.argmax(t, axis=1)\n        \n        accuracy = np.sum(y == t) / float(x.shape[0])\n        return accuracy\n        \n    # x : 입력 데이터, t : 정답 레이블\n5    def numerical_gradient(self, x, t):\n        loss_W = lambda W: self.loss(x, t)\n        \n        grads = {}\n        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n        \n        return grads\n        \n6    def gradient(self, x, t):\n        W1, W2 = self.params['W1'], self.params['W2']\n        b1, b2 = self.params['b1'], self.params['b2']\n        grads = {}\n        \n        batch_num = x.shape[0]\n        \n        # forward\n        a1 = np.dot(x, W1) + b1\n        z1 = sigmoid(a1)\n        a2 = np.dot(z1, W2) + b2\n        y = softmax(a2)\n        \n        # backward\n        dy = (y - t) / batch_num\n        grads['W2'] = np.dot(z1.T, dy)\n        grads['b2'] = np.sum(dy, axis=0)\n        \n        da1 = np.dot(dy, W2.T)\n        dz1 = sigmoid_grad(a1) * da1\n        grads['W1'] = np.dot(x.T, dz1)\n        grads['b1'] = np.sum(dz1, axis=0)\n\n        return grads\n\n\n1\n\n__init__ 클래스의 초기화 수행 (입력층, 은닉층, 출력층 각각의 뉴런수 지정)\n\n2\n\npredict 추론을 수행 (x 이미지 데이터)\n\n3\n\nloss 손실함수 값 산출 (x 이미지 데이터, t 정답레이블)\n\n4\n\naccuracy 신경망의 정확도 산출\n\n5\n\nnumerical_gradient 매개변수(가중치)의 기울기 산출\n\n6\n\ngradient 매개변수(가중치)의 기울기 산출(오차 역전파과정은 다음장에서 설명)\n위의 클래스에서 gradient 메서드의 경우 순전파와 역전파를 모두 사용하고, 순전파시 활성화 함수로 sigmoid를 출력값의 활성화 함수로 분류 문제해결을 위해 softmax를 사용하였습니다.(제사한 사항은 활성화 함수를 참고 Chapter 5)\n추가적으로 우리가 사용할 데이터의 형상에 주의하여 클래스의 초기화를 수행해야 합니다. MNIST 데이터 셋의 개별 입력값은 28 \\times 28 픽셀을 Flatten하게하여 784개의 입력값의 형상을 설정해야 합니다.\n또한, 우리가 수행하는 분류문제에서 출력값은 분류하고자 하는 카테고리의 갯수 여기서 0~9까지 10개의 숫자를 분류해야 함을 고려하여 출력값의 형상은 10개로 설정해야 합니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lab: Implementing ANN with MINIST dataset</span>"
    ]
  },
  {
    "objectID": "ANN-lab_MNIST.html#step2-mini-batch",
    "href": "ANN-lab_MNIST.html#step2-mini-batch",
    "title": "7  Lab: Implementing ANN with MINIST dataset",
    "section": "7.2 STEP2: Mini-Batch",
    "text": "7.2 STEP2: Mini-Batch\n모든 데이터를 갖고 학습하는 것은 효율적이지 않다고 하였습니다. 따라서, 무작위로 훈련 데이터 중 일부를 추출하여 훈련을 진행하는 미니배치 방법을 통하여 훈련의 효율성을 높일 수 있습니다.\n미니배치를 활용하여 확률적 경사하강법을 구현하면 아래와 같습니다.\n\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom dataset.mnist import load_mnist\n\n# 데이터 읽기\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n\n# 하이퍼파라미터\niters_num = 10000  # 반복 횟수를 적절히 설정한다.\ntrain_size = x_train.shape[0]\nbatch_size = 100   # 미니배치 크기\nlearning_rate = 0.1\n\ntrain_loss_list = []\n\nfor i in range(iters_num):\n    # 미니배치 획득\n    batch_mask = np.random.choice(train_size, batch_size)\n    x_batch = x_train[batch_mask]\n    t_batch = t_train[batch_mask]\n    \n    # 기울기 계산\n    #grad = network.numerical_gradient(x_batch, t_batch)\n    grad = network.gradient(x_batch, t_batch)\n    \n    # 매개변수 갱신\n    for key in ('W1', 'b1', 'W2', 'b2'):\n        network.params[key] -= learning_rate * grad[key]\n    \n    # 학습 경과 기록\n    loss = network.loss(x_batch, t_batch)\n    train_loss_list.append(loss)",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lab: Implementing ANN with MINIST dataset</span>"
    ]
  },
  {
    "objectID": "ANN-lab_MNIST.html#step3-evaluating-with-test-data",
    "href": "ANN-lab_MNIST.html#step3-evaluating-with-test-data",
    "title": "7  Lab: Implementing ANN with MINIST dataset",
    "section": "7.3 STEP3: Evaluating with test data",
    "text": "7.3 STEP3: Evaluating with test data\n이제 우리가 구현한 클래스의 성능을 평가해 보도록 하겠습니다. 훈련데이터를 미니배치로 나누어 훈련을 진행하였는데 과연 다른 새로운 데이터셋에서도 동일한 성능을 발휘할지 알아야 합니다.\n만약, 훈련 데이터에만 적응한 ANN이라면 새로운 데이터에서는 적절한 성능을 발휘하지 못할 가능성이 있기 때문입니다. 이를 오버피팅(overfitting)2이라 합니다.\n2 오버피팅은 훈련데이터에 대한 정확도는 높으나 신규 데이터에는 적절한 성능을 발휘하지 못하는 문제로 이러한 문제를 해결하기 위하여 조기종료(early stopping), 가중치 감소, 드롭아웃(drop-out)등의 기법이 사용됩니다.\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom dataset.mnist import load_mnist\n\n# 데이터 읽기\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n\n# 하이퍼파라미터\niters_num = 10000  # 반복 횟수를 적절히 설정한다.\ntrain_size = x_train.shape[0]\nbatch_size = 100   # 미니배치 크기\nlearning_rate = 0.1\n\ntrain_loss_list = []\n1train_acc_list = []\n2test_acc_list = []\n\n3iter_per_epoch = max(train_size / batch_size, 1)\n\nfor i in range(iters_num):\n    # 미니배치 획득\n    batch_mask = np.random.choice(train_size, batch_size)\n    x_batch = x_train[batch_mask]\n    t_batch = t_train[batch_mask]\n    \n    # 기울기 계산\n    #grad = network.numerical_gradient(x_batch, t_batch)\n    grad = network.gradient(x_batch, t_batch)\n    \n    # 매개변수 갱신\n    for key in ('W1', 'b1', 'W2', 'b2'):\n        network.params[key] -= learning_rate * grad[key]\n    \n    # 학습 경과 기록\n    loss = network.loss(x_batch, t_batch)\n    train_loss_list.append(loss)\n    \n    # 정확도 계산\n4    if i % iter_per_epoch == 0:\n        train_acc = network.accuracy(x_train, t_train)\n        test_acc = network.accuracy(x_test, t_test)\n        train_acc_list.append(train_acc)\n        test_acc_list.append(test_acc)\n        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n\n# 그래프 그리기\nmarkers = {'train': 'o', 'test': 's'}\nx = np.arange(len(train_acc_list))\nplt.plot(x, train_acc_list, label='train acc')\nplt.plot(x, test_acc_list, label='test acc', linestyle='--')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.ylim(0, 1.0)\nplt.legend(loc='lower right')\nplt.show()\n\n\n1\n\ntrain_acc_list 학습 데이터에 대한 정확도를 저장하는 튜플\n\n2\n\ntest_acc_list 검증 데이터에 대한 정확도를 저장하는 튜플\n\n3\n\niter_per_epoch 1 epoch당 반복하는 횟수\n\n4\n\nif i % iter_per_epoch == 0: 1 epoch당 정확도 계산\n\n\n\n\n\n\n\n\n\n\nFigure 7.1: Accuracy trends for training and test data\n\n\n\n위의 그림에서 보듯이 훈련 데이터(실선)와 검증 데이터(점선)의 정확도가 epoch인 진행될 수록 같은 수준으로 좋아지고 있습니다. 이는 오버피팅없이 적절히 학습이 이루어 졌다고 평가할 수 있습니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lab: Implementing ANN with MINIST dataset</span>"
    ]
  },
  {
    "objectID": "ANN-backward.html",
    "href": "ANN-backward.html",
    "title": "8  Backward Propagation",
    "section": "",
    "text": "8.1 Pre-requisite: Chain-rule and Dynamic Programming\n오차역전파는 기본적으로 손실함수 값에서 입력값까지의 매개변수를 역으로 조정하는 과정으로 순방향과 반대방향으로 국소적인 미분값을 곱하며 가중치를 조정하는 절차로 이해할 수 있습니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Backward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-backward.html#pre-requisite-chain-rule-and-dynamic-programming",
    "href": "ANN-backward.html#pre-requisite-chain-rule-and-dynamic-programming",
    "title": "8  Backward Propagation",
    "section": "",
    "text": "8.1.1 Chain-rule\n반대방향으로 국소적인 미분값을 곱한다는 것은 어떠한 의미를 갖고 있을까요? 그리고 이러한 연산의 기반이 되는 개념이 무엇일까요? 이물음에 대한 답변이 바로 연쇄법칙입니다. 연쇄법칙에 관한 자세한 설명은 아래 3Blue1Brown1 영상을 참고하기 바랍니다.\n1 3Blue1Brown은 많은 수학적인 문제를 도식화하여 아주 직관적으로 설명하고 있어 매우 유용합니다.\n\n\n8.1.2 Dynamic Programming\n연쇄법칙을 정확히 이해하였다면 지속적으로 미분값이 재귀적으로 사용됨을 확인할 수 있습니다. 그러나 이미 계산된 미분값을 따로 저장하였다가 불러오기만 한다면 연산이 얼마나 쉬워질까요? 쉬워진다기보다 간단해지고 컴퓨터의 연산의 수를 줄일 수 있지 않을까요?\n바로 이러한 배경에서 연쇄법칙을 빠르게 수행하기 위하여 고려되는 방법이 동적계획법 입니다. 이는 피보나치 수열의 계산에 있어서 재귀적으로 반복계산되는 노드를 따로 저장하여 그 값을 호출하여 사용하도록 하므로써 연산의 수를 줄여 알고리즘의 성능을 개선해줄수 있을 것입니다.\n동적계획법에 대한 자세한 설명은 아래 영상을 참고하시기 바랍니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Backward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-backward.html#backpropagation",
    "href": "ANN-backward.html#backpropagation",
    "title": "8  Backward Propagation",
    "section": "8.2 Backpropagation",
    "text": "8.2 Backpropagation\n역전파 과정을 연쇄법칙을 수식 및 그래프를 활용하면 보다 직관적이고 쉽게 이해할 수 있습니다. 우선 합성함수2 Equation 8.1 의 식을 미분을 실행하며 예로 살펴보겠습니다,\n2 합성함수의 미분은 함성함수를 구성하는 각 함수의 미분의 곱으로 표현가능\n\\begin{align}\nz &= t^2 \\\\\nt &= x+y\n\\end{align}\n\\tag{8.1}\nx에 대한 z의 미분인 \\frac{\\partial{z}}{\\partial{x}}은 \\frac{\\partial{z}}{\\partial{t}}과 \\frac{\\partial{t}}{\\partial{x}}의 곱으로 나타낼 수 있습니다. 그리고 \\partial{t}를 서로 지울 수 있습니다.\n\n\\begin{align}\n\\frac{\\partial{z}}{\\partial{x}} &= \\frac{\\partial{z}}{\\partial{t}}\\frac{\\partial{t}}{\\partial{x}} \\\\\n&= \\frac{\\partial{z}}{\\not{\\partial{t}}}\\frac{\\not{\\partial{t}}}{\\partial{x}}\n\\end{align}\n\\tag{8.2}\n연쇄법칙을 써서 \\frac{\\partial{z}}{\\partial{x}}를 구하기 위하여 편미분을 실시하고, 두 미분값을 곱하여 최종 미분값을 산출합니다.\n\n\\begin{align}\n\\frac{\\partial{z}}{\\partial{t}} &= 2t \\qquad\n\\frac{\\partial{t}}{\\partial{x}} = 1 \\\\ \\\\\n\\frac{\\partial{z}}{\\partial{x}} &= \\frac{\\partial{z}}{\\partial{t}}\\frac{\\partial{t}}{\\partial{x}} =\n2t \\cdot 1 = 2(x+y)\n\\end{align}\n\\tag{8.3}\nEquation 8.3 를 그래프로 나타내어 연쇄법칙을 나타내봅시다. Figure 8.1 에서 보는 바와 같이 오른쪽에서 왼쪽으로 신호를 전달(전파) 합니다. 전파의 과정에서 입력값에 해당하는 편미분값을 곱하여 다음 노드에 전달함을 확인 할 수 있습니다.\n\n\n\n\n\n\nFigure 8.1: Multiplying the partial derivative of Equation 8.3 and passing it on\n\n\n\nFigure 8.1 과 같은 과정에 Equation 8.3 의 미분값을 대입하면 Figure 8.2 와 같은 결과를 얻을 수 있습니다.\n\n\n\n\n\n\nFigure 8.2: The process of showing backpropagation results\n\n\n\n\n8.2.1 Backpropagation of Addition Nodes3\n먼저 z=x+y를 갖고 덧셈노드에 대한 역전파를 살펴보겠습니다. 먼저 이 식에 대한 미분을 해석적으로 구하면 \\frac{\\partial{z}}{\\partial{x}}와 \\frac{\\partial{z}}{\\partial{y}} 모두 1이 됩니다.\nFigure 8.3 4 의 그래프를 기준으로 역전파5 과정을 살펴봅시다.\n4 본 예시는 하나의 전체 과정이 아니라 전체 중 일부를 띄어내어 표시한 예로 생각해야 합니다.5 역전파는 순방향과 반대방향으로 국소적 미분(편미분)값을 곱하는 방법으로 수행상류에서 산출한 편미분 값(\\frac{\\partial{L}}{\\partial{z}})을 x간선의 경우 \\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{x}}의 꼴로 역전파가 이루어 지고, y간선의 경우 \\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{y}}의 꼴로 역전파가 이루어 집니다.\nFigure 8.3 는 덧셈의 역전파 이므로 \\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{x}}=\\frac{\\partial{L}}{\\partial{z}}\\cdot1과 \\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{y}}=\\frac{\\partial{L}}{\\partial{z}}\\cdot1로 변형됨으로 입력된 값 그대로 다음 노드에 전달되게 됩니다.\n\n\n\n\n\n\n\n\n\n\nFigure 8.3: Examples: Backpropagation of Addition Nodes\n\n\n\n\n3 덧셈노드에 대한 역전파는 매개변수 중 편향을 타깃으로 함6 곰셈노드에 대한 역전파는 매개변수 중 가중치를 타깃으로 함\n8.2.2 Backpropagation of Multiplication Nodes6\n다음으로 z=xy를 갖고 곱셈노드에 대한 역전파를 살펴보겠습니다. 먼저 이 식에 대한 미분을 해석적으로 구하면 \\frac{\\partial{z}}{\\partial{x}} = y와 \\frac{\\partial{z}}{\\partial{y}} = x가 됩니다.\nFigure 8.4 의 그래프를 기준으로 역전파 과정을 살펴봅시다.\n상류에서 산출한 편미분 값(\\frac{\\partial{L}}{\\partial{z}})을 x간선의 경우 \\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{x}}=\\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{x}}=\\frac{\\partial{L}}{\\partial{z}}\\cdot y의 꼴로 역전파가 이루어 지고, y간선의 경우 \\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{y}}=\\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{y}}=\\frac{\\partial{L}}{\\partial{z}}\\cdot x의 꼴로 역전파가 이루어 집니다.\nFigure 8.3 는 곱셈의 역전파는 서로 바꾼값을 곱하여 하류로 흘려 보내게 됨을 확인할 수 있습니다.\n\n\n\n\n\n\n\n\n\n\nFigure 8.4: Examples: Multiplication of Addition Nodes\n\n\n\n\n\n\n\n\n\n편미분과 그라디언트\n\n\n\n\n신경망의 학습을 위한 역전파 과정은 모든 독립변수에 대한 편미분을 통하여 기울기를 구하게 됨\n대부분의 경우 이를 간단하게 표현하기 위하여 \\del연산자를 쓰고있음\n편미분을 통한 가중치(\\omega)의 업데이트 과정을 통상 아래와 같이 표현함\n\n\n\\omega = \\leftarrow \\omega - \\alpha \\del_{\\omega} \\epsilon",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Backward Propagation</span>"
    ]
  }
]