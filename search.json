[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DeepLearning x 101",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "DeepLearning x 101",
    "section": "Welcome",
    "text": "Welcome\n최근 전세계적으로 AI에 대한 관심이 증가하고 있습니다. 특히 OPEN AI의 Chat-GPT를 시작으로 다양한 생성형 AI가 발표되고 있습니다다.\n이러한 AI 발전의 기초가되는 기술은 Machinelearning과 Deeplearning이 있습니다. 이중 가장 기초가 되는 Deeplearning을 활용하여 Data에서 사람이 찾을 수 없는 Features와 Patterns을 기계를 활용하여 찾기 위한 기술을 학습하고자 합니다.\n이 사이트는 앞서 말한바와 같이 날로 중요해지는 Deeplearning에 대한 기초적인 이해부터 구현까지 학습하는 과정에 대한 기록물입니다. 나아가 Deeplearning기술을 활용하여 금융분야에 활용할 수 있는 방법을 연구하거나, 현재 다양한 금융공학의 기술과 접목시키고자 합니다.\n또한, Deeplearning과 관련된 사항들 수식과 이론에 기반하여 기초적인 사항들을 가급적 빠짐없이 다룰 예정입니다. 또한, Deeplearning과 관련된 내용을 ’engineering’관점에서 실제 기능을 구현하기 위한 코드를 포함할 예정이며, 이러한 소스 코드를 통해 이해의 폭을 높이고자 합니다. 물론 모든 코드와 그에 따른 결과는 매 페이지에서 확인할 수 있습니다.\n\n\n\n\n\n\nNote\n\n\n\n본 사이트는 Quarto를 기반으로 작성되었으며 실습환경에 관하여는 Table 1 을 참고하기 바랍니다. 본 사이트 구축에 관한 소스 코드는 GitHub에서 확인할 수 있습니다.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#disclaimer",
    "href": "index.html#disclaimer",
    "title": "DeepLearning x 101",
    "section": "Disclaimer",
    "text": "Disclaimer\n이 사이트는 모두에게 무료이며, “Deep Learning from Scratch”를 기반으로 학습자들이 연구한 내용을 담고 있습니다. 모든 내용에 대하여 출처를 밝힐 예정이나, 간혹 출처가 빠져 있는 경우 지속적으로 업데이트 하여, 원작자들의 권리를 침해하지 않고 오류를 수정해 나갈 것입니다.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Learning Path\n필자들의 DL 학습배경에 따라 아래의 경로로 DL을 학습할 계획이며 많은 문헌에서 다루고 있는 학습경로 입니다.\n학습경로가 정확한지? 적절한지? 알 수 없지만, 적어도 A to Z의 관점에서 빠짐없이 모든 내용을 학습해보기로 하였습니다.\n학습경로에 관한 내용은 Figure 1 을 참고하기 바라며, 학습을 수행하는 과정마다 변경되거나 추가되는 사항은 지속적으로 반영해 나갈 예정입니다.\nflowchart LR\n  per[Perceptron]:::ch --&gt; per1[Classification]\n  per --&gt; per2[Logistic Regression]\n\n  per1 --&gt; per_l1{{Lab1: Classification}}:::lab\n\n  ann(Artificial Neural Net):::ch --&gt; ann1[Intro of ANN] & ann2[Activation Function] & ann3[Forward Propagation] & ann4[Learning Process] & ann5[Back Propagation]\n\n  ann1 & ann2 & ann3 & ann4 --&gt; ann_l{{Lab2: Classification with MNIST}}:::lab\n\n  classDef ch fill:#ccccff\n  classDef lab fill:#ccffcc\n\n\n\n\nFigure 1: Learning Path",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#environment",
    "href": "intro.html#environment",
    "title": "Introduction",
    "section": "Environment",
    "text": "Environment\n우리가 학습하며 사용한 실습환경에 대하여 간단하게 소개하겠습니다.\n누구나 접근이 가능한 Python을 기반으로 하고 있고, 실습에 사용하는 라이브러리(Table 1 )는 의존도를 최소화 하기 위하여 numpy를 주로 사용하였습니다. 그리고 실습결과를 도식화하기 위하여는 matplotlib을 사용하였습니다.\n이론에 대한 충분한 실습을 완료한 뒤에는 tensorflow 또는 torch를 사용하기로 하였습니다. 이는 NVIDIA의 GPU를 활용하여 보다 Deep한 신경망을 구현하기 위함임을 참고하여 주시고 학습과정에서 본 Framework의 사용은 최소화 할 예정입니다.\n학습경로와 마찬가지로 아래의 테이블에 적시된 라이브러리와 그 버전은 수시로 업데이트 할 예정입니다.\n\n\n\n\n\n\nName\nVersion\n\n\n\n\nnumpy\n#.#.#\n\n\nmatplotlib\n#.#.#\n\n\ntensorflow\n#.#.#\n\n\ntorch\n#.#.#\n\n\n\n\n\nTable 1: List of Packages",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#how-to-read",
    "href": "intro.html#how-to-read",
    "title": "Introduction",
    "section": "How to read",
    "text": "How to read\n이 사이트에서 다루는 내용은 기본적인 이론에 대한 설명과 이와 관련된 코드와 그 실행 결과 들을 보여줄 것입니다.\nCode Example\n\n기본적으로 코드는 아래의 Code Block에서 모든 내용을 표시하였습니다.\n특별히 중요하거나 추가적인 설명이 필요한 경우 Code Annotation에 표시하였습니다.\n\n\n\n\nListing 1: Code Block\n\n\n\ndef add(num1, num2):\n1  result = num1 + num2\n  return  result\n\n\n1\n\nnum1과 num2를 더하여 result에 할당\n\n\n\n\n\n\n\nEquation Example\n\n수식 중 설명이 필요한 경우는 기본적으로 본문에 내용을 표시하였습니다.\n설명이 완료된 수식 중 참고할 사항은 margin컬럼에 표시였습니다.\n\n\n\n\nListing 2: Equation\n\n\n\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\n\n\n\n\n\nWe know from the first fundamental theorem of calculus that for x in [a, b]:\n\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\nCallout Example\n\n학습을 진행해 가는 과정에서 나오는 이슈사항은 Callout으로 표시해 두었습니다,\n각 Callout이 담아야 할 내용은 아래를 참고하여 주시기 바랍니다.\n\n\n\n\nListing 3: Callout\n\n\n\n\n\n\n\n\nNote의 활용법\n\n\n\n\n본문의 내용과 직접관련된 내용으로 부가적인 설명을 담고 있습니다.\n관련 문헌이나 자료들에서 중요한 부분을 발췌한 내용을 담고 있습니다.\n필자가 보다 효율적이라고 판단한 내용들을 보여주고자 합니다.\n\n\n\n\n\n\n\n\n\nTip의 활용법\n\n\n\n\n본문의 내용과 직접관련 없지만 알아두면 좋은 내용을 담고 있습니다.\n코드의 작성방법 등 유용한 정보를 답고 있습니다.\n실습과정에서 발견한 문제의 해결방법을 보여주고자 합니다.\n\n\n\n\n\n\n\n\n\nWarning의 활용법법\n\n\n\n\n이해하기 어려운 내용에 대하여 그 문제를 적시하고자 합니다.\n실습과정에서 경험한 문제 및 해결되지 않은 오류 등을 적시하고자 합니다.\n해결이 완료된 경우 note 또는 tip으로 전환될 수 있습니다.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "perceptron-intro.html",
    "href": "perceptron-intro.html",
    "title": "1  Perceptron",
    "section": "",
    "text": "1.1 What is a ‘Perceptron’?\n퍼셉트론은 인공신경망의 가장 기초가 되는 개념이고 이를 이해하기 위하여 생물학적 신경망의 가장 기초가 되는 뉴런(Figure 1.1)에 대하여 이해할 필요가 있습니다.\n뉴런의 구조는 다양하게 하지만 우리가 집중하고자 하는 곳은 크게 3가지 부분으로 구성되어 있습니다.\n여기서 주목할 것은 뉴런은 정보를 입력받아 내부적인 신호를 생성하여 다음 뉴런에 정보를 전달한 다는 것입니다.\n이러한 뉴런의 작동기전을 모방하여 만들어진 것이 퍼셉트론(Figure 1.2)입니다.\n퍼셉트론은 1957년 프랑크 로젠블라트가 제안한 것으로 퍼셉트론은 이러한 뉴런의 작동기전을 모방하여 정보를 입력(Input)받아 연산을 통해 출력(Output)을 생성하도록 설계되었습니다.\n이러한 정보의 흐름 또는 연산 절차를 다른 말로 Forward Propagation이라 합니다, 향후 논의 될 Back Propagation과 대비되는(?) 개념입니다.\nflowchart LR\n  subgraph node\n    direction LR\n    node2_1((SUM)) --&gt; node2_2((STEP))\n  end\n  node1_1((x_1)) --w1--&gt; node2_1\n  node1_2((x_2)) --w2--&gt; node2_1\n  node2_2 --&gt; node3((y_hat))\n\n\n\n\nFigure 1.2: Basic of Perceptron\nFigure 1.2 에서 원은 노드(Node)라고 하면 노드간 연결된 선을 엣지(Edge)라고 합니다. 엣지상에 존재하는 w는 가중치(Weight)하고 합니다.\n첫번째 노드의 x_1과 x_2는 입력값을 말하고, 두번째 노드는 내부적으로 SUM과 STEP으로 구성된 활성함수를 말하며, 마지막 노드의 z는 출력값으로 노드의 활성 정도를 말합니다.\n노란색 노드에서는 2단계 계산이 발생합니다. 하나늗 입력값의 뉴런에서는 신호의 세기를 계산하는 Weighted Sum(Equation 1.1) 과 뉴런의 여부를 계산하는 Step Function(Equation 1.2) 으로 구성되어 있습니다.\n결과적으로 퍼셉트론의 출력값(\\hat{y}=h_{w,b}(x)=sign(\\textbf{w}^{T}\\textbf{x}+b))은 (-1, 0, 1)로 3가지를 갖게 됩니다. 이 결과값을 실제의 값(y)와 비교(Loss Function)하여 가중치(w)를 업데이트 하여 최적해가 아닌 단순 solution(?)을 찾는 것이 퍼셉트론입니다.\nz = b + w_{1}x_{1} + w_{2}x_{2} + \\cdots + w_{n}x_{n} = b + \\textbf{w}^{T} \\textbf{x}\n\\tag{1.1}\nstep(z) = sign(z) = \\begin{cases}\n-1 & z &lt; 0 \\\\\n0 & z = 0 \\\\\n1 & z &gt; 0\n\\end{cases}\n\\tag{1.2}",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#what-is-a-perceptron",
    "href": "perceptron-intro.html#what-is-a-perceptron",
    "title": "1  Perceptron",
    "section": "",
    "text": "외부 자극등 정보를 수신하는 수상돌기(Dendrite)\n수신된 정보를 신호를 만들어 내는 핵(Nucleus)\n신호를 신경절달 물질로 만들어 내는 축삭돌기(Axon)+시넵스(Synapse)\n\n\n\n\n\n\n\n\nFigure 1.1: Structure of Neuron (source: Wikipedia)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n퍼셉트론에서 사용되는 계단함수\n\n\n\n일반적으로 Sign function을 가장 많이 사용하지만, 이진값(0, 1)만을 갖는 Heavisde step function이 사용되기도 합니다. Clsiffication 문제에서 직선상의 Observation값은 0 , Weight와 같은 방향은 1, 다른 방향은 -1로 처리하는 것이 보다 용이하기에 우리는 Sign function을 주로 사용합니다.\n\nheavisde(z) = \\begin{cases}\n0 & z &lt; 0 \\\\\n1 & z &gt;= 0\n\\end{cases}",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#bit-wise-operator단순-논리-회로",
    "href": "perceptron-intro.html#bit-wise-operator단순-논리-회로",
    "title": "1  Perceptron",
    "section": "1.2 Bit-wise operator(단순 논리 회로)",
    "text": "1.2 Bit-wise operator(단순 논리 회로)\n앞서 보았던 퍼셉트론을 분류(Classification)을 수행해보며 보다 자세하게 살펴보겠습니다. 특히 분류의 문제는 향후 ANN 및 CNN 등 다양한 문제를 해결하는데 사용되는 기법으로 향후 학습을 진행하면서 병렬적으로 작동기전에 대하여 비교하기가 용이할 것으로 생각됩니다.\n분류문제 중 가장 간단한 예시로 Bit-wise operator(단순 논리 회로)에 대한 내용을 살펴보겠습니다. 논리회로는 0과 1로 구분된 2개의 input을 받아 0또는 1을 output으로 출력하는 회로입니다.\n단순 논리 회로는 AND, NAND, OR 그리고 XOR게이트로 구성되어 있으며 입력에 따른 출력이 다음의 진리표(Table 1.1 )로 나타낼 수 있습니다.\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n0\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n1\n1\n1\n\n\n\n\n\n(a) AND gate\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n1\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n1\n1\n0\n\n\n\n\n\n(b) NAND gate\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n0\n\n\n1\n0\n1\n\n\n0\n1\n1\n\n\n1\n1\n1\n\n\n\n\n\n(c) OR gate\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n0\n\n\n1\n0\n1\n\n\n0\n1\n1\n\n\n1\n1\n0\n\n\n\n\n\n(d) XOR gate\n\n\n\n\n\n\n\nTable 1.1: 게이트별 진리표",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#perceptron-으로-구현",
    "href": "perceptron-intro.html#perceptron-으로-구현",
    "title": "1  Perceptron",
    "section": "1.3 Perceptron 으로 구현",
    "text": "1.3 Perceptron 으로 구현\n위의 진리표(Table 1.1 )의 내용을 퍼셉트론으로 구현해보겠습니다. 이를 위해 AND게이트를 예를 들도록 하겠습니다.\nAND게이트는 x_1 과 x_2가 모두 1인 경우 y를 1로 출력하는 논리 회로 입니다. 이를 퍼셉트론으로 표현하면 w_1, w_2, \\theta로 표현할 수 있고 이러한 선형판별식(Equation 1.3) 식은 아래와 같습니다.\n\n\n\ny = \\begin{cases}\n0 & w_1*x_1 + w_2*x_2 \\leq \\theta \\\\\n1 & w_1*x_1 + w_2*x_2 &gt; \\theta  \n\\end{cases}\n\\tag{1.3}\n위의 선형판별식은 아래와 같이 그림으로 표현이 가능합니다. 다만, 가중치 w 와 임계치 \\theta 의 조합은 무수히 많이 존재함을 유의해야 합니다.((?fig-egAndGate ) 의 적색선은 임의로 표현한 직선이고 이 직선이 무수히 많다는 의미)\n\n\n\n\n\n\n\n\nFigure 1.3: AND gate\n\n\n\n\n\n단순 논리 회로(XOR게이트 제외)의 선형판별식을 코드로 구현하면 다음과 같습니다. 여기서 일반적으로 향후 Deeplearning의 표현방법을 따라 임계치인 \\theta 를 편향(bias)인 -b로 치환한 수식을 사용하겠습니다.\n\n\n\ny = \\begin{cases}\n0 & b + w_1*x_1 + w_2*x_2 \\leq 0 \\\\\n1 & b + w_1*x_1 + w_2*x_2 &gt; 0\n\\end{cases}\n\\tag{1.4}\n변형된 수식(Equation 1.4 )에 기초하여 진리표(Table 1.1 )상의 게이트를 코드로 구현하면 아래와 같습니다.\n\n1import numpy as np\n\n# AND gate\ndef AND(x1, x2):\n  x = np.array([x1, x2])\n2  w = np.array([0.5, 0.5])\n  b = -0.7\n3  tmp = np.sum(w*x) + b\n  if tmp &lt;= 0:\n    return 0\n  elif tmp &gt; 0:\n    return 1\n\n# NAND gate\ndef NAND(x1, x2):\n  x = np.array([x1, x2])\n  w = np.array([-0.5, -0.5])\n  b = 0.7\n  tmp = np.sum(w*x) + b \n  if tmp &lt;= 0:\n    return 0\n  elif tmp &gt; 0:\n    return 1\n\n# OR gate\ndef OR(x1, x2):\n  x = np.array([x1, x2])\n  w = np.array([0.5, 0.5])\n  b = -0.7\n  tmp = np.sum(w*x) + b \n  if tmp &lt;= 0:\n    return 0\n  elif tmp &gt; 0:\n    return 1\n\n\n1\n\nVector 연산의 최적화를 위하여 numpy를 기본적으로 사용한다.\n\n2\n\nw와 b는 임의로 할당한다. 다만, NAND 및 OR 는 AND의 부호와 다름에 주의하자.\n\n3\n\nweighted sum은 가중치를 곱하여 더한 값으로 내적과 유사함을 유의하자.",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#mlp",
    "href": "perceptron-intro.html#mlp",
    "title": "1  Perceptron",
    "section": "1.4 MLP",
    "text": "1.4 MLP\n다중 퍼셉트론은 퍼셉트론이 여러층으로 구현된 형태를 말합니다. 층을 여러개 쌓아서 보다 복잡한 문제를 해결할 수 있고, 추후 Deeplearning에서 여러층의 신경망을 쌓는 방식의 기초라고만 이해해 두겠습니다.\n앞서 1층 퍼셉트론으로는 단순 논리 회로 중 선형적인 게이트만을 구현할 수 있었습니다. 그렇다면 XOR게이트는 해결할 수 없을까요? 이를 해결하기 위한 것이 다층 퍼셉트론 입니다.\n가령 XOR게이트 문제를 NAND와 OR게이트를 조합한 출력값을 AND게이트의 입력값으로 받게 된다면 XOR게이트를 구현할 수 있습니다. 국소적인 문제해결을 결합하여 전체 문제를 해결하는 방식으로 이해됩니다.\n\n\n\n\n\n\nflowchart LR\n  x1((x1)) & x2((x2)) ---&gt; nand[NAND] & or[OR] \n  nand --s1---&gt; AND ---&gt; y[y]\n  or --s2---&gt; AND\n\n\n\n\nFigure 1.4: XOR Gate: Composition of NAND, OR, AND\n\n\n\n\n\nXOR의 게이트를 다른 게이트의 조합을 활용한 진리표는 아래와 같습니다. 위의 그림에서 보듯이 x1과 x2의 입력값을 받아 NAND게이트는 s1의 출력값을 OR게이트는 s2의 출력값을 생성하며, 다시 s1과 s2를 입력값으로 받아 AND를 통과시켜 최종적으로 XOR게이트의 진리표를 다시 그릴 수 있습니다.\n\n\n\n\n\n\nx_1\nx_2\ns_1\ns_2\ny\n\n\n\n\n0\n0\n1\n0\n0\n\n\n1\n0\n1\n1\n1\n\n\n0\n1\n1\n1\n1\n\n\n1\n1\n0\n1\n0\n\n\n\n\n\nTable 1.2: XOR게이트의 진리표\n\n\n\n위의 진리표(Table 1.2 )를 코드로 구현하면 아래와 같습니다. 앞서 구현한 게이트들을 코드내에서 사용하여 단순하게 구현할 수 있습니다.\n\ndef XOR(x1, x2):\n  s1 = NAND(x1, x2)\n  s2 = OR(x1, x2)\n  y = AND(s1, s2)\n  return y",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#wrap-up",
    "href": "perceptron-intro.html#wrap-up",
    "title": "1  Perceptron",
    "section": "Wrap up",
    "text": "Wrap up\n지금까지 퍼셈트론에 대하여 살펴 보았습니다. 단순히 퍼셥트론이 뭐다라는 단순한 이야기 이지만, 딥러닝에 있어 가장 기초가 되는 부분입니다. 다만, 퍼셉트론 자체를 더 깊이 알아보기 보다 하나의 뉴런이 여러개의 뉴런이 되는 MLP(Multi-Layers Perceptron)가 여러개의 층으로 이루어 지는 NN(Neural Network)으로 발전된다 정도로 이해해 보도록 하겠습니다.\n자세한 사항은 다음장에서 여러개의 뉴런들이 층을 이루는 인공신경망(ANN, Articial Neural Network)에서 설명하도록 하며 주요 주제는 아래와 같습니다.\n\nActivation function & Forward Propagation\nLoss Function(Loss Optimization) & Back Propagation\nNN in Practice: Adaptive Learning, Mini-batches, Overfitting(Regularization)\n\n이후 ANN을 Foundation으로 Sequential Data Modelling을 위한 RNN 및 이미 처리를 위한 CNN 등에 대하여 학습할 예정입니다.",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-lab_classification.html",
    "href": "perceptron-lab_classification.html",
    "title": "2  Lab: Classification with Perceptron",
    "section": "",
    "text": "2.1 Classification\n우리가 실습할 분류 문제는 선형 판별 분석(LDA, Linear Discriminant Analysis)입니다. 수치형 입력변수를 받아 범주형 타겟 변수를 예측하는 분류 방법으로 퍼셈트론을 활용하여 해결하기 좋은 문제 입니다.\nFigure 2.1: Example of LDA\n위 산점도(Figure 2.1 )와 같은 산점도에서 C1과 C0을 구분하는 문제를 퍼셉트론을 이용하여 해결해 보겠습니다.\n전장에서 살펴본 퍼셉트론(Figure 1.2)에 따라 설명하고자 합니다. 우선 입력받는 변수는 x, 가중치는 \\omega로 둘수 있습니다.\n\\begin{align}\nx = \\begin{bmatrix}x_1\\\\ \\vdots\\\\ x_d \\end{bmatrix} \\qquad\n\\omega = \\begin{bmatrix}\\omega_1\\\\ \\vdots\\\\ \\omega_d \\end{bmatrix}\n\\end{align}\n\\tag{2.1}\n여기서 Weighted Sum의 결과가 특정 임계치(\\theta)를 초과하는 지에 따라 클래스1(C_1) 또는 클래스0(C_0)으로 구분하고자 합니다.\n\\begin{align}\nC_1 \\quad if\\, \\sum_{i=1}^{d}\\omega_{i}x_{i} &gt; \\theta \\\\\nC_0 \\quad if\\, \\sum_{i=1}^{d}\\omega_{i}x_{i} &lt; \\theta\n\\end{align}\n\\tag{2.2}\n이를 다시 Step function을 활용하여 Figure 1.2 의 노란색 박스(h(x))에 해당하는 노드를 다음의 식으로 변형하여 표현할 수 있습니다.\n여기서 임계치(\\theta)는 편향에 해당하는 값으로 변형하고 이를 다시 입력변수 \\omega_0으로 간단하게 표현할 수 있습니다.\n\\begin{align}\nh(x) &= \\text{sign} \\left(\\left( \\sum\\limits_{i=1}^{d}\\omega_ix_i \\right)- \\theta \\right) \\\\\n&= \\text{sign}\\left(\\left( \\sum\\limits_{i=1}^{d}\\omega_ix_i \\right)+ \\omega_0\\right)\n\\end{align}\n\\tag{2.3}\n\\omega_0=1로 두고 이를 벡터 형식(vector form)으로 표현하고, Step function을 Sign function으로 정의하면 아래와 같이 식을 수정할 수 있습니다.\n\\begin{align}\nh(x) &= \\text{sign}(\\sum_{i=0}^{d}\\omega_{i}x_{i})\n=\\text{sign}(\\omega^{T}x) \\\\\n\\text{sign}(x) &= \\begin{cases}\n1, &\\text{if }\\; x &gt; 0\\\\\n0, &\\text{if }\\; x = 0\\\\\n-1, &\\text{if }\\; x &lt; 0\n\\end{cases}\n\\end{align}\n\\tag{2.4}\nPerceptron Learning Algorithm(PLA)\n위의 식을 실제 퍼셉트론에 적용하기 위하여 위 산점도(Figure 2.1 )의 개별 값들을 활용하여 \\text{sign}(\\omega^Tx_n) = \\hat{y}_n을 산출하여 실제 라벨(y_n)과 비교하며 두 라벨값이 다를 경우 \\omega를 업데이트 하도록 합니다.\n\\begin{align}\n\\omega \\leftarrow\n\\begin{cases}\n\\omega+y_nx_n & \\hat{y_n} \\neq y_n \\\\\n\\omega &\\hat{y_n} = y_n \\\\\n\\end{cases}\n\\end{align}\n\\tag{2.5}\n위의 절차를 Training Set을 이용하여 Iterative하게 반복하여 \\omega를 업데이트 하도록 하여 PLA를 수행합니다.\nPerceptron Loss Function\nPLA를 수행하는 과정에서 학습을 종결시키기 위하여 Loss function이 필요합니다. 산출값 \\hat{y}_n과 y_n을 비교하여 Loss들의 합(\\mathscr{L}(\\omega))이 0이 되도록 하는 조건으로 설정할 수 있습니다.\n\\begin{align}\n\\mathscr{L}(\\omega) = \\sum_{n =1}^{m} \\max \\left\\{ 0, -y_n \\cdot \\left(\\omega^T x_n \\right)\\right\\}\n\\end{align}\n\\tag{2.6}",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lab: Classification with Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-lab_classification.html#solving-with-perceptron-algorithm",
    "href": "perceptron-lab_classification.html#solving-with-perceptron-algorithm",
    "title": "2  Lab: Classification with Perceptron",
    "section": "2.2 Solving with perceptron algorithm",
    "text": "2.2 Solving with perceptron algorithm\n위에서 살펴본 내용을 이제 코드로 작성해 보겠습니다. 기본적인 입력변수 x를 x1과 x2로 라벨값 y를 C1과 C0로 생성하였습니다. 그에 따른 산점도 데이터는 아래와 같습니다.\n\n#training data gerneration\nm = 100\nx1 = 8*np.random.rand(m, 1)\nx2 = 7*np.random.rand(m, 1) - 4\n\ng = 0.8*x1 + x2 -3\n\nC1 = np.where(g &gt;= 1)[0]\nC0 = np.where(g &lt; -1)[0]\n\n\n\n\n\n\nLinearly Separable Classes with no dicision boundary\n\n\n\n\n각각의 입력값을 numpy로 연산할 수 있도록 Vectorize를 진행합니다.\n\n\\begin{align}\nx &= \\begin{bmatrix} \\left(x^{(1)}\\right)^T \\\\ \\left(x^{(2)}\\right)^T \\\\ \\left(x^{(3)}\\right)^T\\\\ \\vdots \\\\ \\left(x^{(m)}\\right)^T \\end{bmatrix} = \\begin{bmatrix} 1 & x_1^{(1)} & x_2^{(1)} \\\\ 1 & x_1^{(2)} & x_2^{(2)} \\\\ 1 & x_1^{(3)} & x_2^{(3)}\\\\\\vdots & \\vdots & \\vdots \\\\ 1 & x_1^{(m)} & x_2^{(m)}\\end{bmatrix} \\\\\ny &= \\begin{bmatrix}y^{(1)} \\\\ y^{(2)} \\\\ y^{(3)}\\\\ \\vdots \\\\ y^{(m)} \\end{bmatrix}\n\\end{align}\n\n\nX1 = np.hstack([np.ones([C1.shape[0],1]), x1[C1], x2[C1]])\nX0 = np.hstack([np.ones([C0.shape[0],1]), x1[C0], x2[C0]])\n\nX = np.vstack([X1, X0])\ny = np.vstack([np.ones([C1.shape[0],1]), -np.ones([C0.shape[0],1])])\n\nX = np.asmatrix(X)\ny = np.asmatrix(y)\n\n가중치 \\omega를 1로 초깃값을 설정하고, 각각의 입력값을 이용하여 PLA를 실행하며 가중치 업데이트(\\omega \\leftarrow \\omega + yx)를 실행합니다.\n\nw = np.ones([3,1])\nw = np.asmatrix(w)\n\nn_iter = y.shape[0]\nflag = 0\n\nwhile flag == 0:\n    flag = 1\n    for i in range(n_iter):\n        if y[i,0] != np.sign(X[i,:]*w)[0,0]:\n            w += y[i,0]*X[i,:].T\n            flag = 0\n\n위의 절차를 실행하여 산출한 결정 경계(Dicision Boundary)는 아래와 같습니다.\n\n\n\n\n\nLinearly Separable Classes with dicision boundary\n\n\n\n\n\n\n\n\n\n\nPerceptron과 최적화의 문제\n\n\n\n\n여기서 중요한 것은 퍼셉트론은 구분하는 경계 산출에 촛점을 두고 있으므로 우리가 예상하는 최적 경계에 해당하지 않을 수 있습니다.\n가령 최적 경계는 두 그룹의 중간쯤 위치해야 할 것으로 생각이 됩니다. 그래야 향후 입력값이 추가 되었을 때 경계가 유효할 가능성이 높기 때문입니다.\n이를 해결하기 위하여는 내적을 통한 거리의 개념이 들어가고, Loss Function도 Logistic Regression의 방법으로 해결해야 하지 않을까라고 예상할 수 있습니다.",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lab: Classification with Perceptron</span>"
    ]
  },
  {
    "objectID": "ANN-intro.html",
    "href": "ANN-intro.html",
    "title": "3  Artificial Neural Networks",
    "section": "",
    "text": "인공신경망(ANN, Artificial Neural Networks)은 퍼셉트론과 유사한 메커니즘을 갖고 있습니다. Figure 4.1 에서 가장 왼쪽이 입력층(Input), 중간이 은닉층(Hidden), 가장 오른쪽이 출력층(Output)으로 구성되어 있습니다.\n\n\n\n\n\n\ngraph LR\n  subgraph Input\n      direction LR\n      x1((x1)) & x2((x2)) \n  end\n  \n  subgraph Hidden\n      direction LR\n      h1((h1)) & h2((h2)) & h3((h3))\n  end \n\n  subgraph Output\n      direction LR\n      y1((y1)) & y2((y2))\n  end\n\n    x1((x1)) & x2((x2))  ---&gt; h1((h1)) & h2((h2)) & h3((h3))\n    h1((h1)) & h2((h2)) & h3((h3)) ---&gt; y1((y1)) & y2((y2))\n\n\n\n\nFigure 3.1: Example of ANN\n\n\n\n\n\n다만, 퍼셉트론과 다른 점이 있따면, 신호를 전달 받는 과정에서 편향에 해당하는 b가 명시적으로 존재하여 이 또한 신호로 처리한다는 부분입니다.\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n  x1((x1)) --w1---&gt; y((y))\n  x2((x2)) --w2---&gt; y\n\n\n\n\n(a) Perceptron\n\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n  x0((1)):::bias --b---&gt; y((y))\n  x1((x1))  --w1---&gt; y((y))\n  x2((x2))  --w2---&gt; y\n  classDef bias fill:#f96\n\n\n\n\n(b) ANN\n\n\n\n\n\n\n\n\n\nFigure 3.2: 퍼셉트론과 ANN의 비교\n\n\n\nFigure 3.2 에는 잘 나타나 있지 않지만 Perceptron의 경우 입력신호를 받아 y를 바로 출력하지만, ANN의 경우 입력신호와 가중치를 곱하여 총합을 산출하는 함수와 이 산출값을 이용하여 조건 분기의 동작(0을 넘으면 1을 출력하고 그렇지 않으면 0을 출력)을 나타내는 함수로 구성되어 있으며 이를 구현한 산식은 Equation 3.1 과 같이 나타낼 수 있다.\n\n\\begin{align}\n&y = h(b + w_{1}x_{1} + w_{2}x_{2}) \\\\ \\\\\n&h(x) =\n  \\begin{cases}\n  0 & (x \\leq 0) \\\\\n  1 & (x &gt; 1)\n  \\end{cases}\n\\end{align}\n\\tag{3.1}\n\n\n\n\n\n\n펴셉트론과 Deeplearning의 차이\n\n\n\n\n퍼셉트론에 사용되는 선형판별식에 가중치 및 임계치의 조합은 무수히 많고, 가중치 및 임계치는 인간이 설정해야 함. 결국 Domain Knowledge를 갖고 있어야 한다는 의미임\nDeeplearning의 경우 가중치 및 임계치를 컴퓨터가 학습하여 설정해게 됨\n또한. Activation Function의 경우 미분가능해야 하고, Loss Function의 결과 Back propagation의 활용하여 \\omega를 최적화하는 절차가 존재함",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Artificial Neural Networks</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html",
    "href": "ANN-activation.html",
    "title": "4  Activation Function",
    "section": "",
    "text": "4.1 Sigmoid Function\n시그모이드 함수(sigmoid function)는 계단함수와 달리 ’S자 모양’으로 Non-linear한 함수이고 그 식은 아래와 같습니다.\n\\begin{align}\nh(x) = \\frac{1}{1+exp(-x)}\n\\end{align}\n시그모이드 함수를 python 코드로 아래와 같이 간다하게 구현할 수 있습니다. 이를 활용하여 시그모이드 함수를 실행하면 아래와 같은 그래프(Figure 4.2 )를 볼 수 있습니다.\ndef sigmoid(x):\n  return 1 / (1 + np.exp(-x))",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html#sigmoid-function",
    "href": "ANN-activation.html#sigmoid-function",
    "title": "4  Activation Function",
    "section": "",
    "text": "Figure 4.2: Plot of Sigmoid Function",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html#relu-function",
    "href": "ANN-activation.html#relu-function",
    "title": "4  Activation Function",
    "section": "4.2 ReLU Function",
    "text": "4.2 ReLU Function\nReLU 함수(Rectified Linear Unit funcion)는 시그모이드를 넘어 최근에 많이 사용되는 함수 입니다. 입력값을 0을 넘으면 그 입력값을 그대로 출력하고 그 이하이면 0을 출력하는 함수로 그 식은 아래와 같습니다.\n\n\\begin{align}\nh(x) =\n\\begin{cases}\nx & (x &gt; 0) \\\\\n0 & (x \\leq 0)\n\\end{cases}\n\\end{align}\n\nReLU 함수를 python 코드로 아래와 같이 간다하게 구현할 수 있습니다. 이를 활용하여 시그모이드 함수를 실행하면 아래와 같은 그래프(Figure 4.3 )를 볼 수 있습니다.\n\ndef relu(x):\n  return np.maximum(0, x)\n\n\n\n\n\n\n\nFigure 4.3: Plot of ReLU Function",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html#others",
    "href": "ANN-activation.html#others",
    "title": "4  Activation Function",
    "section": "4.3 others",
    "text": "4.3 others\n위에 소개한 활성화 함수 외에도 많은 종류의 활성화 함수가 존재합니다. 이에 대하여 자세한 사항은 Wiki페이지를 참고하시기 바랍니다.\n학습을 진행하는 과정에서 필요한 내용들을 지속적으로 업데이트 할 예정입니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-forward.html",
    "href": "ANN-forward.html",
    "title": "5  Forward Propagation",
    "section": "",
    "text": "5.1 Layer-by-Layer signaling\n3층 신경망의 신호 전달과정은 아래와 같이 Weighted Sum에 기반하며 그 값을 다시 화성화 함수(가령 Sigmoid)를 통하여 노드의 값이 최종 산출됩니다.\n또한, 이전층의 값들을 받아 산출된 값은 다시 입력값으로 하여 다음층으로 전달되는 과정을 거쳐 최종적으로 출력층까지 이 과정을 반복하게 됩니다. 이 과정이 신호 전달 또는 Forward propagation 입니다.\ninput to hidden\n최초 입력층(0층)의 신호 전달 체계는 입력값(노드)은 2개인 1차원 배열이고 다음의 은닉층(1층)은 노드 3계로 이루어진 1차원 배열입니다. 2개의 노드 값을 받아 3개의 노드로 전달해야 하므로 노드간의 간선은 총 6개(6 = 2 \\times 3)입니다.\n입력값 및 편향값을 a에 전달하고 a값을 활성화 함수(Sigmoid 함수를 사용) h()를 이용하여 신호 z를 산출하도록 합니다. 결과적으로 은닉층(1층)에 해당하는 3개의 노드의 신호를 확인할 수 있습닏.\n# 입력값, 편향, 가중치\nX  = np.array([1.0, 0.5])\nB1 = np.array([0.1,0.2,0.3])\nW1 = np.array([[0.1,0.3,0.5], [0.2,0.4,0.6]])\n\n# Weighted Sum\nA1 = np.dot(X, W1) + B1\n\n# Activation Function\nZ1 = sigmoid(A1)\n\nprint(A1)\nprint(Z1)\n\n[0.3 0.7 1.1]\n[0.57444252 0.66818777 0.75026011]\nhidden to hidden\n은닉층(1층)이 다시 입력층으로 하여 다음의 은닉층(2층)으로 신호를 전달하도록 해야 합니다. 앞서 진행한 신호 전달 과정과 동일합니다.\n다만, 입력 노드가 편향을 포함하여 4개가 다음 층인 2개의 노드로 전달됨에 따라 이전 과정과 달리 간선은 총 8개 입니다. 편향은 2개 간선을 갖고 가중치는 입력 노드별 2개 총 6개로 이루어 집니다.\n# 편향, 가중치\nB2 = np.array([0.1,0.2])\nW2 = np.array([[0.1,0.4], [0.2,0.5], [0.3,0.6]])\n\n# Weighted Sum & Activation Function\nA2 = np.dot(Z1, W2) + B2\nZ2 = sigmoid(A2)\n\nprint(A2)\nprint(Z2)\n\n[0.51615984 1.21402696]\n[0.62624937 0.7710107 ]\nhidden to output\n은닉층(2층)이 다시 입력층으로 하여 다음의 출력층(3층)으로 신호를 전달하도록 해야 합니다. 앞서 진행한 신호 전달 과정과 동일합니다.\n주의할 것은 출력층의 경우 해결하고자 하는 문제의 성질에 맞게 설정되어야 합니다. 여기서는 입력되는 값을 그대로 출력하는 항등함수(Identity Function)알 사용하도록 하겠습니다.\n# 항등함수\ndef identity_function(x):\n  return x\n\n# 편향, 가중치\nB3 = np.array([0.1,0.2])\nW3 = np.array([[0.1,0.3], [0.2,0.4]])\n\n# Weighted Sum & Activation Function\nA3 = np.dot(Z2, W3) + B3\nY  = identity_function(A3) # Y = A3\n\nprint(Y)\n\n[0.31682708 0.69627909]\nWrap-up\n앞서 정리한 내용을 하나의 모듈로 작성하도록 하겠습니다. 이 신경망의 신호 전달 과정은 순방향의 연산 과정만을 익히기 위함이고 가장 처음에 실행되는 과정입니다.\n1def init_network():\n  network = {}\n  network['W1'] = np.array([[0.1,0.3,0.5], [0.2,0.4,0.6]]) # 입력2 출력3\n  network['b1'] = np.array([0.1,0.2,0.3])\n  network['W2'] = np.array([[0.1,0.4], [0.2,0.5], [0.3,0.6]]) # 입력3, 출력2\n  network['b2'] = np.array([0.1,0.2])\n  network['W3'] = np.array([[0.1,0.3], [0.2,0.4]]) # 입력2, 출력2\n  network['b3'] = np.array([0.1,0.2])\n\n  return network\n\n2def forward(network, x):\n  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n\n  a1 = np.dot(x, W1) + b1\n  z1 = sigmoid(a1)\n  a2 = np.dot(z1, W2) + b2\n  z2 = sigmoid(a2)\n  a3 = np.dot(z2, W3) + b3\n  y  = identity_function(a3)\n\n  return Y\n\nnetwork = init_network()\nx = np.array([1.0,5.0])\ny = forward(network, x)\n\nprint(y)\n\n\n1\n\n가중치와 편향을 초기화하고 이들을 닉셔너리 변수인 network에 저장\n\n2\n\n입력신호를 출력으로 변환하는 처리과정\n\n\n\n\n[0.31682708 0.69627909]",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-forward.html#layer-by-layer-signaling",
    "href": "ANN-forward.html#layer-by-layer-signaling",
    "title": "5  Forward Propagation",
    "section": "",
    "text": "(a) input-hidden\n\n\n\n\n\n\n\n\n\n\n\n(b) hidden-hidden\n\n\n\n\n\n\n\n\n\n\n\n(c) hidden-output\n\n\n\n\n\n\n\nFigure 5.2: Process of Forward Propagation(souce: Deeplearning from Scratch)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n출력층의 활성화 함수\n\n\n\n\n출력층의 활성화 함수는 문제의 성질에 맞춰야 한다고 하였습니다.\n문제의 성질은 크게 2가지로 나누어 볼 수 있는데 하나는 분류(classfication), 다른 하나나는 회귀(regression)입니다.\n각각의 문제에 맞는 활성화 함수는 다양하며 자세한 사항은 지속적으로 Chapter 4 에 내용을 추가하도록 하겠습니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-forward.html#disign-output-layer",
    "href": "ANN-forward.html#disign-output-layer",
    "title": "5  Forward Propagation",
    "section": "5.2 Disign Output layer",
    "text": "5.2 Disign Output layer\n신경망의 경우 통상 회귀의 경우 항등 함수를, 분류의 경우는 소프트맥스 함수(softmax function)를 사용합니다. 소프트맥스 함수의 식은 아래와 같습니다.\n\ny_k = \\frac{exp(a_k)}{\\sum^{n}_{i=1}exp(a_i)}\n\\tag{5.2}\n위 식에서 exp(x)는 e^x를 지수함수를 의미하며, n은 출력층의 뉴런수, y_k는 출력노드 중 k번째를 의미합니다. 분자는 k번째 출력노드의 값을 분모는 전체 출력노드의 합을 의미합니다.\n\n\n\n\n\nflowchart LR\n  subgraph h [\"sigma()\"]\n    direction LR\n    a1((a1)) & a2((a2)) & a3((a3))\n    y1((y1)) & y2((y2)) & y3((y3))\n  end\n\n  a1 & a2 & a3 ---&gt; y1 & y2 & y3\n\n\n\n\n\n\nCautions for implementing the Softmax function\nEquation 5.2 식을 코드로 구현하기 이전에 주의할 사항이 필요합니다.\n하나는 오퍼플로(overflow), 즉 컴퓨터의 특성상 너무 큰 수의 경우 Inf가 나오게 된다는 점입니다.\n이러한 문제를 해결하기 위하여 참고한 자료에는 임의 상수 C를 분모와 분자에 모두 곱해주는 방식으로 이 문제를 해결 할수 있다고 하며 C는 다시 exp의 지수항으로 옮기고 C'로 변경할 수 있습니다.\n\n\\begin{align}\ny_k = \\frac{exp(a_k)}{\\sum^{n}_{i=1}exp(a_i)} &= \\frac{C\\,exp(a_k)}{C\\,\\sum^{n}_{i=1}exp(a_i)} \\\\\n&= \\frac{exp(a_k+log C)}{\\sum^{n}_{i=1}exp(a_i+log C)} \\\\\n&= \\frac{exp(a_k+C')}{\\sum^{n}_{i=1}exp(a_i+C')}\n\\end{align}\n\\tag{5.3}\n위의 식에 따라 출력층에 사용할 소프트맥스 함수를 아래와 같이 구현할 수 있으며, 개선된 식의 C는 통상 입력값의 최대값으로 설정하도록 하겠습니다.\n\ndef softmax(a):\n  c = np.max(a)\n  exp_a = np.exp(a-c)\n  sum_exp_a = np.sum(exp_a)\n  y = exp_a / sum_exp_a\n\n  return y\n\na = np.array([0.3, 2.9, 4.0])\ny = softmax(a)\n\nprint(y)\n\nnp.sum(y)\n\n[0.01821127 0.24519181 0.73659691]\n\n\n1.0\n\n\n위이 함수를 실행하면 출력값의 총합은 1임을 알 수 있습니다. 이것은 출력된 개별 값들을 확률로 해석할 수 있음을 의미합니다. 다만, 지수합수인 exp()계산시 자원이 많이 소비됨에 따라 추론 단계에서는 소프트맥스 함수를 생랙하기도 한다고 합니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-forward.html#lab-number-recognition-with-mnist",
    "href": "ANN-forward.html#lab-number-recognition-with-mnist",
    "title": "5  Forward Propagation",
    "section": "5.3 Lab : Number recognition with MNIST",
    "text": "5.3 Lab : Number recognition with MNIST\n현재 우리가 진행하고 있는 과정은 학습과 추론 중 추론(inference)에 해당하는 순전파(forward propagation)입니다. 학습의 경우 역전파(back propagation)를 통하여 가중치를 업데이트 하나 추론의 경우는 설정된 가중치를 이용하여 문제를 해결하는 과정입니다.\n\n\n\n\n\n\nMNIST 데이터셋\n\n\n\nMNIST1 데이터셋은 기계 학습 분야에서 널리 사용되는 손으로 쓴 숫자 이미지 데이터셋입니다. 이 데이터셋은 0부터 9까지의 숫자를 손으로 쓴 28x28 픽셀 크기의 이미지로 구성되어 있습니다. 주로 숫자 인식 및 분류 알고리즘의 테스트 및 훈련에 사용됩니다.\n\n크기: 28x28 픽셀\n포맷: 흑백 이미지(1채널)\n이미지 개수: - 훈련 데이터: 60,000개 - 테스트 데이터: 10,000개\n픽셀 값 범위: 0부터 255까지\n\n\n\n1 ANN 및 CNN 까지 다양한 예제에 활용될 예정\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nimport numpy as np\nfrom dataset.mnist import load_mnist\nfrom PIL import Image\n\n# MNIST 데이터셋 로드\n(x_train, t_train), (x_test, t_test) = \\\n  load_mnist(\n1    flatten = True,\n2    normalize = False,\n3    one_hot_label = False\n    ) \n\ndef img_show(img):\n    pil_img = Image.fromarray(np.uint8(img))\n    pil_img.show()\n\nimg = x_train[0]\nlabel = t_train[0]\nprint(label)  # 5\n\nprint(img.shape)  # (784,)\nimg = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\nprint(img.shape)  # (28, 28)\n\nimg_show(img)\n\n\n1\n\nflatten은 28x28의 2D-배열을 784x1 1D배열로 만들지 말지 결정하는 변수\n\n2\n\nnormalize는 픽셀값의 범위를 기존 [0, 255]에서 [0.0, 1.0]으로 변환할지 말지를 결정하는 변수\n\n3\n\none_hot_label은 레이블의 값을 정수(False, 예:5)로 할지, 한 원소만을 1로 갖는 배열(True, 예:[0,0,0,0,0,1,0,0,0,0,0])로 할지 결정하는 변수\n\n\n\n\n5\n(784,)\n(28, 28)\n\n\n\n5.3.1 Inference processing\nANN을 활용하여 MNIST 데이터셋을 가지고 추론과정을 신경망으로 구현하면 아래와 같습니다. 입력층의 뉴런은 28\\times28의 데이터를 받아 Flatten하게 784개의 뉴런으로 갖도록 합니다. 그리고 출력층의 뉴런은 0~9까지 10개로 분류해야 하므로 10개의 뉴런을 갖도록 합니다.\n입력과 출력사이의 은닉층은 2개의 층으로 구성하도록 하고 각각 50개 100개의 뉴런을 갖도록 합니다. 은닉층의 뉴런의 갯수는 임의로 정한 것이고 본 사전에 학습된 \\omega 를 사용하여 추론의 정확도를 평가해 보도록 하겠습니다.\n\n# coding: utf-8\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nimport numpy as np\nimport pickle\nfrom dataset.mnist import load_mnist\nfrom common.functions import sigmoid, softmax\n\n\ndef get_data():\n    (x_train, t_train), (x_test, t_test) = load_mnist(\n4      normalize=True,\n      flatten=True, \n      one_hot_label=False)\n    return x_test, t_test\n\n\ndef init_network():\n    with open(\"dataset/sample_weight.pkl\", 'rb') as f:\n        network = pickle.load(f)\n    return network\n\n\ndef predict(network, x):\n    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n\n    a1 = np.dot(x, W1) + b1\n    z1 = sigmoid(a1)\n    a2 = np.dot(z1, W2) + b2\n    z2 = sigmoid(a2)\n    a3 = np.dot(z2, W3) + b3\n    y = softmax(a3)\n\n    return y\n\n\nx, t = get_data()\nnetwork = init_network()\naccuracy_cnt = 0\n1for i in range(len(x)):\n    y = predict(network, x[i])\n2    p= np.argmax(y)\n3    if p == t[i]:\n        accuracy_cnt += 1\n\nprint(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))\n\n\n1\n\nfor문 안에서 이미지 1장씩 꺼내어 predict()함수로 분류(0~9)를 실행하여 레이블의 확률을 Numpy 배열로 반환\n\n2\n\nnp.argmax로 반환된 레이블 배열에서 가장 높은 값(확률)의 인덱스를 산출\n\n3\n\n정답 레이블과 산출 레이블의 비교하여 일치하면 accuracy_cnt로 정답 갯수 업데이트\n\n4\n\nload_mnist함수의 인자 중 normalize가 True는 데이터를 0~1사이의 값으로 정규화 한다는 의미\n\n\n\n\nAccuracy:0.9352\n\n\n위의 과정을 통해 분류의 정확도는 93.52%임을 확인 할 수 있습니다. 이후에 이 정확도를 향상시키기 위한 신경망의 학습 등에 대하여 살펴볼 예정입니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-learning.html",
    "href": "ANN-learning.html",
    "title": "6  Learning process",
    "section": "",
    "text": "6.1 Loss Function\n손실함수는 인공신경에 입력되어 산출되는 값과 실제 값을 비교하여 정확도를 측정하는 하나의 지표라고 할 수 있다. ANN은 이러한 지표를 기준으로 최적의 가중치와 편향을 탐색하는 방식으로 학습을 진행합니다.\n손실함수로는 일반적으로 오차제곱합(SSE, sum of squares for error)과 교차 엔트로피 오차(CEE, cross entropy error)를 사용합니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Learning process</span>"
    ]
  },
  {
    "objectID": "ANN-learning.html#loss-function",
    "href": "ANN-learning.html#loss-function",
    "title": "6  Learning process",
    "section": "",
    "text": "6.1.1 SSE(sum of squares for error)\n오차제곱합(Equation 6.1 )은 신경말의 출력값(y_k)과 실제값(t_k) 사이의 차이인 오차를 계산하고 이 오차를 제곱하여 모두 더한 값을 말하며 이 값이 작아질 수록 모델이 더 좋은 예측능력을 보유한다고 판단합니다.\n\nE = \\frac{1}{2}\\sum^{}_{k}(y_k - t_k)^2\n\\tag{6.1}\n오차제곱합의 작동원리를 이해하기 위하여 임의로 원-핫 인코딩된 레이블(t_k)과 임의로 소프트맥수 합수의 출력값(y_k)을 생성하여 코드로 구현해 보겠습니다.1\n1 CEE에서도 동일한 예제를 사용 예정\n# 정답 레이블은 2\nt = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n\ndef sum_squres_error(y, t):\n  return 0.5 * np.sum((y-t)**2)\n\n# 예1: 2일 확률이 제일 높음(60%)\ny = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\nl1 = sum_squres_error(np.array(y), np.array(t))\n\n# 예2: 7일 확률이 제일 높음(60%)\ny = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\nl2 = sum_squres_error(np.array(y), np.array(t))\n\nprint(\"1번예제: %3f, 2번예제:%3f\" % (l1, l2))\n\n1번예제: 0.097500, 2번예제:0.597500\n\n\n정답 레이블인 2를 높은 확률로 산출한 1번 예제의 손실값이 0.09로 0에 근접하고, 7를 높은 확률로 산출한 2번 예제의 손실값이 0.59로 0에 멀게 산출됨을 확인 할 수 있습니다.\n\n\n6.1.2 CEE(cross entropy error)\n교차 엔트로피(Equation 6.2 )는 신경망의 출력값(y_k)이 소프트 맥스 함수를 거쳐 확률로 [0.0, 1.0]의 값을 갖는 다는 점을 고려하여 확률값이 높을 수록 0에 수렴하는 손실값을 산출합니다.\n\nE = -\\sum^{}_{k}t_k\\log{y_k}\n\\tag{6.2}\n\n\n\n\n\n\nFigure 6.2: Graph of y=lox(x)\n\n\n\n위의 그래프(Figure 6.2 )에서 보듯 x가 1일때 y는 0이 되고 x가 0에 근접시 y는 점점 작아집니다. 교차 엔트로피는 여기에 음(-)의 부호를 붙여 활률값인 x가 작아질수록 손실값인 y가 크게 나오도록 하였습니다.\n위의 식(Equation 6.2 )을 코드로 구현해 보겠습니다.\n\n# 정답 레이블은 2\nt = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n\ndef corss_entropy_error(y, t):\n1  delta = 1e-7\n  return -np.sum(t * np.log(y + delta))\n\n# 예1: 2일 확률이 제일 높음(60%)\ny = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\nl1 = corss_entropy_error(np.array(y), np.array(t))\n\n# 예2: 7일 확률이 제일 높음(60%)\ny = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\nl2 = corss_entropy_error(np.array(y), np.array(t))\n\nprint(\"1번예제: %3f, 2번예제:%3f\" % (l1, l2))\n\n\n1\n\ndelta를 설정한 이유는 y가 0이면 np,log함수는 무한대인 inf값을 출력하는데 이를 방지하기 위함\n\n\n\n\n1번예제: 0.510825, 2번예제:2.302584\n\n\n1번 예제의 손실값이 0.51로 2번 예제의 손실값보다 낮은 값을 출력하여 오차제곱합의 결과와 일치함을 확인할 수 있습니다.\n\n\n6.1.3 CEE with Mini-batch\n손실함수는 주어진 데이터에 대한 모든 손실값의 합을 모델의 평가지표로 산출합니다. 가령 훈련 데이터가 100개이 60,000개 인경우 60,000개의 손실값을 산출해야 합니다.\n이렇게 훈련데이터 모두에 대한 손실값을 산출하는 경우 데이터가 증가할 수록 산출시간이 오래 걸리는 문제가 있습니다. 그렇다면 이를 보다 효율적으로 할 수 있는 방법은 무엇이 있을까요?\n일부 데이터를 추려 근사치를 계산하는 방법을 생각할 수 있습니다. 이러한 방법을 미니배치(mini-batch)라고 하며 훈련데이터 전체에서 임의로 특정 데이터를 뽑아 학습하는 방법입니다.\n우리는 이러한 미니배치 학습을 위해 몇개를 임의 추출할지(batch-size)와 이러한 과정을 몇번 수행할 것인지(number of iteration)에 대한 고민을 해야 합니다, 그 이유는 배치는 전체데이터의 일부만을 대상으로 하기 때문입니다.2\n2 본 문제는 hyper parameter의 설정에 대한 내용으로 overfitting을 방지하려는 문제와 관련이 있습니다.\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nfrom dataset.mnist import load_mnist\n\n# MNIST 데이터셋 로드\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, one_hot_label = True)\n\n# Mini-batch 설정\ntrain_size = x_train.shape[0]\nbatch_size = 10\n1batch_mask = np.random.choice(train_size, batch_size)\n\n# Batch용 데이터 설정\n2x_batch = x_train[batch_mask]\nt_batch = t_train[batch_mask]\n\n\n1\n\nnp.randon.choice는 전체 N개의 데이터(train_size)에서 임의로 몇개(batch_size)를 추출할 것인지 결정\n\n2\n\nbatch_mask는 임의 뽑힌 데이터의 인덱스 값\n\n\n\n\n위에서 우리는 학습을 효율적으로 실시하기 위하여 미니배치를 설정하였습니다. 그렇다면 미니배치로 손실을 어떻게 구해야 할까고민입니다. 앞서 구현한 교차 엔트로피 오차를 아래의 코드와 같이 일부만 수정하면 간단히 해결할 수 있습니다.\n\ndef corss_entropy_error(y, t):\n  if y.ndim == 1:\n    t = t.reshape(1, t.size)\n    y = y.reshape(1, y.size)\n  \n  batch_size = y.shape[0]\n1  return -np.sum(t * np.log(y + 1e-7)) / batch_size\n2  return -np.sum(t * np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n\n\n1\n\n정답 레이블이 원-핫 인코딩 형상인 경우\n\n2\n\n정답 레이블이 숫자 레이블인 경우",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Learning process</span>"
    ]
  },
  {
    "objectID": "ANN-learning.html#gradient-descent",
    "href": "ANN-learning.html#gradient-descent",
    "title": "6  Learning process",
    "section": "6.2 Gradient Descent",
    "text": "6.2 Gradient Descent\nANN은 손실함수의 값을 최소화 하는 방향으로 학습을 진행한다고 하였습니다. 이를 다시 말하면 손실함수가 최소값을 갖도록 하는 최적의 매개변수(가중치와 편향)를 탐색하는 문제입니다.\n그러나 매개변수의 공간은 방대하여 이를 찾는 문제는 쉽지 않습니다. 그래서 기울기를 사용한 최적화 알고리즘인 경사하강법(gradient descent)을 이해할 필요가 있습니다.\n경사하강법은 현재의 위치에서 모든 방향으로 기울기3를 구하고, 기울기의 반대방향으로 일정거리(학습률, learning rate)만큼 이동합니다. 이를 반복수행하면서 함수의 기울기(경사)를 줄여나가는 방법입니다. 이를 식으로 나타내보겠습니다.\n3 경사하강법은 기울기를 구한다는 점에서 미분에 대한 이해, 특히 매개변수별 기울기(모든 방향으로의 기울기)를 구한다는 점에서 편미분이 사용됩니다.\n\\begin{align}\nx_0 &= x_0 - \\eta \\frac{\\partial{f}}{\\partial{x_0}}\nx_1 &= x_1 - \\eta \\frac{\\partial{f}}{\\partial{x_1}}\n\\end{align}\n\\tag{6.3}\n위의 식을 도식화 하면 아래(Figure 6.3 )와 같고 아래의 표에서 학습을 시작한 초기점은 등고선의 1사분면 쪽에서 시작하여 기울기의 반대방향으로 매개변수를 업데이트해 나가는 과정을 보여줍니다.\n\n\n\n\n\n\nFigure 6.3: Example of Gradient Descent\n\n\n\n\n\n\n\n\n\n경사하강법의 한계\n\n\n\n경사하강법은 함수의 기울기는 0인 곳을 찾아가는 최적화 알고리즘입니다. 그러나 함수의 기울기아 0이 되는 곳이 항상 최솟값에 해당하지 않습니다. 가령 함수가 복접하고 찌그러진 모양인 경우 그곳이 최솟값인지 아니면 극솟값인지 또는 안정점인지 알고리즘은 알지 못합니다.\n물론 이러한 문제를 해결하기 위하여 다양한 방법을 사용합니다. 가령 확률의 개념을 도입하거나 배치를 설정할 수 있습니다, 또한, 업데이트 하는 정도인 학습률(learning rate)와 같은 하이퍼파라미터의 설정의 조정하는 방법도 있습니다. 자세한 사항은 뒤에서 설명하겠습니다.\n\n\n아래는 경사하강법을 구현한 예시입니다.\n\n# 기울기 계산\n1def numerical_gradient(f, x):\n2  h = 1e-4\n3  grad = np.zeros_like(x)\n\n  for idx in range(x.size):\n    tmp_val = x[idx]\n    # f(x) 계산\n    x[idx] = tmp_val + h\n    fxh1 = f(x)\n    # f(x-h) 계산\n    x[idx] = tmp_val - h\n    fxh2 = f(x)\n\n4    grad[idx] = (fxh1 - fxh2) / (2*h)\n    x[idx] = tmp_val\n  \n  return grad\n\n# 경사하강\n5def gradient_descent(f, init_x, lr = 0.01, step_num=100):\n  x = init_x\n\n  for i in range(step_num):\n6    grad = numerical_gradient(f, x)\n    x -= lr * grad\n  return x\n\n# 실전 풀이\ndef function_2(x):\n  return x[0]**2 + x[1]**2\n  \nresult = []\n# 학습률이 적정\ninit_x = np.array([-3.0, 4.0])\nresult.append(gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100))\n# 학습률이 과다\ninit_x = np.array([-3.0, 4.0])\nresult.append(gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100))\n# 학습률이 과소\ninit_x = np.array([-3.0, 4.0])\nresult.append(gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100))\n\nprint(\"학습률별 결과:\")\nfor i in range(3):\n    print(f\"Result {i+1}:\", result[i])\n\n\n1\n\nnumerical_gradien는 기울기를 구하는 함수(수치미분 사용)\n\n2\n\nh는 수치미분을 위한 아주 작은 크기의 변화량\n\n3\n\ngrad = np.zeros_list(x)는 x와 형상기 같은 배열을 생성\n\n4\n\nfxh1과 fxh2 사이의 기울기를 구한다는 의미가\n\n5\n\nf 최적화 대상 함수, init_x 초깃값, lr 학습률, step_num 반복시행 횟수\n\n6\n\n1번의 수치미분 함수\n\n\n\n\n학습률별 결과:\nResult 1: [-6.11110793e-10  8.14814391e-10]\nResult 2: [-2.58983747e+13 -1.29524862e+12]\nResult 3: [-2.99999994  3.99999992]\n\n\n\n\n\n\n\n\nFigure 6.4: Results by learning rate\n\n\n\nFigure 6.4 에서 보듯이 학습률의 설정은 ANN 등 신경망의 학습시 하이퍼파라미터 설정의 중요성4을 잘 보여주는 사례입니다.\n4 ANN의 효율성 및 신뢰성을 높이기 위한 기법 및 하이퍼파라미터 설정에 대한 이슈는 개별 이슈가 발생시 추가적으로 정리할 예정입니다.가령 학습률을 적정하게(1번) 설정시 학습이 원활하게 이루어지지만 학습률이 매우 큰경우(2번) 오버슈팅으로 의도한바와 전혀 다른 결과가 나오게 됩니다. 반면 학습률을 너무 작게 설정한 경우(3번) 학습이 잘 이루어지지 않는 문제를 확인할 수 있습니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Learning process</span>"
    ]
  },
  {
    "objectID": "ANN-learning.html#applying-gradient-descent-to-ann",
    "href": "ANN-learning.html#applying-gradient-descent-to-ann",
    "title": "6  Learning process",
    "section": "6.3 Applying gradient descent to ANN",
    "text": "6.3 Applying gradient descent to ANN\n지금까지 우리는 손실함수와 경사하강법에 대하여 학습하였습니다. 다시 정리하면 ANN에서의 손실함수는 신경망의 출력값과 레이블값의 차이를 구하는 도구이고, 경사하강법은 매개변수(가중치 및 편향)에 대한 손실함수의 기울기에 해당합니다.\n여기서 경사하강법을 이용하여 2 \\times 3형상의 가중치 \\textbf{W}에 대한 손실함수 L의 기울기를 기울기5를 구하도록 하겠습니다.(Equation 6.4 )\n5 모든 가중치에 대한 손실함수의 기울기를 구해야 함을 고려시, 모든 가중치에 해당하는 벡터별로 독립적으로 기울기를 구한다는 의미로 편미분으로 처리\n\\begin{align}\n\\textbf{W} &= \\begin{pmatrix}\n    w_{11} & w_{12} & w_{13} \\\\\n    w_{11} & w_{12} & w_{13}\n\\end{pmatrix} \\\\ \\\\\n\\frac{\\partial{L}}{\\partial{\\textbf{W}}}&= \\begin{pmatrix}\n    \\frac{\\partial{L}}{\\partial{w_{11}}} & \\frac{\\partial{L}}{\\partial{w_{12}}} & \\frac{\\partial{L}}{\\partial{w_{13}}} \\\\\n    \\frac{\\partial{L}}{\\partial{w_{11}}} & \\frac{\\partial{L}}{\\partial{w_{12}}} & \\frac{\\partial{L}}{\\partial{w_{13}}}\n\\end{pmatrix}\n\\end{align}\n\\tag{6.4}\n위의 식(Equation 6.4 )을 코드로 구현하여 기울기를 산출해 보도록 하겠습니다. 먼제 간단하게 신경망을 아래와 같이 구현할 수 있습니다.\n\n# 환경설정\nimport sys, os\nsys.path.append(os.pardir)\nimport numpy as np\nfrom common.functions import softmax, cross_entropy_error\nfrom common.gradient import numerical_gradient\n\n# 클래스 구현\nclass simpleNet:\n  def __init__(self):\n    self.W = np.random.randn(2,3)\n\n  def predict(self, x):\n    return np.dot(x, self.W)\n\n  def loss(self, x, t):\n    z = self.predict(x)\n    y = softmax(z)\n    loss = cross_entropy_error(y, t)\n    return loss\n\n# 실습\n1net = simpleNet()\n2x = np.array([0.6, 0.9])\n3p = net.predict(x)\n\n4t = np.array([0, 0, 1])\n5res = net.loss(x, t)\n\n# 결과\nprint(\"가중치 현황\")\nprint(net.W)\nprint(\"출력값\")\nprint(p)\nprint(\"손실값\")\nprint(res)\n\n\n1\n\nsimpleNet 객체생성\n\n2\n\n입력변수 생성\n\n3\n\n가중치와 입력값의 weighted sum 산출\n\n4\n\n정답 레이블\n\n5\n\n손실함수 산출 결과\n\n\n\n\n가중치 현황\n[[-1.11022851 -0.59567708  1.53878677]\n [-0.72623452 -0.0610624   0.94174967]]\n출력값\n[-1.31974817 -0.41236241  1.77084676]\n손실값\n0.14682744469556858\n\n\n다음으로 기울기는 아래와 같이 구현할 수 있습니다. 가중치에 대한 손실함수의 기울기를 편미분을 이용하여 구하는 경우 본래 가중치가 보유한 형상은 유지됨을 주의하도록 합니다.6\n6 형상이 바뀌는 경우 신경망의 구조가 변하게 되어 에러가 발생합니다.\ndef f(W):\n  return net.loss(x,t)\n\ndW = numerical_gradient(f, net.W)\nprint(dW)\n\n[[ 0.02355898  0.0583753  -0.08193428]\n [ 0.03533847  0.08756295 -0.12290142]]\n\n\n위의 내용에서 하석할 수 있는 것은 numerical_gradient를 통해 w_{11}를 h만큼 미세하게 변화 시키는 경우 손실함수 값은 print(dW)의 1행x1열의 값만큼 변화한다는 의미7입니다. 또한 w_{11} 보다 w_{23}의 기여도가 더 크다고 이해할 수 있습니다.\n\n\n7 따라서 손실함수 값을 감소시키려면 기울기의 반대방향으로 가중치 \\textbf{W}을 갱신(w_{ij} \\leftarrow w_{ij} - \\eta \\frac{\\partial{L}}{\\partial{w_{ij}}})해야 한다",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Learning process</span>"
    ]
  },
  {
    "objectID": "ANN-lab_MNIST.html",
    "href": "ANN-lab_MNIST.html",
    "title": "7  Lab: Implementing ANN with MINIST dataset",
    "section": "",
    "text": "7.1 STEP1: Two Layer Net\n우리는 지금까지 학습한 내용에 기초하여 아래와 같이 순전파(forward propagation) 과정을 Two Layer Net이라는 클래스로 구현해 보겠습니다.\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nfrom common.functions import *\nfrom common.gradient import numerical_gradient\n\n\nclass TwoLayerNet:\n\n1    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n        # 가중치 초기화\n        self.params = {}\n        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n        self.params['b1'] = np.zeros(hidden_size)\n        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n        self.params['b2'] = np.zeros(output_size)\n\n2    def predict(self, x):\n        W1, W2 = self.params['W1'], self.params['W2']\n        b1, b2 = self.params['b1'], self.params['b2']\n    \n        a1 = np.dot(x, W1) + b1\n        z1 = sigmoid(a1)\n        a2 = np.dot(z1, W2) + b2\n        y = softmax(a2)\n        \n        return y\n        \n    # x : 입력 데이터, t : 정답 레이블\n3    def loss(self, x, t):\n        y = self.predict(x)\n        \n        return cross_entropy_error(y, t)\n    \n4    def accuracy(self, x, t):\n        y = self.predict(x)\n        y = np.argmax(y, axis=1)\n        t = np.argmax(t, axis=1)\n        \n        accuracy = np.sum(y == t) / float(x.shape[0])\n        return accuracy\n        \n    # x : 입력 데이터, t : 정답 레이블\n5    def numerical_gradient(self, x, t):\n        loss_W = lambda W: self.loss(x, t)\n        \n        grads = {}\n        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n        \n        return grads\n        \n6    def gradient(self, x, t):\n        W1, W2 = self.params['W1'], self.params['W2']\n        b1, b2 = self.params['b1'], self.params['b2']\n        grads = {}\n        \n        batch_num = x.shape[0]\n        \n        # forward\n        a1 = np.dot(x, W1) + b1\n        z1 = sigmoid(a1)\n        a2 = np.dot(z1, W2) + b2\n        y = softmax(a2)\n        \n        # backward\n        dy = (y - t) / batch_num\n        grads['W2'] = np.dot(z1.T, dy)\n        grads['b2'] = np.sum(dy, axis=0)\n        \n        da1 = np.dot(dy, W2.T)\n        dz1 = sigmoid_grad(a1) * da1\n        grads['W1'] = np.dot(x.T, dz1)\n        grads['b1'] = np.sum(dz1, axis=0)\n\n        return grads\n\n\n1\n\n__init__ 클래스의 초기화 수행 (입력층, 은닉층, 출력층 각각의 뉴런수 지정)\n\n2\n\npredict 추론을 수행 (x 이미지 데이터)\n\n3\n\nloss 손실함수 값 산출 (x 이미지 데이터, t 정답레이블)\n\n4\n\naccuracy 신경망의 정확도 산출\n\n5\n\nnumerical_gradient 매개변수(가중치)의 기울기 산출\n\n6\n\ngradient 매개변수(가중치)의 기울기 산출(오차 역전파과정은 다음장에서 설명)\n위의 클래스에서 gradient 메서드의 경우 순전파와 역전파를 모두 사용하고, 순전파시 활성화 함수로 sigmoid를 출력값의 활성화 함수로 분류 문제해결을 위해 softmax를 사용하였습니다.(제사한 사항은 활성화 함수를 참고 Chapter 5)\n추가적으로 우리가 사용할 데이터의 형상에 주의하여 클래스의 초기화를 수행해야 합니다. MNIST 데이터 셋의 개별 입력값은 28 \\times 28 픽셀을 Flatten하게하여 784개의 입력값의 형상을 설정해야 합니다.\n또한, 우리가 수행하는 분류문제에서 출력값은 분류하고자 하는 카테고리의 갯수 여기서 0~9까지 10개의 숫자를 분류해야 함을 고려하여 출력값의 형상은 10개로 설정해야 합니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lab: Implementing ANN with MINIST dataset</span>"
    ]
  },
  {
    "objectID": "ANN-lab_MNIST.html#step2-mini-batch",
    "href": "ANN-lab_MNIST.html#step2-mini-batch",
    "title": "7  Lab: Implementing ANN with MINIST dataset",
    "section": "7.2 STEP2: Mini-Batch",
    "text": "7.2 STEP2: Mini-Batch\n모든 데이터를 갖고 학습하는 것은 효율적이지 않다고 하였습니다. 따라서, 무작위로 훈련 데이터 중 일부를 추출하여 훈련을 진행하는 미니배치 방법을 통하여 훈련의 효율성을 높일 수 있습니다.\n미니배치를 활용하여 확률적 경사하강법을 구현하면 아래와 같습니다.\n\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom dataset.mnist import load_mnist\n\n# 데이터 읽기\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n\n# 하이퍼파라미터\niters_num = 10000  # 반복 횟수를 적절히 설정한다.\ntrain_size = x_train.shape[0]\nbatch_size = 100   # 미니배치 크기\nlearning_rate = 0.1\n\ntrain_loss_list = []\n\nfor i in range(iters_num):\n    # 미니배치 획득\n    batch_mask = np.random.choice(train_size, batch_size)\n    x_batch = x_train[batch_mask]\n    t_batch = t_train[batch_mask]\n    \n    # 기울기 계산\n    #grad = network.numerical_gradient(x_batch, t_batch)\n    grad = network.gradient(x_batch, t_batch)\n    \n    # 매개변수 갱신\n    for key in ('W1', 'b1', 'W2', 'b2'):\n        network.params[key] -= learning_rate * grad[key]\n    \n    # 학습 경과 기록\n    loss = network.loss(x_batch, t_batch)\n    train_loss_list.append(loss)",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lab: Implementing ANN with MINIST dataset</span>"
    ]
  },
  {
    "objectID": "ANN-lab_MNIST.html#step3-evaluating-with-test-data",
    "href": "ANN-lab_MNIST.html#step3-evaluating-with-test-data",
    "title": "7  Lab: Implementing ANN with MINIST dataset",
    "section": "7.3 STEP3: Evaluating with test data",
    "text": "7.3 STEP3: Evaluating with test data\n이제 우리가 구현한 클래스의 성능을 평가해 보도록 하겠습니다. 훈련데이터를 미니배치로 나누어 훈련을 진행하였는데 과연 다른 새로운 데이터셋에서도 동일한 성능을 발휘할지 알아야 합니다.\n만약, 훈련 데이터에만 적응한 ANN이라면 새로운 데이터에서는 적절한 성능을 발휘하지 못할 가능성이 있기 때문입니다. 이를 오버피팅(overfitting)2이라 합니다.\n2 오버피팅은 훈련데이터에 대한 정확도는 높으나 신규 데이터에는 적절한 성능을 발휘하지 못하는 문제로 이러한 문제를 해결하기 위하여 조기종료(early stopping), 가중치 감소, 드롭아웃(drop-out)등의 기법이 사용됩니다.\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom dataset.mnist import load_mnist\n\n# 데이터 읽기\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n\n# 하이퍼파라미터\niters_num = 10000  # 반복 횟수를 적절히 설정한다.\ntrain_size = x_train.shape[0]\nbatch_size = 100   # 미니배치 크기\nlearning_rate = 0.1\n\ntrain_loss_list = []\n1train_acc_list = []\n2test_acc_list = []\n\n3iter_per_epoch = max(train_size / batch_size, 1)\n\nfor i in range(iters_num):\n    # 미니배치 획득\n    batch_mask = np.random.choice(train_size, batch_size)\n    x_batch = x_train[batch_mask]\n    t_batch = t_train[batch_mask]\n    \n    # 기울기 계산\n    #grad = network.numerical_gradient(x_batch, t_batch)\n    grad = network.gradient(x_batch, t_batch)\n    \n    # 매개변수 갱신\n    for key in ('W1', 'b1', 'W2', 'b2'):\n        network.params[key] -= learning_rate * grad[key]\n    \n    # 학습 경과 기록\n    loss = network.loss(x_batch, t_batch)\n    train_loss_list.append(loss)\n    \n    # 정확도 계산\n4    if i % iter_per_epoch == 0:\n        train_acc = network.accuracy(x_train, t_train)\n        test_acc = network.accuracy(x_test, t_test)\n        train_acc_list.append(train_acc)\n        test_acc_list.append(test_acc)\n        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n\n# 그래프 그리기\nmarkers = {'train': 'o', 'test': 's'}\nx = np.arange(len(train_acc_list))\nplt.plot(x, train_acc_list, label='train acc')\nplt.plot(x, test_acc_list, label='test acc', linestyle='--')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.ylim(0, 1.0)\nplt.legend(loc='lower right')\nplt.show()\n\n\n1\n\ntrain_acc_list 학습 데이터에 대한 정확도를 저장하는 튜플\n\n2\n\ntest_acc_list 시험 데이터에 대한 정확도를 저장하는 튜플\n\n3\n\niter_per_epoch 1 epoch당 반복하는 횟수\n\n4\n\nif i % iter_per_epoch == 0: 1 epoch당 정확도 계산\n\n\n\n\n\n\n\n\n\n\nFigure 7.1: Accuracy trends for training and test data\n\n\n\n위의 그림에서 보듯이 훈련 데이터(실선)와 시험 데이터(점선)의 정확도가 epoch인 진행될 수록 같은 수준으로 좋아지고 있습니다. 이는 오버피팅없이 적절히 학습이 이루어 졌다고 평가할 수 있습니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lab: Implementing ANN with MINIST dataset</span>"
    ]
  },
  {
    "objectID": "ANN-backward.html",
    "href": "ANN-backward.html",
    "title": "8  Backward Propagation",
    "section": "",
    "text": "8.1 Pre-requisite: Chain-rule and Dynamic Programming\n오차역전파는 기본적으로 손실함수 값에서 입력값까지의 매개변수를 역으로 조정하는 과정으로 순방향과 반대방향으로 국소적인 미분값을 곱하며 가중치를 조정하는 절차로 이해할 수 있습니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Backward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-backward.html#pre-requisite-chain-rule-and-dynamic-programming",
    "href": "ANN-backward.html#pre-requisite-chain-rule-and-dynamic-programming",
    "title": "8  Backward Propagation",
    "section": "",
    "text": "8.1.1 Chain-rule\n반대방향으로 국소적인 미분값을 곱한다는 것은 어떠한 의미를 갖고 있을까요? 그리고 이러한 연산의 기반이 되는 개념이 무엇일까요? 이물음에 대한 답변이 바로 연쇄법칙입니다. 연쇄법칙에 관한 자세한 설명은 아래 3Blue1Brown1 영상을 참고하기 바랍니다.\n1 3Blue1Brown은 많은 수학적인 문제를 도식화하여 아주 직관적으로 설명하고 있어 매우 유용합니다.\n\n\n8.1.2 Dynamic Programming\n연쇄법칙을 정확히 이해하였다면 지속적으로 미분값이 재귀적으로 사용됨을 확인할 수 있습니다. 그러나 이미 계산된 미분값을 따로 저장하였다가 불러오기만 한다면 연산이 얼마나 쉬워질까요? 쉬워진다기보다 간단해지고 컴퓨터의 연산의 수를 줄일 수 있지 않을까요?\n바로 이러한 배경에서 연쇄법칙을 빠르게 수행하기 위하여 고려되는 방법이 동적계획법 입니다. 이는 피보나치 수열의 계산에 있어서 재귀적으로 반복계산되는 노드를 따로 저장하여 그 값을 호출하여 사용하도록 하므로써 연산의 수를 줄여 알고리즘의 성능을 개선해줄수 있을 것입니다.\n동적계획법에 대한 자세한 설명은 아래 영상을 참고하시기 바랍니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Backward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-backward.html#backpropagation",
    "href": "ANN-backward.html#backpropagation",
    "title": "8  Backward Propagation",
    "section": "8.2 Backpropagation",
    "text": "8.2 Backpropagation\n역전파 과정을 연쇄법칙을 수식 및 그래프를 활용하면 보다 직관적이고 쉽게 이해할 수 있습니다. 우선 합성함수2 Equation 8.1 의 식을 미분을 실행하며 예로 살펴보겠습니다,\n2 합성함수의 미분은 함성함수를 구성하는 각 함수의 미분의 곱으로 표현가능\n\\begin{align}\nz &= t^2 \\\\\nt &= x+y\n\\end{align}\n\\tag{8.1}\nx에 대한 z의 미분인 \\frac{\\partial{z}}{\\partial{x}}은 \\frac{\\partial{z}}{\\partial{t}}과 \\frac{\\partial{t}}{\\partial{x}}의 곱으로 나타낼 수 있습니다. 그리고 \\partial{t}를 서로 지울 수 있습니다.\n\n\\begin{align}\n\\frac{\\partial{z}}{\\partial{x}} &= \\frac{\\partial{z}}{\\partial{t}}\\frac{\\partial{t}}{\\partial{x}} \\\\\n&= \\frac{\\partial{z}}{\\not{\\partial{t}}}\\frac{\\not{\\partial{t}}}{\\partial{x}}\n\\end{align}\n\\tag{8.2}\n연쇄법칙을 써서 \\frac{\\partial{z}}{\\partial{x}}를 구하기 위하여 편미분을 실시하고, 두 미분값을 곱하여 최종 미분값을 산출합니다.\n\n\\begin{align}\n\\frac{\\partial{z}}{\\partial{t}} &= 2t \\qquad\n\\frac{\\partial{t}}{\\partial{x}} = 1 \\\\ \\\\\n\\frac{\\partial{z}}{\\partial{x}} &= \\frac{\\partial{z}}{\\partial{t}}\\frac{\\partial{t}}{\\partial{x}} =\n2t \\cdot 1 = 2(x+y)\n\\end{align}\n\\tag{8.3}\nEquation 8.3 를 그래프로 나타내어 연쇄법칙을 나타내봅시다. Figure 8.1 에서 보는 바와 같이 오른쪽에서 왼쪽으로 신호를 전달(전파) 합니다. 전파의 과정에서 입력값에 해당하는 편미분값을 곱하여 다음 노드에 전달함을 확인 할 수 있습니다.\n\n\n\n\n\n\nFigure 8.1: Multiplying the partial derivative of Equation 8.3 and passing it on\n\n\n\nFigure 8.1 과 같은 과정에 Equation 8.3 의 미분값을 대입하면 Figure 8.2 와 같은 결과를 얻을 수 있습니다.\n\n\n\n\n\n\nFigure 8.2: The process of showing backpropagation results\n\n\n\n\n8.2.1 Backpropagation of Addition Nodes\n먼저 z=x+y를 갖고 덧셈노드에 대한 역전파를 살펴보겠습니다. 먼저 이 식에 대한 미분을 해석적으로 구하면 \\frac{\\partial{z}}{\\partial{x}}와 \\frac{\\partial{z}}{\\partial{y}} 모두 1이 됩니다.\nFigure 8.6 의 그래프를 기준으로 역전파3 과정을 살펴봅시다.\n3 역전파는 순방향과 반대방향으로 국소적 미분(편미분)값을 곱하는 방법으로 수행상류에서 산출한 편미분 값(\\frac{\\partial{L}}{\\partial{z}})을 x간선의 경우 \\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{x}}의 꼴로 역전파가 이루어 지고, y간선의 경우 \\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{y}}의 꼴로 역전파가 이루어 집니다.\nFigure 8.6 는 덧셈의 역전파 이므로 \\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{x}}=\\frac{\\partial{L}}{\\partial{z}}\\cdot1과 \\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{y}}=\\frac{\\partial{L}}{\\partial{z}}\\cdot1로 변형됨으로 입력된 값 그대로 다음 노드에 전달되게 됩니다.\n\n\n\n\n\n\nFigure 8.3: Examples: Backpropagation of Addition Nodes\n\n\n\n\n\n8.2.2 Backpropagation of Multiplication Nodes\n다음으로 z=xy를 갖고 곱셈노드에 대한 역전파를 살펴보겠습니다. 먼저 이 식에 대한 미분을 해석적으로 구하면 \\frac{\\partial{z}}{\\partial{x}} = y와 \\frac{\\partial{z}}{\\partial{y}} = x가 됩니다.\nFigure 8.4 의 그래프를 기준으로 역전파 과정을 살펴봅시다.\n상류에서 산출한 편미분 값(\\frac{\\partial{L}}{\\partial{z}})을 x간선의 경우 \\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{x}}=\\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{x}}=\\frac{\\partial{L}}{\\partial{z}}\\cdot y의 꼴로 역전파가 이루어 지고, y간선의 경우 \\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{y}}=\\frac{\\partial{L}}{\\partial{z}}\\frac{\\partial{z}}{\\partial{y}}=\\frac{\\partial{L}}{\\partial{z}}\\cdot x의 꼴로 역전파가 이루어 집니다.\nFigure 8.4 는 곱셈의 역전파는 서로 바꾼값을 곱하여 하류로 흘려 보내게 됨을 확인할 수 있습니다.\n\n\n\n\n\n\nFigure 8.4: Examples: Multiplication of Addition Nodes\n\n\n\n\n\n\n\n\n\n편미분과 그라디언트\n\n\n\n\n신경망의 학습을 위한 역전파 과정은 모든 독립변수에 대한 편미분을 통하여 기울기를 산출\n대부분의 경우 이를 간단하게 표현하기 위하여 \\nabla연산자를 사용\n편미분을 통한 가중치(\\omega)의 업데이트 과정을 아래와 같이 표현\n\n\n\\omega = \\leftarrow \\omega - \\alpha \\nabla_{\\omega} \\epsilon",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Backward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-backward.html#implementing-the-activation-layer",
    "href": "ANN-backward.html#implementing-the-activation-layer",
    "title": "8  Backward Propagation",
    "section": "8.3 Implementing the Activation Layer",
    "text": "8.3 Implementing the Activation Layer\n역전파의 과정을 활성화 함수에 적용하여 구현해 보도록 하겠습니다. 우리가 사용할 활성화 함수는 ReLU와 Sigmoid입니다.\n\n8.3.1 ReLU\nReLU(Rectified Linear Unit) 함수는 0을 기점으로 입력값이 0이하이면 0을 출력하고 0을 초과하면 그대로 출력하도록 하는 활성화 함수 입니다.4\n4 \\frac{\\partial{L}}{\\partial{y}} = \\begin{cases} 1 & (x &gt;0) \\\\ 0 & (x \\leq 0) \\end{cases}5 y = \\begin{cases} x & (x &gt;0) \\\\ 0 & (x \\leq 0) \\end{cases}ReLU 함수의 미분값5의 역전파 과정은 (1) x &gt; 0일때 역전파는 미분값(\\frac{\\partial{L}}{\\partial{y}})을 그대로 흘려보내고, (2) x \\leq 0일때 역전파는 미분값을 보내지 않습니다.\n\n\n\n\n\n\nFigure 8.5: Backpropagation process of ReLU\n\n\n\nFigure 8.5 의 과정을 참고하여 ReLU 계층을 코드로 구현하면 아래와 같습니다.\n\nimport numpy as np\n\nclass Relu:\n  def __init__(self):\n    self.mask = None\n\n  def forward(self, x):\n1    self.mask = (x&lt;=0)\n    out = x.copy()\n2    out[self.mask] = 0\n    return out\n  \n  def backward(self, dout):\n3    dout[self.mask] = 0\n    dx = dout\n    return dx\n\nx = np.array([[1.0, -0.5], [-2.0, 3.0]])\nmask = (x &lt;= 0)\nprint(mask)\n\n\n1\n\nx이하인 값의 경우 True를 반환하고 초과인 경우 False를 반환\n\n2\n\nself.mask에서 True에 해당하는 값을 0으로 함\n\n3\n\nself.mask가 True인 값은 역전파시 0을 산출하도록 함\n\n\n\n\n[[False  True]\n [ True False]]\n\n\n\n\n8.3.2 Sigmoid Layer\nSigmoid6의 경우는 곱하기, 더하기 등의 노드가 결합되는 형태로 ReLU에 비하여 조금 복잡할 수 있으나 아래의 그래프(Figure 8.6 )를 참고하여 단계별로 나누어 역전파 과정을 설명하도록 하겠습니다.\n6 y=\\frac{1}{1+exp(-x)}\n\n\n\n\n\n\n\nForward\n\n\n\n\n\n\n\n\n\nBackward\n\n\n\n\n\n\nFigure 8.6: Backpropagation process of Sigmoid\n\n\n\n계산 그래프(Figure 8.6 ) ’/’노드의 역전파를 설명을 위해 순전화 과정에서 약간의 트릭으로 역수의 곱하기 노드로 변형할 수 있습니다.. 이는 1+epx(-x)를 x로 두고 y=\\frac{1}{x}로 순전파를 진행하여 y를 출력하고, 역전파는 곱하기이므로 x에 대한 y의 미분값7을 입력값(\\frac{\\partial{L}}{\\partial{y}})과 곱하여 하류로 흘려보내면 \\times 노드의 역전파로 풀이할 수 있습니다.\n7 \\frac{\\partial{y}}{\\partial{x}}=-\\frac{1}{x^2}=-y^2+노드는 상류의 값을 하류로 그대로 흘려 보내는 것으로 /노드에서 산출한 -\\frac{\\partial{L}}{\\partial{y}}y^2을 그대로 하류로 흘려 보내면 되겠습니다.\nexp노드는 곱하기 노드 이므로 상류에서 흘러온 값(-\\frac{\\partial{L}}{\\partial{y}}y^2)과 순전파시 해당노드의 산출값의 미분값(\\frac{\\partial{y}}{\\partial{x}}=exp(x))을 곱해야 하므로 -\\frac{\\partial{L}}{\\partial{y}}y^2exp(-x)를 하류로 흘려보내게 됩니다.\n마지막으로 \\times으 노드이다. 상류에서 입력되는 값과 해당노드의 미분값을 곱하여 하류로 흘려 보내는 방식으로 역전파를 수행하며, 곱하기 노드의 순전파시 산출이 -x이므로 역전파에 사용할 미분값은 -1이므로 입력된 값의 부호만을 변경해주면 됩니다.\nSigmoid 노드의 역전파를 단순화 하면 입력값은 \\frac{\\partial{L}}{\\partial{y}}이 되고, 출력값은 \\frac{\\partial{L}}{\\partial{y}}y^2exp(-x)이 되게 됩니다. 이 식을 다음(Equation 8.4)과 같이 변형해서 Figure 8.7 과 같이 최종 단순화 할 수 있습니다.\n\n\\begin{align}\n\\frac{\\partial{L}}{\\partial{y}}y^2exp(-x) &= \\frac{\\partial{L}}{\\partial{y}}\\frac{1}{(1+exp(-x))^2}exp(-x) \\\\\n&= \\frac{\\partial{L}}{\\partial{y}}\\frac{1}{1+exp(-x)}\\frac{exp(-x)}{1+exp(-x)} \\\\\n&= \\frac{\\partial{L}}{\\partial{}}y(1-y)\n\\end{align}\n\n\n\n\n\n\n\nFigure 8.7: Simplified Backward of Sigmoid\n\n\n\nFigure 8.7 의 과정을 참고하여 Sigmoid 계층을 코드로 구현하면 아래와 같습니다.\n\nclass Sigmoid:\n  def __init__(self):\n    self.out = None\n\n  def forward(self, x):\n    out = 1/(1+exp(-x))\n    self.out = out\n1    return out\n\n  def backward(self, dout):\n    dx = dout * (1.0 - self.out) * self.out\n    return dx\n\n\n1\n\nforward 출력을 인스턴스 변수 out에 보관하였다가, backward연산에 사용",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Backward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-backward.html#implementing-the-output-layer",
    "href": "ANN-backward.html#implementing-the-output-layer",
    "title": "8  Backward Propagation",
    "section": "8.4 Implementing the Output Layer",
    "text": "8.4 Implementing the Output Layer\nANN에서 순전파때 수행하는 행렬의 곱은 기하학에서 어파인 변환(affine tranformation)이라고 이를 Affine 계층이라 합니다. Softmax 계층은 ANN의에서 입력값을 정규화하여 출력값을 산출하는 계층입니다.\n\n8.4.1 Affine\nANN의 순전파에서 입력값(\\textbf{X})과 가중치(\\textbf{W})의 Weighted sum에 편향(\\textbf{B})을 합산하여 활성화 함수를 통해 출력값을 다음 계층에 전달하게 됩니다. 이 과정에서 중요한 것은 특정 계층 또는 노드의 계산과정에서의 형상 또는 차원을 일치시켜야 한다는 점입니다.\n\n\n\n\n\n\nFigure 8.8: Forward Propagation of Affine\n\n\n\nFigure 8.8 는 행렬을 기준으로 한 순전파 과정입니다. 이는 2개의 입력노드를 \\textbf{X}, 3개의 출력노드 \\textbf{Y}를 갖는 신경망8 (Figure 8.9 )을 벡터폼으로 표현한 것입니다.\n8 입력노드와 출력노드간 간선에 해당하는 가중치 2\\times3의 \\textbf{W}\n\n\n\n\n\n\n\nflowchart LR\n  x1((x1)) --w11---&gt; y1((y1)) --&gt; sigmoid1(sigmoid) --&gt; z1((z1))\n  x1((x1)) --w12---&gt; y2((y2)) --&gt; sigmoid2(sigmoid) --&gt; z2((z2))\n  x1((x1)) --w13---&gt; y3((y3)) --&gt; sigmoid3(sigmoid) --&gt; z3((z3))\n  x2((x2)) --w21---&gt; y1((y1))\n  x2((x2)) --w22---&gt; y2((y2))\n  x2((x2)) --w23---&gt; y3((y3))\n\n\n\n\n\n\n\n\nFigure 8.9\n\n\n\nFigure 8.8 의 각 단계별 역전파를 위하여 편미분을 진행하면 다음과 같은 식이 도출됩니다.\n\n\\begin{align}\n\\frac{\\partial{L}}{\\partial{\\textbf{X}}} &= \\frac{\\partial{L}}{\\partial{\\textbf{Y}}}\\frac{\\partial{\\textbf{Y}}}{\\partial{\\textbf{X}}} \\\\\n&= \\frac{\\partial{L}}{\\partial{\\textbf{Y}}}\\frac{\\partial{(\\textbf{X}\\cdot\\textbf{W}+\\textbf{B})}}{\\partial{\\textbf{X}}} \\\\\n&= \\frac{\\partial{L}}{\\partial{\\textbf{Y}}}\\cdot\\textbf{W}^T \\\\\\\\\n\\frac{\\partial{L}}{\\partial{\\textbf{W}}} &= \\frac{\\partial{L}}{\\partial{\\textbf{Y}}}\\frac{\\partial{\\textbf{Y}}}{\\partial{\\textbf{W}}} \\\\\n&= \\frac{\\partial{L}}{\\partial{\\textbf{Y}}}\\frac{\\partial{(\\textbf{X}\\cdot\\textbf{W}+\\textbf{B})}}{\\partial{\\textbf{W}}} \\\\\n&= \\textbf{X}^T\\cdot\\frac{\\partial{L}}{\\partial{\\textbf{Y}}}\n\\end{align}\n\\tag{8.4}\nEquation 8.4 의 식을 이용하여 역전파 과정을 그리면 Figure 8.10 과 같이 그 과정을 표현할 수 있습니다. 주의할 것은 \\textbf{X}(\\textbf{W})의 형상과 역전파로 산출되는 \\frac{\\partial{L}}{\\partial{\\textbf{X}}}(\\frac{\\partial{L}}{\\partial{\\textbf{W}}})의 형상이 동일하다는 것입니다.\n\n\n\n\n\n\nFigure 8.10: Backward Propagation of Affine\n\n\n\n이러한 어파인 과정을 배치용 계층으로 구성할 때는 \\textbf{X}의 형상만을 변형해주면 손쉽게 구현할 수 있습니다.\n\n\n\n\n\n\nFigure 8.11: Backward Propagation of Affine for Mini-batch\n\n\n\n지금까지 설명한 Affine을 코드로 구현하겠습니다. 앞선 예들과 같이 순전파와 역전파 과정을 모두 포함합니다.,\n\nclass Affine:\n  def __init__(self, W, b):\n    self.W = W\n    self.b = b\n    self.x = None\n    self.dw = None\n    self.db = None\n\n  def forward(self, x):\n    self.x = x\n    out = np.dot(x, self.W) + self.b\n    return out\n\n  def backward(self, dout):\n    dx = np.dot(dout. self.W.T)\n    self.dw = np.dot(self.x.T, dout)\n    self.db = np.sum(dout, axis = 0)\n\n\n\n8.4.2 Softmax\nSoftmax 계층은 입력값을 정규화 하여 출력하는 계층이라 하였습니다. 이러한 소프트맥스 함수는 손실함수 인 교차 엔트로피 오차도 포함하여 Softmax-with-loss 계층으로 마지막 출력층으로 구현됩니다.\n\n\n\n\n\n\nFigure 8.12: Layer of Softmax-with-loss\n\n\n\n\n\n\n\n\n\n학습과 추론시의 Softmax 함수의 사용여부\n\n\n\n\n신경망은 학습과 추론의 작업수행합니다.\n일반적으로 Softmax 계층은 추론에서는 사용하지 않습니다.\n\nClassification의 추론문제를 예를 들어보면 산출값 중 최대값 찾는 문제입니다.\n최대값을 찾기 위하여 정규화는 필수적인 요소가 아니고 효율성을 높이기 위해 추론에서는 사용하지 않는 것입니다.\n\n반면 학습에서는 산출된 오차를 역전파를 통하여 매개변수를 업데이트 해야 하므로 정규화된 값이 필요합니다.\n\n\n\nForward Propagation\nFigure 8.13 에서 소프트맥스 계층에 사용되는 함수9를 그래프의 순전파 과정은 Figure 8.13 과 같습니다. 주의할 것은 지수의 합을 S로 표기하였다는 점입니다.\n9 y_k = \\frac{exp(a_k)}{\\sum_{i=1}^{n}exp(a_i)}\n\n\n\n\n\nFigure 8.13: Forward process of Softmax\n\n\n\nFigure 8.14 에서 크로스 엔트로피 오차 계층에 사용되는 함수10를 그래프의 순전파 과정은 Figure 8.14 과 같습니다.\n10 L=-\\sum_{k}^{}t_k\\log{y_k}\n\n\n\n\n\nFigure 8.14: Forward process of Cross-entropy\n\n\n\nBackward Propagation\n역전파는 순전파의 순서를 바꾸어 크로스 엔트로피 오차의 역전파 과정(Figure 8.15 )을 먼저 살펴보겠습니다.\n\n\n\n\n\n\nFigure 8.15: Backward process of Cross-entropy\n\n\n\n\n1단계: 교차 엔트로피 오차의 역전파 중 초깃값은 Figure 8.15 에서 가장 오른쪽값인 1(\\frac{\\partial{L}}{\\partial{L}}=1)입니다.\n2단계: 첫번째 \\times 노드의 역전파는 상류의 편미분값 1과 순전파때 입력값 중 -1을 곱하여 -1하류로 흘려보냅니다.\n3단계: + 노드의 역전파는 -1을 그대로 하류로 흘려보냅니다.\n4단계: 두번째 \\times 노드의 역전파는 상류의 편미분값 -1과 입력값 중 t_1을 곱하여 -t_1을 하류로 흘려보냅니다.\n5단계: \\log 노드의 역전파는 순전파시의 식(y=\\log{x})을 편미분한 값(\\frac{\\partial{y}}{\\partial{x}}=\\frac{1}{x}, 여기서 x를 y_1로 대입한다.)에 -t_1을 곱하여 최종결과를 산출합니다.\n\n다음으로 크로스 엔트로피 오차 계층의 결과(-\\frac{t_1}{y_1}, -\\frac{t_2}{y_2}, -\\frac{t_3}{y_3})를 사용하여 소프트맥스의 역전파 과정(Figure 8.16 )을 살펴보겠습니다. 아래 과정은 크로스 엔트로피 분모쪽의 역전파를 먼저 수행하고 분자쪽의 역잔파를 다음에 수행하며 설명하겠습니다.\n\n\n\n\n\n\nFigure 8.16: Backward process of Softmax\n\n\n\n\n1단계: 앞 계층인 크로스 엔트로피 오차 계층의 결과 값의 연전파 값이 역전파의 초깃값(-\\frac{t_1}{y_1})에 해당합니다.\n2단계: 상류에서 입력받은 값과 \\times 노드 중 분모쪽 역전파를 수행해야 하므로 순전파시 분자쪽 입력값(exp(a_1))을 곱하여 -t_1S 하류로 흘려보냅니다. 11\n\n11 -t_1S이 산출되는 과정 \n\\begin{align}\ny_1 = \\frac{\\exp(a_1)}{S} \\quad &\\rightarrow \\quad \\frac{1}{y_1} = \\frac{S}{\\exp(a_1)} \\\\\n-\\frac{t_1}{y_1}\\exp(a_1) &= -t_1\\frac{S}{\\exp(a_1)}\\exp(a_1)=-t_1S\n\\end{align}\n\n3단계: \\div(/) 노드의 순전파시에 다음 노드로 나누어 흘려 보냈으므로 역전파시에는 나누어진 값(-t_1S, -t_2S, -t_3S)들을 먼저 합하여야 합니다. 합산된 값(-t_1S+-t_2S+-t_3S = -S(t_1+t_2+t_3))에 순전파시 흘려보낸 값(\\frac{1}{S} = S^{-1})의 미분값(-S^{-2}=-\\frac{1}{S^2})을 곱하여 \\frac{1}{S}(t_1+t_2+t_3)12를 하류로 흘려보냅니다.\n4단계: 분모쪽 \\div(/) 노드를 통해 흘러들어온 \\frac{1}{S}는 + 노드를 통하여 그대로 \\frac{1}{S}을 하류로 흘려보냅니다.\n5단계: 이제 크로스엔트로피의 분자쪽 방향의 역전파를 살펴보겠습니다. \\times 노드 중 순전파시 분모쪽 입력값(\\frac{1}{S})를 상류에서 역전파를 위해 입력받은 값(-\\frac{t_1}{y_1})과 곱하여 -\\frac{t_1}{y_1}\\frac{1}{S}13를 하류로 흘려보냅니다.\n6단계: EXP노드는 앞서 부모쪽 \\div(/) 노드처럼 순전파시 exp(a_1) 을 다음노드로 나누어 흘려 보냈으므로 역전파시에는 나누어진 값(부모쪽:\\frac{1}{S}, 분자쪽:-\\frac{t_1}{exp(a_1)})들을 먼저 합하여야 합니다. 이렇게 합한 값에 순전파시 흘려보낸 값(y=\\exp(a_1))의 미분값(\\frac{\\partial{y}}{\\partial{x}}=\\exp(x))을 곱하여 최종적으로 \\frac{\\exp(a_1)}{S}-t_114 소프트맥스 계층의 역전파 값을 산출합니다.\n\n12 주의할 것은 (t_1, t_2, t_3)은 원-핫 벡터로 이들의 합은 항상 1이 됩니다. 따라서, 식을 간단히 하여 하류로 흘려보내는 값은 \\frac{1}{S}로 단순화 시킬수 있습니다.13 이식에서 y_1=\\frac{exp(a_1)}{S}를 활용하여 -\\frac{t_1}{exp(a_1)}로 단순화 킬수 있습니다.14 (\\frac{1}{S}-\\frac{t_1}{\\exp(a_1)\\exp(a_1)}\\exp(a_1))",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Backward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-backward.html#implementing-of-softmax-with-error",
    "href": "ANN-backward.html#implementing-of-softmax-with-error",
    "title": "8  Backward Propagation",
    "section": "8.5 Implementing of Softmax-with-error",
    "text": "8.5 Implementing of Softmax-with-error\n지금까지 순전파 및 역전파 과정을 계산그래프를 통하여 살펴보았습니다, 특히 Softmax-with-loss 계층을 코드로 구현하며 마무리 해 보도록 하겠습니다,15\n15 Chapter 6 에서 구현한 softmax()와 cross-entropy_error()을 활용하겠습니다.\nfrom common.functions import softmax, cross_entropy_error\n\nclass SoftmaxWithLoss:\n  def __init__(self):\n    self.loss = None\n    self.y = None\n    self.t = None\n\n  def forward(self, x, t):\n    self.t = t\n    self.y = softmax(x)\n    self.loss = cross_entropy_error(self.y, self.t)\n    return self.loss\n\n  def backward(self, dout=1):\n    batch_size = self.t.shape[0]\n    dx = (sefl.y - self.t) / batch_size\n    return dx",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Backward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-lab_Backpro.html",
    "href": "ANN-lab_Backpro.html",
    "title": "9  Lab: Implementing Backpropagation to ANN",
    "section": "",
    "text": "9.1 STEP1: Two Layer Net\n지금까지 학습한 내용을 바탕으로 기존 Two Layer Net을 새롭게 구현해 보겠습니다. 2층 신경망의 가중치 초기화 및 계층을 생성하도록 합니다.\n이후 이 계층들을 활용하여 순전파1를 우선 실행합니다. 이후 순전파시의 손실함수값을 받아 역전파를 진행합니다.\nimport sys, os\nsys.path.append(os.pardir)\nimport numpy as np\n\nfrom common.layers import *\nfrom common.gradient import numerical_gradient\nfrom collections import OrderedDict\n\nclass TwoLayerNet:\n\n  def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n    # 가중치 초기화\n    self.params = {}\n    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n    self.params['b1'] = np.zeros(hidden_size)\n    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n    self.params['b2'] = np.zeros(output_size)\n    # 계층 생성\n1    self.layers = OrderedDict()\n    self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n    self.layers['Relu1'] = Relu()\n    self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n    self.lastLayer = SoftmaxWithLoss()\n\n  def predict(self, x):\n    for layer in self.layers.values():\n2        x = layer.forward(x)\n    return x\n\n  # x :입력 데이터, t : 정답 레이블\n  def loss(self, x, t):\n    y = self.predict(x)\n    return self.lastLayer.forward(y, t)\n\n  def accuracy(self, x, t):\n    y = self.predict(x)\n    y = np.argmax(y, axis=1)\n    if t.ndim != 1: t = np.argmax(t, axis=1)\n    accuracy = np.sum(y == t) / float(x.shape[0])\n    return accuracy\n\n  # x :입력 데이터, t : 정답 레이블\n3  def numerical_gradient(self, x, t):\n    loss_W = lambda W: self.loss(x, t)\n    \n    grads = {}\n    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n    return grads\n\n  def gradient(self, x, t):\n    # 순전파\n    self.loss(x, t)\n\n    # 역전파\n    dout = 1\n4    dout = self.lastLayer.backward(dout)\n    layers = list(self.layers.values())\n5    layers.reverse()\n    for layer in layers:\n      dout = layer.backward(dout)\n\n    # 결과저장\n    grads = {}\n    grads['W1'] = self.layers['Affine1'].dW\n    grads['b1'] = self.layers['Affine1'].db\n    grads['W2'] = self.layers['Affine2'].dW\n    grads['b2'] = self.layers['Affine2'].db\n\n    return grads\n\n\n1\n\nOrderedDict의 경우 순서가 딕셔너리라 순전파 때 추가한 순서대로 연산\n\n2\n\nforward는 Affine 및 Relu클래스에 존재하는 순전파 메서드\n\n3\n\nnumerical_gradient은 시험용 수치미분 메서드, gradient는 학습용 해석미분 메서드\n\n4\n\nbackward는 Affine 및 Relu클래스에 존재하는 역전파 메서드\n\n5\n\nreverse로 layers의 순서를 뒤집어 연산이 역으로 진행되게 하는 메서드",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Lab: Implementing Backpropagation to ANN</span>"
    ]
  },
  {
    "objectID": "ANN-lab_Backpro.html#step1-two-layer-net",
    "href": "ANN-lab_Backpro.html#step1-two-layer-net",
    "title": "9  Lab: Implementing Backpropagation to ANN",
    "section": "",
    "text": "1 순전파는 hidden layers를 대상으로 하는 predict와 output layer를 대상으로 하는 loss 메서드로 구분",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Lab: Implementing Backpropagation to ANN</span>"
    ]
  },
  {
    "objectID": "ANN-lab_Backpro.html#step2-gradient-check",
    "href": "ANN-lab_Backpro.html#step2-gradient-check",
    "title": "9  Lab: Implementing Backpropagation to ANN",
    "section": "9.2 STEP2: Gradient Check",
    "text": "9.2 STEP2: Gradient Check\n오차역전파 이전에 가중치 매개변수를 업데이트하기 위하여 기울기가 필요하다고 하였습니다. 이러한 기울기는 수치미분을 써서 구하는 방법과 핵석적으로 수식을 풀어 구하는 방법이 존재합을 확인하였습니다.\n후자의 경우가 매개변수가 많아도 효율적으로 계산할 수 있음을 확인한 만큼 오차역전파를 해석적인 방법을 활용하여 구현하겠습니다.2\n2 수치미분은 구현이 쉬워 실수를 줄이고 정확한 값을 산출할 수 있습니다. 다만, 효율적이지 않은 문제가 있습니다. 따라서, 수치미분은 해석적 방법으로 구한 기울기의 값을 시험하기 위한 도구로 활용시 이점이 있습니다.\n# coding: utf-8\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nimport numpy as np\nfrom dataset.mnist import load_mnist\n# from two_layer_net import TwoLayerNet\n\n# 데이터 읽기\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n\nx_batch = x_train[:3]\nt_batch = t_train[:3]\n\ngrad_numerical = network.numerical_gradient(x_batch, t_batch)\ngrad_backprop = network.gradient(x_batch, t_batch)\n\n# 각 가중치의 절대 오차의 평균을 구한다.\nfor key in grad_numerical.keys():\n    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n    print(key + \":\" + str(diff))\n\nW1:4.838949180900964e-10\nb1:2.9738846211524536e-09\nW2:6.0533955455972435e-09\nb2:1.4023094265930293e-07",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Lab: Implementing Backpropagation to ANN</span>"
    ]
  },
  {
    "objectID": "ANN-lab_Backpro.html#step3-implementing-backpropagation-to-ann",
    "href": "ANN-lab_Backpro.html#step3-implementing-backpropagation-to-ann",
    "title": "9  Lab: Implementing Backpropagation to ANN",
    "section": "9.3 STEP3: Implementing Backpropagation to ANN",
    "text": "9.3 STEP3: Implementing Backpropagation to ANN\n기울기를 수치미분으로 구하는 방법이 아닌 해석적 방법의 연쇄법칙을 사용한 오차역전파를 사용하여 신경망학습을 구현해 보겠습니다.\n\n# coding: utf-8\nimport sys, os\nsys.path.append(os.pardir)\n\nimport numpy as np\nfrom dataset.mnist import load_mnist\n# from two_layer_net import TwoLayerNet\n\n# 데이터 읽기\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n\niters_num = 10000\ntrain_size = x_train.shape[0]\nbatch_size = 100\nlearning_rate = 0.1\n\ntrain_loss_list = []\ntrain_acc_list = []\ntest_acc_list = []\n\niter_per_epoch = max(train_size / batch_size, 1)\n\nfor i in range(iters_num):\n    batch_mask = np.random.choice(train_size, batch_size)\n    x_batch = x_train[batch_mask]\n    t_batch = t_train[batch_mask]\n    \n1    # 기울기 계산\n    #grad = network.numerical_gradient(x_batch, t_batch) # 수치 미분 방식\n    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식(훨씬 빠르다)\n    \n    # 갱신\n    for key in ('W1', 'b1', 'W2', 'b2'):\n        network.params[key] -= learning_rate * grad[key]\n    \n    loss = network.loss(x_batch, t_batch)\n    train_loss_list.append(loss)\n    \n    if i % iter_per_epoch == 0:\n        train_acc = network.accuracy(x_train, t_train)\n        test_acc = network.accuracy(x_test, t_test)\n        train_acc_list.append(train_acc)\n        test_acc_list.append(test_acc)\n        print(train_acc, test_acc)\n\n\n1\n\n수치미분방법과 해석적방법의 기울기 계산\n\n\n\n\n0.07421666666666667 0.0796\n0.90335 0.9064\n0.9232166666666667 0.9263\n0.9370333333333334 0.9386\n0.9467166666666667 0.9452\n0.9517333333333333 0.9496\n0.9575333333333333 0.9534\n0.96105 0.9575\n0.96455 0.9605\n0.9673166666666667 0.962\n0.97055 0.9652\n0.9716 0.9662\n0.9741833333333333 0.9671\n0.9752166666666666 0.9678\n0.97685 0.9677\n0.9770666666666666 0.9682\n0.9794666666666667 0.9706",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Lab: Implementing Backpropagation to ANN</span>"
    ]
  },
  {
    "objectID": "TECH-optimizer.html",
    "href": "TECH-optimizer.html",
    "title": "10  Optimaizer",
    "section": "",
    "text": "10.1 Methodologies for updating parameters\n신경망의 매개변수 최적화를 위해 우리는 기울기(편미분)를 시용하여 배개변수 값을 지속적으로 갱신하는 확률적 경사하강법(SGD)을 사용하였습니다.\n우리는 여기서 SGD의 장단점을 살펴보고 매개변수를 업데이트 하는 다른 최적화 기법들에 대하여 살펴 보도록 하겠습니다.",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimaizer</span>"
    ]
  },
  {
    "objectID": "TECH-optimizer.html#methodologies-for-updating-parameters",
    "href": "TECH-optimizer.html#methodologies-for-updating-parameters",
    "title": "10  Optimaizer",
    "section": "",
    "text": "10.1.1 Stochastic Gradient Descent(SGD)\nSGD의 수식은 다음과 같습니다, 여기서 \\textbf{w}는 갱신할 가중치이고 \\frac{\\partial{L}}{\\partial{\\textbf{W}}}는 \\textbf{w}의 손실함수에 대한 기울기 입니다. \\eta는 학습률1로 가중치를 기울기로 업데이트 하는 크기를 의미합니다.\n1 학습률의 Step size를 어떻게 정하냐에 따라 Overshotting 또는 trapping의 문제가 발생할 수 있습니다.\n\\textbf{W} \\leftarrow \\textbf{W} - \\eta\\frac{\\partial{L}}{\\partial{\\textbf{W}}}\n\n위의 식을 간단한 클래스로 구현하도록 하겠습니다.\n\nclass SGD:\n  def __init__(self, lr=0.01):\n    self.lr = lr\n\n  def update(self, params, grads):\n    for kye in params.keys():\n      params[key] -= self.lr * grads[key]\n\nnetwork = TwolayerNet(...)\noptimizer = SGD()\n\nfor i in range(10000):\n  ...\n  x_batch, t_batch = get_mini_batch(...)\n  grads = network.gradient(x_batch, t_batch)\n  params = network.params\n  optimizer.update(params, grads)\n  ...\n\nSGD의 경우 위와 같이 구현이 쉽다는 장점이 있습니다. 다만, 경우에 따라 비효율적일 때가 있기 때문에, 매개변수를 갱신하는 다른 최적화 기법들이 필요한 것입니다.\n먼저 f(x, y) = \\frac{1}{20}x^2+y^2의 합수를 이용하여 최소값을 구하는 문제를 살펴보겠습니다. 이 함수는 아래의 그림(Figure 10.1 )과 같이 그릇을 X축의 방향으로 늘인 타원과 같습니다.\n\n\n\n\n\n\nFigure 10.1: Graphs and contour lines\n\n\n\n등고선을 살펴보면 y축방향으로 가파르나 x축 방향으로는 완만한 거의 0에 가깝다는 것을 알 수 있습니다. 이러한 함수에 SGD를 적용하면 지그재그로 움직이는 비효율적인 모습을 보여줍니다. 이를 SGD의 단점 비등방성이라 하고 학습의 효율을 하락시키게 되는 것입니다.\n\n\n\n\n\n\nFigure 10.2: Update path for SGD\n\n\n\n이는 기울기의 반대방향으로 매개변수인 가중치를 갱신하는 단순성에서 나오는 문제로 이를 개선해주는 방법으로 Momentum, AdaGrad, Adam 등이 있으며 이를 살펴보도록 하겠습니다.\n\n\n10.1.2 Momentum\n모멘텀은 ’운동량’을 뜻하는 단어로 그 수식은 아래와 같습니다.\n\n\\begin{align}\n\\textbf{v} &\\leftarrow \\alpha\\textbf{v}-\\eta\\frac{\\partial{l}}{\\partial{\\textbf{W}}} \\\\\n\\textbf{W} &\\leftarrow \\textbf{W} + \\textbf{v}\n\\end{align}\n\nSGD와 가장 큰 차이점은 \\textbf{v}(velocity)가 등장하여 기울기 방향으로 힘을 받아 물체가 가속되는 물리법칙을 의미합니다. 또 하나는 \\alpha\\textbf{v}항 아무런 힘이 영향을 주지 않을 때 운동량을 약화 시키는(저항에 해당) 역할을 한다는 것입니다.\n이러한 모멘텀 클래스를 구현하면 아래와 같습니다.\n\nclass Momentum:\n  def __init__(self, lr=0.01, momentum=0.9):\n    self.lr = lr\n    self.momentum = momentum\n    self.v = None\n\n  def update(self, params, grads):\n1    if self.v is None:\n      self.v = {}\n      for key in params.items():\n          self.v[key] = np.zeros_like(val)\n    \n    for key in params.keys():\n      self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n      params[key] += self.v[key]\n\n\n1\n\nv 인스턴스변수는 초기 아무값도 담지 않고, update() 호출시 매개변수와 같은 구조의 딕셔너리 변수로 저장\n\n\n\n\n모멘텀을 이용하는 방식을 사용하는 경우 SGD에 비하여 가중치를 갱신하는 경우 지그재그로 움직이는 정도가 줄어 들었음을 확인 할 수 있습니다.\n\n\n\n\n\n\nFigure 10.3: Update path for Momentum\n\n\n\n\n\n10.1.3 AdaGrad\nAdaGrad는 신경망 학습에서 학습률을 정하는 기술로 그 수식은 아래와 같습니다.\n\n\\begin{align}\n\\textbf{h} &\\leftarrow \\textbf{h}+\\frac{\\partial{L}}{\\partial{\\textbf{W}}} \\odot \\frac{\\partial{L}}{\\partial{\\textbf{W}}} \\\\\n\\textbf{W} &\\leftarrow \\textbf{W} + \\eta\\frac{1}{\\sqrt{\\textbf{h}}}\\frac{\\partial{L}}{\\partial{\\textbf{W}}}\n\\end{align}\n\n즉, 초기에는 학습률을 크게 하고 학습이 진행됨에 따라 학습률을 작게 하는 신경망 학습 방법입니다. 이때 학습률을 낮추는 방법은 매개변수 각각에 맞는(적응하는) 학습률을 정하는 방법입니다.\n여기서 \\textbf{h}가 등장합니다. 이 값은 기울기를 제곱하여 계속 더해주게 됩니다. 그리고 매개변수인 가중치를 갱신할 때 \\frac{1}{\\sqrt{\\textbf{h}}}를 곱하여 학습률을 조정해 줍니다.\n이는 이전 스텝에서 크게 갱신된 매개변수(가중치)는 이번 스텝에서 낮은 학습률을 적용하여 원소마다 상이한 학습률을 갖도록 한다는 것으로 이해할 수 있습니다.\n이러한 AdaGrad 클래스를 구현하면 아래와 같습니다.\n\nclass AdaGrad:\n  def __init__(self, lr=0.01):\n    self.lr = lr\n    self.h = None\n\n  def update(self, params, grads):\n    if self.h is None:\n      self.h = {}\n      for key, val in params.items():\n        self.h[key] = np.zeros_like(val)\n\n    for key in params.keys():\n      self.h[key] += grads[key] * grads[key]\n      params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n\nAdaGrad를 이용한 합습경로를 보면 최솟값을 향해 효율적으로 움직이는 것을 확인할 수 있습니다.\n\n\n\n\n\n\nFigure 10.4: Update path for AdaGrad\n\n\n\n\n\n\n\n\n\nRMSProp(=EWMA)\n\n\n\n\nAdaGrad는 이전의 기울기 값들이 지속적으로 제곱하여 더해가는 방법론입니다. 이로인해 학습을 진행할수록 학습률은 0에 근접하여 갱신이 이루어지지 않을 수 있는 문제를 내포하고 있습니다.\n이러한 문제를 개선하고자 고안된 방벙이 RMSProp입니다. 이는 과거의 모든 기울기를 균일하게 더하는 것이 아니라 먼 과거의 기울기를 서서히 잊고 새로운 기울기 정보를 크게 반영하는 방법입니다.\n\n\n\n\n\n10.1.4 Adam\nAdam은 정확하지는 않지만 직관적으로 모멘텀과 AdaGrad를 융합한듯한 방법입니다. 이 두 이점을 조합했다고 단순히 이해할 수 있습니다.2\n2 Adam에 대하여 보다 자세하게 이해하기 위하여는 Adam논문을 읽어 보시기 바랍니다.이러한 Adam 클래스를 구현하면 아래와 같습니다.\n\nclass Adam:\n    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n        self.lr = lr\n        self.beta1 = beta1\n        self.beta2 = beta2\n        self.iter = 0\n        self.m = None\n        self.v = None\n        \n    def update(self, params, grads):\n        if self.m is None:\n            self.m, self.v = {}, {}\n            for key, val in params.items():\n                self.m[key] = np.zeros_like(val)\n                self.v[key] = np.zeros_like(val)\n        \n        self.iter += 1\n        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         \n        \n        for key in params.keys():\n            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])            \n            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\n\nAdam을 이용한 합습경로를 보면 앞서 설명한 바와 같이 모멘텀 및 AdaGrad가 혼합된 형태로 최솟값을 향해 효율적으로 움직이는 것을 확인할 수 있습니다.\n\n\n\n\n\n\nFigure 10.5: Update path for Adam\n\n\n\n\n\n\n\n\n\nAdam의 하이퍼파라미터\n\n\n\nAdam에는 3개의 하이퍼파라미터를 설정해야 합니다.\n\n\\alpha: 매개변수 업데이트 정도인 학습률\n\\beta_1: 1차 모멘텀 계수로 논문에서는 0.9를 기본값으로 설정\n\\beta_2: 2차 모멘텀 계수로 논문에서는 0.999를 기본값으로 설정",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimaizer</span>"
    ]
  },
  {
    "objectID": "TECH-optimizer.html#comparing-methodologies-for-updating-parameters",
    "href": "TECH-optimizer.html#comparing-methodologies-for-updating-parameters",
    "title": "10  Optimaizer",
    "section": "10.2 Comparing Methodologies for Updating Parameters",
    "text": "10.2 Comparing Methodologies for Updating Parameters\n우리가 살펴본 4가지의 모델 중 과연 어떠한 모델이 좋을까요? 이런 물음에 대한 답은 아직까지는 없다 입니다. 이는 문제의 성격에 따라 모델별로 잘 푸는 문제가 따로 있기 때문입니다.\n이러한 모델의 비교는 성능을 측정하여 우월성을 판단하기 위한 것이 아니라 모델별 성격에 따라 학습의 진도가 어떻게 다른지 이해하기 위함합니다.\n먼저 MNIST 데이터 셋을 이용하여 손글씨 인식문제의 학습진도를 비교해 보도록 하겠습니다.\n\n\n\n\n\n\nFigure 10.6: Training progress by model on the MNIST dataset\n\n\n\n위 비교에 사용된 신경망은 각층이 100개의 뉴런으로 구성된 5층 신경망에 ReLU를 활성화 함수로 사용한 결과 입니다. SGD의 학습 진도가 가장느리고 나머지 3가지 모델은 학습 진도가 매우 유사합니다.\n이러한 결과는 일반적인 결과이고 나머지 3개의 모델은 학습률 등 하이퍼파라미터의 설정 또는 신경망의 구조에 따라 결과가 달리 나올수 있다는 점만 이해하도록 하겠습니다.",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimaizer</span>"
    ]
  },
  {
    "objectID": "TECH-initializing.html",
    "href": "TECH-initializing.html",
    "title": "11  Initializing parameters",
    "section": "",
    "text": "11.1 Weighting initialization when using Sigmoid functions\n(Distribution of activation values in the hidden layer)\n은닉층의 화성화값은 활성화 함수에서 출력되는 데이터를 말합니다.\n스탠퍼드 대학교의 CS231n의 수업에서 시그모이드 함수로 구현된 은닉층에 무작위로 생성한 입력데이터를 넣어 출력되는 데이터의 분포를 히스토그램으로 그려보았습니다.\n먼저 수업에 사용된 코드는 아래와 같습니다.\n# coding: utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef ReLU(x):\n    return np.maximum(0, x)\n\ndef tanh(x):\n    return np.tanh(x)\n    \ninput_data = np.random.randn(1000, 100)  # 1000개의 데이터\nnode_num = 100  # 각 은닉층의 노드(뉴런) 수\nhidden_layer_size = 5  # 은닉층이 5개\nactivations = {}  # 이곳에 활성화 결과를 저장\n\nx = input_data\n\nfor i in range(hidden_layer_size):\n    if i != 0:\n        x = activations[i-1]\n\n    # 초깃값을 다양하게 바꿔가며 실험해보자！\n1    w = np.random.randn(node_num, node_num) * 1\n    # w = np.random.randn(node_num, node_num) * 0.01\n    # w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n    # w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)\n\n    a = np.dot(x, w)\n\n    # 활성화 함수도 바꿔가며 실험해보자！\n2    z = sigmoid(a)\n    # z = ReLU(a)\n    # z = tanh(a)\n\n    activations[i] = z\n\n# 히스토그램 그리기\nfor i, a in activations.items():\n    plt.subplot(1, len(activations), i+1)\n    plt.title(str(i+1) + \"-layer\")\n    if i != 0: plt.yticks([], [])\n    # plt.xlim(0.1, 1)\n    # plt.ylim(0, 7000)\n    plt.hist(a.flatten(), 30, range=(0,1))\nplt.show()\n\n\n1\n\n가중치 초깃값 설정 코드\n\n2\n\n활성화 함수 설정 코드\n위 소스코드에서 가중치 초기화를 표준편차가 1인 정규분포, 표준편차가 0.01인 정규분포 그리고 Xavier1의 방법을 사용하여 가중치의 활성화값 분포를 확인해보면 아래와 같습니다.\n표준편차가 1인 정규분포를 이용한 가중치 초기화시에는 0과 1로 치우치는 모습이 보입니다. 이는 역전파시에 기울기 값을 점점 작아시게 하여 기울기 소실(8gradient vanising)의 문제를 야기합니다.\n표준편차가 0.01인 정규분포를 이용한 가중치 초기화시에는 0.5에 집중되는 모습이 보입니다. 노드별 값의 차이점이 없어 표현력 제한의 문제를 야기합니다.\nXavier의 방법은 모든 노드에 골고루 분포되어 기울기 소실 또는 표현력 제한의 이슈를 해결할 수 있는 것으로 보입니다. 현재 일반적으로 딥러닝의 표준으로 사용됩니다.",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Initializing parameters</span>"
    ]
  },
  {
    "objectID": "TECH-initializing.html#weighting-initialization-when-using-sigmoid-functions",
    "href": "TECH-initializing.html#weighting-initialization-when-using-sigmoid-functions",
    "title": "11  Initializing parameters",
    "section": "",
    "text": "1 Xavier는 이전 노드의 갯수가 n개인 경우 표준편차가 \\frac{1}{\\sqrt{n}}인 분포를 사용하는 방식입니다.\n\n\n\n\n\n\n\nNormmal Distribution with STD = 1\n\n\n\n\n\n\n\n\n\nNormmal Distribution with STD = 0.01\n\n\n\n\n\n\n\n\n\nXavier\n\n\n\n\n\n\nFigure 11.1: Distribution of activation values by weight initialization methodology\n\n\n\n\n\n\n\n\n\n\n\n\n층이 깊어질 수록 분포가 고르지 않은 이유\n\n\n\n시그모이드 함수의 대칭저은 (x, y) = (0, 0.5)이다. 따라서, 층을 지나갈수록 활성화 값이 고르지 않게 나오는 것입니다. 이를 해결하기 위하여는 원점에 대하여 대칭인 tahn함수를 고려할 수 있습니다.",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Initializing parameters</span>"
    ]
  },
  {
    "objectID": "TECH-initializing.html#weighting-initialization-when-using-relu-functions",
    "href": "TECH-initializing.html#weighting-initialization-when-using-relu-functions",
    "title": "11  Initializing parameters",
    "section": "11.2 Weighting initialization when using ReLU functions",
    "text": "11.2 Weighting initialization when using ReLU functions\nReLU 함수는 앞서 살펴본 Sigmoid와 달리 비선형함수입니다. 따라서 가중치의 초깃값 설정 방법도 다르지 않을까요? 맞습니다. ReLU에 특회된 초깃값 설정 방법으로 He 초깃값이 존재합니다.\n이는 Xavier와 비슷하게 이전 노드의 갯수가 n개일 때, 표준편차가 {\\sqrt\\frac{2}{n}}인 정규 분포를 사용합니다. 이는 ReLU가 음의 영역이 0이라서 더 넓게 분포시키기 위해 2배의 계수가 필요하다고 해석할 수 있습니다.\n그럼 앞서 Sigmoid와 같이 표준편차가 0.01인 정규분포, Xavier 그리고 He초깃값의 방법을 사용하여 가중치의 활성화값 분포를 확인해보면 아래와 같습니다.\n\n\n\n\n\n\nFigure 11.2: Distribution of activation values by weight initialization methodology\n\n\n\n표준편차가 0.01인 정규분포를 이용한 가중치 초기화시에는 각 층의 활성화값이 아주 작은값들이 나오게 되어 역전파시 학습이 거의 이루어지지 않는 문제를 갖고 있습니다.\nXavier의 방법은 층이 깊어 질수록 한쪽으로 치우짐이 커지고, 학습시 기울기 소실의 문제를 갖고 있습니다.\nHe 초깃값은 모든 층에서 활성화 값이 균일하가 분포되어 역전파시에 적절한 학습을 기대할 수 있습니다.\n\n\n\n\n\n\n활성화값의 분포\n\n\n\n\n초깃값의 설정은 활성화함수를 거쳐 나오는 출력값 즉, 활성화값의 분포를 결정합니다. 적절한 학습을 위해서는 활성화값이 균일하게 분포되고 기울기 소실 또는 표현력 문제를 야기하지 않아야 합니다.\n결과적으로 Sigmoid는 Xavier, ReLU는 He초깃값을 활용하여 가중치 초깃값을 설정할 경우 활성화값의 분포를 어느 한쪽에 치우침없이 균일하게 설정할 수 있습니다.",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Initializing parameters</span>"
    ]
  },
  {
    "objectID": "TECH-batchnorm.html",
    "href": "TECH-batchnorm.html",
    "title": "12  Batch Normalization",
    "section": "",
    "text": "12.1 Algorithm of Batch Normalization\n배치정규화는 학습의 효율성과 정확성을 증가시키는 등 강점은 명확합니다.\n그렇다면 배치정규화는 무엇일까요? 배치정규화는 이름에서 알수 있듯이 미니배치를 단위로 정규화를 진행하는 것으로 데이터 분포가 평균 0, 분산이 1이 되도록 정규화 하는 방법으로 그 수식은 아래와 같습니다.\n\\begin{align}\n\\mu_{B} &\\leftarrow \\frac{1}{m}\\sum^{m}_{i=1}x_i \\\\\n\\sigma^2_B &\\leftarrow \\frac{1}{m}\\sum^{m}_{i=1}(x_i-\\mu_B)^2 \\\\\n\\hat{x}_i &\\leftarrow \\frac{x_i-\\mu_B}{\\sqrt{\\sigma^2_B+\\epsilon}}\n\\end{align}\n미니배치(B=\\{x_1, x_2, \\cdots, x_m\\})에 m개의 입력 데이터가 존재할때 해당 미니배치의 평균과 분산을 구하여 입력 데이터를 평균이 0, 분산이 1이되도록 정규화를 진행합니다.1\n이렇게 정규화한 데이터를 활성화함수 앞 또는 뒤에 삽입함으로써 활성화 함수값의 분포를 고르게 만들 수 있습니다.\n또 하나 주목할 만한 것은 정규화 계층마다 고유한 확대(scale) 및 이동(shift) 변환을 수행할 수 있다는 것이고 이러한 확대 및 변환에 관한 수식은 아래와 같습니다.\ny_i \\leftarrow \\gamma\\hat{x}_i+\\beta\n여기서 \\gamma는 확대를 담당하고 1부터 시작합니다. 그리고 \\beta는 이동을 담당하고 0부터 시작합니다.\n이 알고리즘은 순전파때 적용되고 아래와 같이 계산그래프(Figure 12.1 )로 표현이 가능합니다.\n이 알고리즘의 역전파에 대한 계산그래프는 추후 정리하여 업데이트 하도록 하겠습니다.",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Batch Normalization</span>"
    ]
  },
  {
    "objectID": "TECH-batchnorm.html#algorithm-of-batch-normalization",
    "href": "TECH-batchnorm.html#algorithm-of-batch-normalization",
    "title": "12  Batch Normalization",
    "section": "",
    "text": "학습을 빨리 진행할수 있다.(학습속도 개선)\n초깃값에 크게 의존하지 않는다(골치아픈 초깃값 선택 장애 회피)\n오버피팅을 억제한다(드롭아웃 등의 필요성 감소)\n\n\n\n\n1 \\epsilon은 아주 작은값을 의미하며 0으로 나누게 되는 경우를 방지하기 위합입니다.\n\n\n\n\n\n\n\n\n\n\nFigure 12.1: Graph of process for Batch Normalization",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Batch Normalization</span>"
    ]
  },
  {
    "objectID": "TECH-batchnorm.html#effects-of-batch-normalization",
    "href": "TECH-batchnorm.html#effects-of-batch-normalization",
    "title": "12  Batch Normalization",
    "section": "12.2 Effects of Batch Normalization",
    "text": "12.2 Effects of Batch Normalization\n배치 졍규화를 실시하면 사용하지 않을 때보다 학습 진도(?)가 더 빨라진다는 것을 확인할 수 있습니다.\n\n\n\n\n\n\nFigure 12.2: Effects of Batch Normalization\n\n\n\n배치 정규화를 사용한 경우에 빨라지는 학습 진도(?)는 가중치 초깃값의 표준편차를 무엇으로 하느냐에 크게 영향을 받지않고 있음을 아래의 그림을 통해 확인할 수 있습니다.\n\n\n\n\n\n\nFigure 12.3: Effects of Batch Normalization",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Batch Normalization</span>"
    ]
  },
  {
    "objectID": "TECH-overfitting.html",
    "href": "TECH-overfitting.html",
    "title": "13  Overfitting",
    "section": "",
    "text": "13.1 Understanding overfitting\n오버피팅의 문제를 해결하기 위해서는 어떠한 상황에서 오버피팅이 발생하는지에 대한 이해가 필요합니다.\n위의 상황을 살펴보기 위해 7층의 신경망을 사용하여 네트워크의 복잡성을 지나치게 높이고, 60,000개인 MNIST 데이터셋의 훈련데이터 중 아주 적은 300개만 사용한다면 오버피팅이 발생할까요?\nMNIST 데이터를 이용하여 훈련데이터와 시험데이터의 정확도를 아래 구현된 코드를 활용하여 비교해보도록 하겠습니다.\n# coding: utf-8\nimport os\nimport sys\n\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom dataset.mnist import load_mnist\nfrom common.multi_layer_net import MultiLayerNet\nfrom common.optimizer import SGD\n\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n\n# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임\nx_train = x_train[:300]\nt_train = t_train[:300]\n\n# weight decay（가중치 감쇠） 설정 =======================\nweight_decay_lambda = 0 # weight decay를 사용하지 않을 경우\n# weight_decay_lambda = 0.1\n# ====================================================\n\nnetwork = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\n                        weight_decay_lambda=weight_decay_lambda)\noptimizer = SGD(lr=0.01) # 학습률이 0.01인 SGD로 매개변수 갱신\n\nmax_epochs = 201\ntrain_size = x_train.shape[0]\nbatch_size = 100\n\ntrain_loss_list = []\ntrain_acc_list = []\ntest_acc_list = []\n\niter_per_epoch = max(train_size / batch_size, 1)\nepoch_cnt = 0\n\nfor i in range(1000000000):\n    batch_mask = np.random.choice(train_size, batch_size)\n    x_batch = x_train[batch_mask]\n    t_batch = t_train[batch_mask]\n\n    grads = network.gradient(x_batch, t_batch)\n    optimizer.update(network.params, grads)\n\n    if i % iter_per_epoch == 0:\n        train_acc = network.accuracy(x_train, t_train)\n        test_acc = network.accuracy(x_test, t_test)\n        train_acc_list.append(train_acc)\n        test_acc_list.append(test_acc)\n\n        # print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n\n        epoch_cnt += 1\n        if epoch_cnt &gt;= max_epochs:\n            break\n\n\n# 그래프 그리기==========\nmarkers = {'train': 'o', 'test': 's'}\nx = np.arange(max_epochs)\nplt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\nplt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.ylim(0, 1.0)\nplt.legend(loc='lower right')\nplt.show()\n훈련 데이터를 사용한 정확도는 epoch가 100을 지날 무렴 정확도는 100%에 근접함에 반하여 시험 데이터를 사용한 정확도는 60%~70% 수준에 머무르는 것을 확인할 수 있습니다.\n이는 결국 훈련 데이터에만 지나치게 적용(fitting)하여 시험 데이터 등에 대한 범용성을 확보하지 못하였음을 즉, 오버피팅이 발생하였음을 보여줍니다.",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Overfitting</span>"
    ]
  },
  {
    "objectID": "TECH-overfitting.html#understanding-overfitting",
    "href": "TECH-overfitting.html#understanding-overfitting",
    "title": "13  Overfitting",
    "section": "",
    "text": "매개변수가 많고 표현력이 높은 모델\n훈련 데이터가 적은 경우",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Overfitting</span>"
    ]
  },
  {
    "objectID": "TECH-overfitting.html#weight-decay",
    "href": "TECH-overfitting.html#weight-decay",
    "title": "13  Overfitting",
    "section": "13.2 Weight decay",
    "text": "13.2 Weight decay\n첫번째로 살펴볼 오버피팅을 억제하는 수단으로는 가중치 감소(weight decay, \\lambda)가 있습니다. 이는 학습과정 에서 가장 큰 가중치에 대해서는 그에 상응하는 큰 패널티를 부과하는 방법입니다.1\n1 L(\\textbf{w})+\\frac{1}{2}\\lambda\\textbf{W}^2페널티는 어떻게 산출해야 할까요? 순전파시에 손실함수 값에 \\frac{1}{2}\\lambda\\textbf{W}^2를 더하여 역전파시 가중치 업데이트 과정에서 그 마분값인 \\lambda\\textbf{W}를 더하게 되어 가중치가 큰 곳에 더 큰 패널티가 산출됩니다.\n정규화의 강도를 조절, 즉, 강중치 감소 정도는 하이퍼파라미터인 \\lambda로 조절합니다.\n\n\\begin{align}\n\\textbf{L}^* &= \\textbf{L}(\\textbf{W})+\\frac{1}{2}\\lambda\\textbf{W}^2 \\\\ \\\\\n\\textbf{W} &= \\textbf{W} - \\eta\\frac{\\partial{\\textbf{L}^*}}{\\partial{\\textbf{W}}} \\\\\n&= \\textbf{W} - \\eta\\frac{\\partial{(\\textbf{L}+\\frac{1}{2}\\lambda\\textbf{W}^2)}}{\\partial{\\textbf{W}}} \\\\\n&= \\textbf{W} - \\eta(\\frac{\\partial{\\textbf{L}}}{\\partial{\\textbf{W}}}+\\frac{\\partial\\frac{1}{2}\\lambda\\textbf{W}^2}{\\partial{\\textbf{W}}}) \\\\\n&= \\textbf{W} - \\eta(\\frac{\\partial{\\textbf{L}}}{\\partial{\\textbf{W}}}+\\lambda\\textbf{W})\n\\end{align}\n\n\n\n\n\n\n\nL2 Norm을 손실함수 값에 더한다? 그런데 왜 \\sqrt{w_1^2+w_2^2+\\cdots+w_i^2}이지?\n\n\n\n\nL2 Norm은 \\sqrt{w_1^2+w_2^2+\\cdots+w_i^2} 꼴로 나타나느데 왜 딥러닝의 가중치감소에서는 손실함수에 더하는 L2 Norm을 \\frac{1}{2}\\lambda\\textbf{W}^2으로 정의되었을까요?\n먼저 \\frac{1}{2}항을 살펴보면 이는 수학적 편의를 위한 트릭에 해당합니다. 더해진 값을 역전파시 미분해야 하는데 \\lambda|\\textbf{W}|_2^2을 미분하는 것보다 \\frac{1}{2}\\lambda|\\textbf{W}|_2^2을 미분하여 \\lambda\\textbf{W}가 되면 보다 식을 단순하게 만들 수 있기 때문입니다.\nL2 Norm의 제곱은 어디로 갔을까요? 이는 최적화 과정에서 모델 가중치 \\textbf{W}를 업데이트할때 제곱근 연산이 필요없기 때문에 불필요한 내용을 생락한 것입니다.\n\n\n\n지금까지 살펴 본 내용을 바탕으로 가중치 감소에 따른 효과를 살펴 보도록 하겠습니다. 하이퍼파라미터인 \\lambda는 0.1로 설정하여 가중치 감소를 적용하였습니다.\n\n\n\n\n\n\n\n\n\n여전히 오버피팅이 발생하고 있지만 이전과 비교하여 상당부분 훈련 데이터와 시험 데이터간 정확도의 차이가 줄어든 것을 확인할 수 있습니다. 즉, 오버피팅이 억제된 효과를 확인할 수 있습니다.",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Overfitting</span>"
    ]
  },
  {
    "objectID": "TECH-overfitting.html#dropout",
    "href": "TECH-overfitting.html#dropout",
    "title": "13  Overfitting",
    "section": "13.3 Dropout",
    "text": "13.3 Dropout\n오버피팅을 억제하기 위하여 가중치 감소를 사용하였습니다. 구현도 쉽고 효과도 어느정도 확인하였습니다. 그러나 신경망의 모델이 복잡해지면 가중치 감소만으로는 적절한 대으이 어려울 수 있습니다.\n이러한 문제를 해결하고자 고안된 기법이 바로 드롭아웃입니다. 드롭우웃은 신경망의 각층의 노드를 훈련과정에서 임의로 삭제하면서 신호전달을 차단하는 방법입니다. 다만, 시험 또는 시험과정에서는 모든 노드를 사용합니다.2\n2 주의 할 것은 시험 과정에서 각 노드 또는 뉴런의 출력에 훈련때 삭제 안한 비율을 곱하여 출력을 수행합니다.\n\n\n\n\n\nFigure 13.1: Concept of Dropout\n\n\n\n위에서 설명한 드롭아웃을 구현하도록 하겠습니다. 먼저 순전파를 담당하는 forward메서드에서는 훈련 때(train_flg=True)만 잘 계산해두면 시험 때 단순히 데이터를 흘리기만 하면됩니다.3\n3 삭제 안한 비율은 곱하지 않아도 됩니다.\nclass Dropout:\n  def __init__(self, dropout_ratio=0.5):\n    self.dropout_ratio = dropout_ratio\n    self.mask = None\n\n  def forward(self, x, train_flg=True):\n    if train_flg:\n1      self.mask = np.random.rand(*x.shape) &gt; self.dropout_ratio\n      return x * self.mask\n    else:\n      return x * (1.0 - self.dropout_ratio)\n\n  def backward(self, dout):\n2    return dout * self.mask\n\n\n1\n\nself.mask에 삭제할 뉴런을 False로 표시\n\n2\n\nbackwardsms ReLU와 동작원리가 같음\n\n\n\n\n위의 구현코드를 가지고 실험한 7층의 신경망의 학습결과입니다.\n\n\n\n\n\n\nFigure 13.2: Comparison of results(without Dropout(Left), with Dropout(Right))\n\n\n\n드롭아웃을 적용한 경우 훈련 데이터와 시험 데이터간 정확도의 차이가 확연하게 줄어 들었음을 확인할 수 있습니다. 동시에 표현력도 상당히 개선되었음을 확인할 수 있습니다.\n\n\n\n\n\n\nDropout과 앙상블 학습\n\n\n\n\n기계학습에서 앙상블 학습(ensemble learning)은 개별적으로 학습시킨 여러 모델의 출력을 평균내어 추론하는 방식입니다.\n드롭아웃은 무작위로 노드 또는 뉴련을 삭제함으로써 각기 다른 신경망을 학습시킨후 평균을 내어 답하는 것과 비슷합니다.",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Overfitting</span>"
    ]
  },
  {
    "objectID": "TECH-settingparam.html",
    "href": "TECH-settingparam.html",
    "title": "14  Finding the appropriate hyperparameters",
    "section": "",
    "text": "14.1 Validation Data\n앞서 모델의 정확성 및 범용성을 높이기(오버피팅의 억제 등) 위하여 훈련 데이터와 시험 데이터를 나누어 사용하였습니다. 그러나 하이퍼파라미터의 다양한 값을 설정하고 시험하는 경우에는 시험 데이터를 사용해서는 안된다는 사실을 잘 기억해야 합니다.\n하이퍼파라미터 시험시 시험 데이터를 사용하지 않는 이유는 시험 데이터를 사용하여 하이퍼파라미터를 조정하는 경우 시험 데이터에 과적합될 수 있기 때문입니다.\n그래서 하이퍼파라미터를 조정할 때는 하이이퍼파라미터 전용 검증 데이터를 만들어 사용합니다.\n데이터셋에 따라 위와 같이 3가지 데이터로 분류되는 경우도 있지만 사용자가 직접 분류를 해야 하는 경우도 있습니다. 아래는 MNIST 데이터셋을 활용하여 훈련 데이터에서 20%의 검증 데이터를 얻는 방법을 구현해보겠씁니다.\nfrom dataset.mnist import load_mnist\nfrom common.util import shuffle_dataset\n\n(x_train, t_train), (x_test, t_test) = load_mnist()\n\n# 훈련 데이터 뒤섞기\nx_train, t_train = shuffle_dataset(x_train, t_train)\n\n# 20%의 검증 데이터 얻기\nvalidation_rate = 0.20\nvalidation_num = int(x_train.shape[0] * validation_rate)\n\nx_val = x_train[:validation_num]\nt_val = t_train[:validation_num]\nx_train = x_train[validation_num:]\nt_train = t_train[validation_num:]",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Finding the appropriate hyperparameters</span>"
    ]
  },
  {
    "objectID": "TECH-settingparam.html#validation-data",
    "href": "TECH-settingparam.html#validation-data",
    "title": "14  Finding the appropriate hyperparameters",
    "section": "",
    "text": "신경망 학습시 사용하는 데이터의 종류\n\n\n\n\n훈련 데이터: 매개변수 학습에 사용\n검증 데이터: 하이퍼파라미터 성능평가에 사용\n시험 데이터: 신경망의 정확성 및 범용성 성능평가에 사용",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Finding the appropriate hyperparameters</span>"
    ]
  },
  {
    "objectID": "TECH-settingparam.html#optimization-for-hyperparameters",
    "href": "TECH-settingparam.html#optimization-for-hyperparameters",
    "title": "14  Finding the appropriate hyperparameters",
    "section": "14.2 Optimization for hyperparameters",
    "text": "14.2 Optimization for hyperparameters\n앞서 하이퍼파라미터용 데이터인 검증 데이터를 획득하였습니다. 이제 본격적으로 검증 데이터를 이용하여 하이퍼파라미터의 최적 값을 찾는 과정을 살펴보겠습니다.\n여기서 말하는 최적 값은 근사 값을 찾아가는 과정으로 최적 값이 존재하는 벙위를 좁혀 나가는 과정을 사용합니다2. 먼저 대략적인 범위3를 설정하여 정확도를 측정하는 절차를 반복 수행하여 최적 값의 범위를 줄여 나갑니다.\n2 하이퍼파라미터 최적화시 오랜시간이 걸리는 바 결과 좋지 못한 값 또는 범위는 일찍 포기하는 것이 좋습니다.(예: 학습을 위한 에폭을 작게설정하여 1회 평가 시간 단축하는 등의 방법 사용)3 대략적인 범위는 통항 Log scale(10의 지수승)로 지정4 아래의 내용들이 다소 직관에 의존하는 느낌이 드는 경우 베이즈 최적화(Beyesian optimization)을 활용가능(Practical Nayesian Optimization of Machine Learing Algorithms)위의 내용을 정리하면 아래의 단계를 따릅니다.4\n\n0단계\n\n하이퍼파라미터 값의 범위를 설정합니다.\n\n1단계\n\n설정된 범위에서 하이퍼파라미터의 값을 무작위로 추추합니다.\n\n2단계\n\n1단계에서 샘플링한 하이퍼파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도를 평가합니다.(이 과정의 에폭은 작게 설정)\n\n3단계\n\n1단계와 2단계를 특정횟수(100회 등) 반복하며, 그 정확도의 결과를 보고 하이퍼파라미터의 범위를 좁히도록 합니다.\n\n\n위의 절차에 따라 하이퍼파라미터의 최적화를 실시해보독 하겠습니다.\n\nimport numpy as np\nweight_decay = 10** np.random.uniform(-8, -4)\nlr = 10 ** np.random.uniform(-6, -2)\n\n위와 같이 가중치 감소 계수의 범위를 10^{-8}\\sim10^{-4}로 설정하여 무작위로 추출하고, 학습률의 범위를 10^{-6}\\sim10^{-2}로 설정하여 무작위로 추출해 보겠습니다.\n\n\n\n\n\n\nFigure 14.1: Accuracy of validation and training data per hyperparameter\n\n\n\n위의 그림을 살펴보면 ’Best-5’까지의 검증데이터의 학습 결과가 매우 좋은 것을 확인할 수 있습니다. 이러한 결과를 바탕으로 학습률은 0.001~0.01, 가중치 감소계수는 10^{-8}\\sim10^{-4}가 적당한 범위라 할 수 있습니다.\n이후 이 범위 내에서 다시 범위를 좁혀가며 학습을 진행하며 최종적인 하이퍼파라미터값을 최적화 할 수 있습니다.",
    "crumbs": [
      "Learning technologies",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Finding the appropriate hyperparameters</span>"
    ]
  },
  {
    "objectID": "CNN-intro.html",
    "href": "CNN-intro.html",
    "title": "15  Convolution Neural Networks",
    "section": "",
    "text": "작성예정",
    "crumbs": [
      "CNN",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Convolution Neural Networks</span>"
    ]
  }
]