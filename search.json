[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DeepLearning x 101",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "DeepLearning x 101",
    "section": "Welcome",
    "text": "Welcome\n최근 전세계적으로 AI에 대한 관심이 증가하고 있습니다. 특히 OPEN AI의 Chat-GPT를 시작으로 다양한 생성형 AI가 발표되고 있습니다다.\n이러한 AI 발전의 기초가되는 기술은 Machinelearning과 Deeplearning이 있습니다. 이중 가장 기초가 되는 Deeplearning을 활용하여 Data에서 사람이 찾을 수 없는 Features와 Patterns을 기계를 활용하여 찾기 위한 기술을 학습하고자 합니다.\n이 사이트는 앞서 말한바와 같이 날로 중요해지는 Deeplearning에 대한 기초적인 이해부터 구현까지 학습하는 과정에 대한 기록물입니다. 나아가 Deeplearning기술을 활용하여 금융분야에 활용할 수 있는 방법을 연구하거나, 현재 다양한 금융공학의 기술과 접목시키고자 합니다.\n또한, Deeplearning과 관련된 사항들 수식과 이론에 기반하여 기초적인 사항들을 가급적 빠짐없이 다룰 예정입니다. 또한, Deeplearning과 관련된 내용을 ’engineering’관점에서 실제 기능을 구현하기 위한 코드를 포함할 예정이며, 이러한 소스 코드를 통해 이해의 폭을 높이고자 합니다. 물론 모든 코드와 그에 따른 결과는 매 페이지에서 확인할 수 있습니다.\n\n\n\n\n\n\nNote\n\n\n\n본 사이트는 Quarto를 기반으로 작성되었으며 실습환경에 관하여는 Table 1 을 참고하기 바랍니다. 본 사이트 구축에 관한 소스 코드는 GitHub에서 확인할 수 있습니다.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#disclaimer",
    "href": "index.html#disclaimer",
    "title": "DeepLearning x 101",
    "section": "Disclaimer",
    "text": "Disclaimer\n이 사이트는 모두에게 무료이며, “Deep Learning from Scratch”를 기반으로 학습자들이 연구한 내용을 담고 있습니다. 모든 내용에 대하여 출처를 밝힐 예정이나, 간혹 출처가 빠져 있는 경우 지속적으로 업데이트 하여, 원작자들의 권리를 침해하지 않고 오류를 수정해 나갈 것입니다.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Learning Path\n필자들의 DL 학습배경에 따라 아래의 경로로 DL을 학습할 계획이며 많은 문헌에서 다루고 있는 학습경로 입니다.\n학습경로가 정확한지? 적절한지? 알 수 없지만, 적어도 A to Z의 관점에서 빠짐없이 모든 내용을 학습해보기로 하였습니다.\n학습경로에 관한 내용은 Figure 1 을 참고하기 바라며, 학습을 수행하는 과정마다 변경되거나 추가되는 사항은 지속적으로 반영해 나갈 예정입니다.\nflowchart LR\n  opt[Optimazation]:::ch --&gt; opt1[Solving Problems]\n  opt --&gt; opt2[Gradient Descent] \n\n  opt1 --&gt; opt_l{{Lab1: Linear Regression}}\n  opt2 --&gt; opt_l:::lab\n\n  per[Perceptron]:::ch --&gt; per1[Classification]\n  per --&gt; per2[Logistic Regression]\n\n  per1 --&gt; per_l1{{Lab2: Classification}}:::lab\n  per2 --&gt; per_l2{{Lab2: Logistic Regression}}:::lab\n\n  %% ann[ANN]:::ch --&gt; ann1[Multi Layer Perceptron] --&gt; ann_l{{Lab3:}}:::lab\n  %% ann --&gt; ann2[Artificial NN?]\n\n  %% ann2 --&gt; ann2_1[Recursive Algorithm]\n  %% ann2 --&gt; ann2_2[Dynamic Programing]\n  %% ann2 --&gt; ann2_3[Neural Networks]\n  \n  %% ann2_3 --&gt; ann2_3_3[Loss Function]\n  %% ann2_3 --&gt; ann2_3_1[Optimization]\n  %% ann2_3 --&gt; ann2_3_2[Activation Function]\n\n  %% ann2_1 & ann2_2 & ann2_3_1 & ann2_3_2 & ann2_3_3 --&gt; ann_l{{Lab3: MNIST Classification}}:::lab\n  \n  %% cnn[Convolution-NN]:::ch --&gt; cnn1[NA]\n\n  %% rnn[Recurrent-NN]:::ch --&gt; rnn[NA]\n\n  classDef ch fill:#ccccff\n  classDef lab fill:#ccffcc\n\n\n\n\nFigure 1: Learning Path",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#environment",
    "href": "intro.html#environment",
    "title": "Introduction",
    "section": "Environment",
    "text": "Environment\n우리가 학습하며 사용한 실습환경에 대하여 간단하게 소개하겠습니다.\n누구나 접근이 가능한 Python을 기반으로 하고 있고, 실습에 사용하는 라이브러리(Table 1 )는 의존도를 최소화 하기 위하여 numpy를 주로 사용하였습니다. 그리고 실습결과를 도식화하기 위하여는 matplotlib을 사용하였습니다.\n이론에 대한 충분한 실습을 완료한 뒤에는 tensorflow 또는 torch를 사용하기로 하였습니다. 이는 NVIDIA의 GPU를 활용하여 보다 Deep한 신경망을 구현하기 위함임을 참고하여 주시고 학습과정에서 본 Framework의 사용은 최소화 할 예정입니다.\n학습경로와 마찬가지로 아래의 테이블에 적시된 라이브러리와 그 버전은 수시로 업데이트 할 예정입니다.\n\n\n\n\n\n\nName\nVersion\n\n\n\n\nnumpy\n#.#.#\n\n\nmatplotlib\n#.#.#\n\n\ntensorflow\n#.#.#\n\n\ntorch\n#.#.#\n\n\n\n\n\nTable 1: List of Packages",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#how-to-read",
    "href": "intro.html#how-to-read",
    "title": "Introduction",
    "section": "How to read",
    "text": "How to read\n이 사이트에서 다루는 내용은 기본적인 이론에 대한 설명과 이와 관련된 코드와 그 실행 결과 들을 보여줄 것입니다.\nCode Example\n\n기본적으로 코드는 아래의 Code Block에서 모든 내용을 표시하였습니다.\n특별히 중요하거나 추가적인 설명이 필요한 경우 Code Annotation에 표시하였습니다.\n\n\n\n\nListing 1: Code Block\n\n\n\ndef add(num1, num2):\n1  result = num1 + num2\n  return  result\n\n\n1\n\nnum1과 num2를 더하여 result에 할당\n\n\n\n\n\n\n\nEquation Example\n\n수식 중 설명이 필요한 경우는 기본적으로 본문에 내용을 표시하였습니다.\n설명이 완료된 수식 중 참고할 사항은 margin컬럼에 표시였습니다.\n\n\n\n\nListing 2: Equation\n\n\n\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\n\n\n\n\n\nWe know from the first fundamental theorem of calculus that for x in [a, b]:\n\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\nCallout Example\n\n학습을 진행해 가는 과정에서 나오는 이슈사항은 Callout으로 표시해 두었습니다,\n각 Callout이 담아야 할 내용은 아래를 참고하여 주시기 바랍니다.\n\n\n\n\nListing 3: Callout\n\n\n\n\n\n\n\n\nNote의 활용법\n\n\n\n\n본문의 내용과 직접관련된 내용으로 부가적인 설명을 담고 있습니다.\n관련 문헌이나 자료들에서 중요한 부분을 발췌한 내용을 담고 있습니다.\n필자가 보다 효율적이라고 판단한 내용들을 보여주고자 합니다.\n\n\n\n\n\n\n\n\n\nTip의 활용법\n\n\n\n\n본문의 내용과 직접관련 없지만 알아두면 좋은 내용을 담고 있습니다.\n코드의 작성방법 등 유용한 정보를 답고 있습니다.\n실습과정에서 발견한 문제의 해결방법을 보여주고자 합니다.\n\n\n\n\n\n\n\n\n\nWarning의 활용법법\n\n\n\n\n이해하기 어려운 내용에 대하여 그 문제를 적시하고자 합니다.\n실습과정에서 경험한 문제 및 해결되지 않은 오류 등을 적시하고자 합니다.\n해결이 완료된 경우 note 또는 tip으로 전환될 수 있습니다.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "perceptron-intro.html",
    "href": "perceptron-intro.html",
    "title": "1  Perceptron",
    "section": "",
    "text": "1.1 What is a ‘Perceptron’?\n퍼셉트론은 인공신경망의 가장 기초가 되는 개념이고 이를 이해하기 위하여 생물학적 신경망의 가장 기초가 되는 뉴런(Figure 1.1)에 대하여 이해할 필요가 있습니다.\n뉴런의 구조는 다양하게 하지만 우리가 집중하고자 하는 곳은 크게 3가지 부분으로 구성되어 있습니다.\n여기서 주목할 것은 뉴런은 정보를 입력받아 내부적인 신호를 생성하여 다음 뉴런에 정보를 전달한 다는 것입니다.\n이러한 뉴런의 작동기전을 모방하여 만들어진 것이 퍼셉트론(Figure 1.2)입니다.\n퍼셉트론은 1957년 프랑크 로젠블라트가 제안한 것으로 퍼셉트론은 이러한 뉴런의 작동기전을 모방하여 정보를 입력(Input)받아 연산을 통해 출력(Output)을 생성하도록 설계되었습니다.\n이러한 정보의 흐름 또는 연산 절차를 다른 말로 Forward Propagation이라 합니다, 향후 논의 될 Back Propagation과 대비되는(?) 개념입니다.\nflowchart LR\n  subgraph node\n    direction LR\n    node2_1((SUM)) --&gt; node2_2((STEP))\n  end\n  node1_1((x_1)) --w1--&gt; node2_1\n  node1_2((x_2)) --w2--&gt; node2_1\n  node2_2 --&gt; node3((y_hat))\n\n\n\n\nFigure 1.2: Basic of Perceptron\nFigure 1.2 에서 원은 노드(Node)라고 하면 노드간 연결된 선을 엣지(Edge)라고 합니다. 엣지상에 존재하는 w는 가중치(Weight)하고 합니다.\n첫번째 노드의 x_1과 x_2는 입력값을 말하고, 두번째 노드는 내부적으로 SUM과 STEP으로 구성된 활성함수를 말하며, 마지막 노드의 z는 출력값으로 노드의 활성 정도를 말합니다.\n노란색 노드에서는 2단계 계산이 발생합니다. 하나늗 입력값의 뉴런에서는 신호의 세기를 계산하는 Weighted Sum(Equation 1.1) 과 뉴런의 여부를 계산하는 Step Function(Equation 1.2) 으로 구성되어 있습니다.\n결과적으로 퍼셉트론의 출력값(\\hat{y}=h_{w,b}(x)=sign(\\textbf{w}^{T}\\textbf{x}+b))은 (-1, 0, 1)로 3가지를 갖게 됩니다. 이 결과값을 실제의 값(y)와 비교(Loss Function)하여 가중치(w)를 업데이트 하여 최적해가 아닌 단순 solution(?)을 찾는 것이 퍼셉트론입니다.\nz = b + w_{1}x_{1} + w_{2}x_{2} + \\cdots + w_{n}x_{n} = b + \\textbf{w}^{T} \\textbf{x}\n\\tag{1.1}\nstep(z) = sign(z) = \\begin{cases}\n-1 & z &lt; 0 \\\\\n0 & z = 0 \\\\\n1 & z &gt; 0\n\\end{cases}\n\\tag{1.2}",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#what-is-a-perceptron",
    "href": "perceptron-intro.html#what-is-a-perceptron",
    "title": "1  Perceptron",
    "section": "",
    "text": "외부 자극등 정보를 수신하는 수상돌기(Dendrite)\n수신된 정보를 신호를 만들어 내는 핵(Nucleus)\n신호를 신경절달 물질로 만들어 내는 축삭돌기(Axon)+시넵스(Synapse)\n\n\n\n\n\n\n\n\nFigure 1.1: Structure of Neuron (source: Wikipedia)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n퍼셉트론에서 사용되는 계단함수\n\n\n\n일반적으로 Sign function을 가장 많이 사용하지만, 이진값(0, 1)만을 갖는 Heavisde step function이 사용되기도 합니다. Clsiffication 문제에서 직선상의 Observation값은 0 , Weight와 같은 방향은 1, 다른 방향은 -1로 처리하는 것이 보다 용이하기에 우리는 Sign function을 주로 사용합니다.\n\nheavisde(z) = \\begin{cases}\n0 & z &lt; 0 \\\\\n1 & z &gt;= 0\n\\end{cases}",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#bit-wise-operator단순-논리-회로",
    "href": "perceptron-intro.html#bit-wise-operator단순-논리-회로",
    "title": "1  Perceptron",
    "section": "1.2 Bit-wise operator(단순 논리 회로)",
    "text": "1.2 Bit-wise operator(단순 논리 회로)\n앞서 보았던 퍼셉트론을 분류(Classification)을 수행해보며 보다 자세하게 살펴보겠습니다. 특히 분류의 문제는 향후 ANN 및 CNN 등 다양한 문제를 해결하는데 사용되는 기법으로 향후 학습을 진행하면서 병렬적으로 작동기전에 대하여 비교하기가 용이할 것으로 생각됩니다.\n분류문제 중 가장 간단한 예시로 Bit-wise operator(단순 논리 회로)에 대한 내용을 살펴보겠습니다. 논리회로는 0과 1로 구분된 2개의 input을 받아 0또는 1을 output으로 출력하는 회로입니다.\n단순 논리 회로는 AND, NAND, OR 그리고 XOR게이트로 구성되어 있으며 입력에 따른 출력이 다음의 진리표(Table 1.1 )로 나타낼 수 있습니다.\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n0\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n1\n1\n1\n\n\n\n\n\n(a) AND gate\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n1\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n1\n1\n0\n\n\n\n\n\n(b) NAND gate\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n0\n\n\n1\n0\n1\n\n\n0\n1\n1\n\n\n1\n1\n1\n\n\n\n\n\n(c) OR gate\n\n\n\n\n\n\n\n\n\n\n\nx_1\nx_2\ny\n\n\n\n\n0\n0\n0\n\n\n1\n0\n1\n\n\n0\n1\n1\n\n\n1\n1\n0\n\n\n\n\n\n(d) XOR gate\n\n\n\n\n\n\n\nTable 1.1: 게이트별 진리표",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#perceptron-으로-구현",
    "href": "perceptron-intro.html#perceptron-으로-구현",
    "title": "1  Perceptron",
    "section": "1.3 Perceptron 으로 구현",
    "text": "1.3 Perceptron 으로 구현\n위의 진리표(Table 1.1 )의 내용을 퍼셉트론으로 구현해보겠습니다. 이를 위해 AND게이트를 예를 들도록 하겠습니다.\nAND게이트는 x_1 과 x_2가 모두 1인 경우 y를 1로 출력하는 논리 회로 입니다. 이를 퍼셉트론으로 표현하면 w_1, w_2, \\theta로 표현할 수 있고 이러한 선형판별식(Equation 1.3) 식은 아래와 같습니다.\n\n\n\ny = \\begin{cases}\n0 & w_1*x_1 + w_2*x_2 \\leq \\theta \\\\\n1 & w_1*x_1 + w_2*x_2 &gt; \\theta  \n\\end{cases}\n\\tag{1.3}\n위의 선형판별식은 아래와 같이 그림으로 표현이 가능합니다. 다만, 가중치 w 와 임계치 \\theta 의 조합은 무수히 많이 존재함을 유의해야 합니다.((?fig-egAndGate ) 의 적색선은 임의로 표현한 직선이고 이 직선이 무수히 많다는 의미)\n\n\n\n\n\n\n\n\nFigure 1.3: AND gate\n\n\n\n\n\n단순 논리 회로(XOR게이트 제외)의 선형판별식을 코드로 구현하면 다음과 같습니다. 여기서 일반적으로 향후 Deeplearning의 표현방법을 따라 임계치인 \\theta 를 편향(bias)인 -b로 치환한 수식을 사용하겠습니다.\n\n\n\ny = \\begin{cases}\n0 & b + w_1*x_1 + w_2*x_2 \\leq 0 \\\\\n1 & b + w_1*x_1 + w_2*x_2 &gt; 0\n\\end{cases}\n\\tag{1.4}\n변형된 수식(Equation 1.4 )에 기초하여 진리표(Table 1.1 )상의 게이트를 코드로 구현하면 아래와 같습니다.\n\n1import numpy as np\n\n# AND gate\ndef AND(x1, x2):\n  x = np.array([x1, x2])\n2  w = np.array([0.5, 0.5])\n  b = -0.7\n3  tmp = np.sum(w*x) + b\n  if tmp &lt;= 0:\n    return 0\n  elif tmp &gt; 0:\n    return 1\n\n# NAND gate\ndef NAND(x1, x2):\n  x = np.array([x1, x2])\n  w = np.array([-0.5, -0.5])\n  b = 0.7\n  tmp = np.sum(w*x) + b \n  if tmp &lt;= 0:\n    return 0\n  elif tmp &gt; 0:\n    return 1\n\n# OR gate\ndef OR(x1, x2):\n  x = np.array([x1, x2])\n  w = np.array([0.5, 0.5])\n  b = -0.7\n  tmp = np.sum(w*x) + b \n  if tmp &lt;= 0:\n    return 0\n  elif tmp &gt; 0:\n    return 1\n\n\n1\n\nVector 연산의 최적화를 위하여 numpy를 기본적으로 사용한다.\n\n2\n\nw와 b는 임의로 할당한다. 다만, NAND 및 OR 는 AND의 부호와 다름에 주의하자.\n\n3\n\nweighted sum은 가중치를 곱하여 더한 값으로 내적과 유사함을 유의하자.",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#mlp",
    "href": "perceptron-intro.html#mlp",
    "title": "1  Perceptron",
    "section": "1.4 MLP",
    "text": "1.4 MLP\n다중 퍼셉트론은 퍼셉트론이 여러층으로 구현된 형태를 말합니다. 층을 여러개 쌓아서 보다 복잡한 문제를 해결할 수 있고, 추후 Deeplearning에서 여러층의 신경망을 쌓는 방식의 기초라고만 이해해 두겠습니다.\n앞서 1층 퍼셉트론으로는 단순 논리 회로 중 선형적인 게이트만을 구현할 수 있었습니다. 그렇다면 XOR게이트는 해결할 수 없을까요? 이를 해결하기 위한 것이 다층 퍼셉트론 입니다.\n가령 XOR게이트 문제를 NAND와 OR게이트를 조합한 출력값을 AND게이트의 입력값으로 받게 된다면 XOR게이트를 구현할 수 있습니다. 국소적인 문제해결을 결합하여 전체 문제를 해결하는 방식으로 이해됩니다.\n\n\n\n\n\n\nflowchart LR\n  x1((x1)) & x2((x2)) ---&gt; nand[NAND] & or[OR] \n  nand --s1---&gt; AND ---&gt; y[y]\n  or --s2---&gt; AND\n\n\n\n\nFigure 1.4: XOR Gate: Composition of NAND, OR, AND\n\n\n\n\n\nXOR의 게이트를 다른 게이트의 조합을 활용한 진리표는 아래와 같습니다. 위의 그림에서 보듯이 x1과 x2의 입력값을 받아 NAND게이트는 s1의 출력값을 OR게이트는 s2의 출력값을 생성하며, 다시 s1과 s2를 입력값으로 받아 AND를 통과시켜 최종적으로 XOR게이트의 진리표를 다시 그릴 수 있습니다.\n\n\n\n\n\n\nx_1\nx_2\ns_1\ns_2\ny\n\n\n\n\n0\n0\n1\n0\n0\n\n\n1\n0\n1\n1\n1\n\n\n0\n1\n1\n1\n1\n\n\n1\n1\n0\n1\n0\n\n\n\n\n\nTable 1.2: XOR게이트의 진리표\n\n\n\n위의 진리표(Table 1.2 )를 코드로 구현하면 아래와 같습니다. 앞서 구현한 게이트들을 코드내에서 사용하여 단순하게 구현할 수 있습니다.\n\ndef XOR(x1, x2):\n  s1 = NAND(x1, x2)\n  s2 = OR(x1, x2)\n  y = AND(s1, s2)\n  return y",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-intro.html#wrap-up",
    "href": "perceptron-intro.html#wrap-up",
    "title": "1  Perceptron",
    "section": "Wrap up",
    "text": "Wrap up\n지금까지 퍼셈트론에 대하여 살펴 보았습니다. 단순히 퍼셥트론이 뭐다라는 단순한 이야기 이지만, 딥러닝에 있어 가장 기초가 되는 부분입니다. 다만, 퍼셉트론 자체를 더 깊이 알아보기 보다 하나의 뉴런이 여러개의 뉴런이 되는 MLP(Multi-Layers Perceptron)가 여러개의 층으로 이루어 지는 NN(Neural Network)으로 발전된다 정도로 이해해 보도록 하겠습니다.\n자세한 사항은 다음장에서 여러개의 뉴런들이 층을 이루는 인공신경망(ANN, Articial Neural Network)에서 설명하도록 하며 주요 주제는 아래와 같습니다.\n\nActivation function & Forward Propagation\nLoss Function(Loss Optimization) & Back Propagation\nNN in Practice: Adaptive Learning, Mini-batches, Overfitting(Regularization)\n\n이후 ANN을 Foundation으로 Sequential Data Modelling을 위한 RNN 및 이미 처리를 위한 CNN 등에 대하여 학습할 예정입니다.",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-lab_classification.html",
    "href": "perceptron-lab_classification.html",
    "title": "2  Lab: Classification with Perceptron",
    "section": "",
    "text": "2.1 Classification\n우리가 실습할 분류 문제는 선형 판별 분석(LDA, Linear Discriminant Analysis)입니다. 수치형 입력변수를 받아 범주형 타겟 변수를 예측하는 분류 방법으로 퍼셈트론을 활용하여 해결하기 좋은 문제 입니다.\nFigure 2.1: Example of LDA\n위 산점도(Figure 2.1 )와 같은 산점도에서 C1과 C0을 구분하는 문제를 퍼셉트론을 이용하여 해결해 보겠습니다.\n전장에서 살펴본 퍼셉트론(Figure 1.2)에 따라 설명하고자 합니다. 우선 입력받는 변수는 x, 가중치는 \\omega로 둘수 있습니다.\n\\begin{align}\nx = \\begin{bmatrix}x_1\\\\ \\vdots\\\\ x_d \\end{bmatrix} \\qquad\n\\omega = \\begin{bmatrix}\\omega_1\\\\ \\vdots\\\\ \\omega_d \\end{bmatrix}\n\\end{align}\n\\tag{2.1}\n여기서 Weighted Sum의 결과가 특정 임계치(\\theta)를 초과하는 지에 따라 클래스1(C_1) 또는 클래스0(C_0)으로 구분하고자 합니다.\n\\begin{align}\nC_1 \\quad if\\, \\sum_{i=1}^{d}\\omega_{i}x_{i} &gt; \\theta \\\\\nC_0 \\quad if\\, \\sum_{i=1}^{d}\\omega_{i}x_{i} &lt; \\theta\n\\end{align}\n\\tag{2.2}\n이를 다시 Step function을 활용하여 Figure 1.2 의 노란색 박스(h(x))에 해당하는 노드를 다음의 식으로 변형하여 표현할 수 있습니다.\n여기서 임계치(\\theta)는 편향에 해당하는 값으로 변형하고 이를 다시 입력변수 \\omega_0으로 간단하게 표현할 수 있습니다.\n\\begin{align}\nh(x) &= \\text{sign} \\left(\\left( \\sum\\limits_{i=1}^{d}\\omega_ix_i \\right)- \\theta \\right) \\\\\n&= \\text{sign}\\left(\\left( \\sum\\limits_{i=1}^{d}\\omega_ix_i \\right)+ \\omega_0\\right)\n\\end{align}\n\\tag{2.3}\n\\omega_0=1로 두고 이를 벡터 형식(vector form)으로 표현하고, Step function을 Sign function으로 정의하면 아래와 같이 식을 수정할 수 있습니다.\n\\begin{align}\nh(x) &= \\text{sign}(\\sum_{i=0}^{d}\\omega_{i}x_{i})\n=\\text{sign}(\\omega^{T}x) \\\\\n\\text{sign}(x) &= \\begin{cases}\n1, &\\text{if }\\; x &gt; 0\\\\\n0, &\\text{if }\\; x = 0\\\\\n-1, &\\text{if }\\; x &lt; 0\n\\end{cases}\n\\end{align}\n\\tag{2.4}\nPerceptron Learning Algorithm(PLA)\n위의 식을 실제 퍼셉트론에 적용하기 위하여 위 산점도(Figure 2.1 )의 개별 값들을 활용하여 \\text{sign}(\\omega^Tx_n) = \\hat{y}_n을 산출하여 실제 라벨(y_n)과 비교하며 두 라벨값이 다를 경우 \\omega를 업데이트 하도록 합니다.\n\\begin{align}\n\\omega \\leftarrow\n\\begin{cases}\n\\omega+y_nx_n & \\hat{y_n} \\neq y_n \\\\\n\\omega &\\hat{y_n} = y_n \\\\\n\\end{cases}\n\\end{align}\n\\tag{2.5}\n위의 절차를 Training Set을 이용하여 Iterative하게 반복하여 \\omega를 업데이트 하도록 하여 PLA를 수행합니다.\nPerceptron Loss Function\nPLA를 수행하는 과정에서 학습을 종결시키기 위하여 Loss function이 필요합니다. 산출값 \\hat{y}_n과 y_n을 비교하여 Loss들의 합(\\mathscr{L}(\\omega))이 0이 되도록 하는 조건으로 설정할 수 있습니다.\n\\begin{align}\n\\mathscr{L}(\\omega) = \\sum_{n =1}^{m} \\max \\left\\{ 0, -y_n \\cdot \\left(\\omega^T x_n \\right)\\right\\}\n\\end{align}\n\\tag{2.6}",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lab: Classification with Perceptron</span>"
    ]
  },
  {
    "objectID": "perceptron-lab_classification.html#solving-with-perceptron-algorithm",
    "href": "perceptron-lab_classification.html#solving-with-perceptron-algorithm",
    "title": "2  Lab: Classification with Perceptron",
    "section": "2.2 Solving with perceptron algorithm",
    "text": "2.2 Solving with perceptron algorithm\n위에서 살펴본 내용을 이제 코드로 작성해 보겠습니다. 기본적인 입력변수 x를 x1과 x2로 라벨값 y를 C1과 C0로 생성하였습니다. 그에 따른 산점도 데이터는 아래와 같습니다.\n\n#training data gerneration\nm = 100\nx1 = 8*np.random.rand(m, 1)\nx2 = 7*np.random.rand(m, 1) - 4\n\ng = 0.8*x1 + x2 -3\n\nC1 = np.where(g &gt;= 1)[0]\nC0 = np.where(g &lt; -1)[0]\n\n\n\n\n\n\nLinearly Separable Classes with no dicision boundary\n\n\n\n\n각각의 입력값을 numpy로 연산할 수 있도록 Vectorize를 진행합니다.\n\n\\begin{align}\nx &= \\begin{bmatrix} \\left(x^{(1)}\\right)^T \\\\ \\left(x^{(2)}\\right)^T \\\\ \\left(x^{(3)}\\right)^T\\\\ \\vdots \\\\ \\left(x^{(m)}\\right)^T \\end{bmatrix} = \\begin{bmatrix} 1 & x_1^{(1)} & x_2^{(1)} \\\\ 1 & x_1^{(2)} & x_2^{(2)} \\\\ 1 & x_1^{(3)} & x_2^{(3)}\\\\\\vdots & \\vdots & \\vdots \\\\ 1 & x_1^{(m)} & x_2^{(m)}\\end{bmatrix} \\\\\ny &= \\begin{bmatrix}y^{(1)} \\\\ y^{(2)} \\\\ y^{(3)}\\\\ \\vdots \\\\ y^{(m)} \\end{bmatrix}\n\\end{align}\n\n\nX1 = np.hstack([np.ones([C1.shape[0],1]), x1[C1], x2[C1]])\nX0 = np.hstack([np.ones([C0.shape[0],1]), x1[C0], x2[C0]])\n\nX = np.vstack([X1, X0])\ny = np.vstack([np.ones([C1.shape[0],1]), -np.ones([C0.shape[0],1])])\n\nX = np.asmatrix(X)\ny = np.asmatrix(y)\n\n가중치 \\omega를 1로 초깃값을 설정하고, 각각의 입력값을 이용하여 PLA를 실행하며 가중치 업데이트(\\omega \\leftarrow \\omega + yx)를 실행합니다.\n\nw = np.ones([3,1])\nw = np.asmatrix(w)\n\nn_iter = y.shape[0]\nflag = 0\n\nwhile flag == 0:\n    flag = 1\n    for i in range(n_iter):\n        if y[i,0] != np.sign(X[i,:]*w)[0,0]:\n            w += y[i,0]*X[i,:].T\n            flag = 0\n\n위의 절차를 실행하여 산출한 결정 경계(Dicision Boundary)는 아래와 같습니다.\n\n\n\n\n\nLinearly Separable Classes with dicision boundary\n\n\n\n\n\n\n\n\n\n\nPerceptron과 최적화의 문제\n\n\n\n\n여기서 중요한 것은 퍼셉트론은 구분하는 경계 산출에 촛점을 두고 있으므로 우리가 예상하는 최적 경계에 해당하지 않을 수 있습니다.\n가령 최적 경계는 두 그룹의 중간쯤 위치해야 할 것으로 생각이 됩니다. 그래야 향후 입력값이 추가 되었을 때 경계가 유효할 가능성이 높기 때문입니다.\n이를 해결하기 위하여는 내적을 통한 거리의 개념이 들어가고, Loss Function도 Logistic Regression의 방법으로 해결해야 하지 않을까라고 예상할 수 있습니다.",
    "crumbs": [
      "Perceptron",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lab: Classification with Perceptron</span>"
    ]
  },
  {
    "objectID": "ANN-intro.html",
    "href": "ANN-intro.html",
    "title": "3  Artificial Neural Networks",
    "section": "",
    "text": "인공신경망(ANN, Artificial Neural Networks)은 퍼셉트론과 유사한 메커니즘을 갖고 있습니다. Figure 4.1 에서 가장 왼쪽이 입력층(Input), 중간이 은닉층(Hidden), 가장 오른쪽이 출력층(Output)으로 구성되어 있습니다.\n\n\n\n\n\n\ngraph LR\n  subgraph Input\n      direction LR\n      x1((x1)) & x2((x2)) \n  end\n  \n  subgraph Hidden\n      direction LR\n      h1((h1)) & h2((h2)) & h3((h3))\n  end \n\n  subgraph Output\n      direction LR\n      y1((y1)) & y2((y2))\n  end\n\n    x1((x1)) & x2((x2))  ---&gt; h1((h1)) & h2((h2)) & h3((h3))\n    h1((h1)) & h2((h2)) & h3((h3)) ---&gt; y1((y1)) & y2((y2))\n\n\n\n\nFigure 3.1: Example of ANN\n\n\n\n\n\n다만, 퍼셉트론과 다른 점이 있따면, 신호를 전달 받는 과정에서 편향에 해당하는 b가 명시적으로 존재하여 이 또한 신호로 처리한다는 부분입니다.\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n  x1((x1)) --w1---&gt; y((y))\n  x2((x2)) --w2---&gt; y\n\n\n\n\n(a) Perceptron\n\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n  x0((1)):::bias --b---&gt; y((y))\n  x1((x1))  --w1---&gt; y((y))\n  x2((x2))  --w2---&gt; y\n  classDef bias fill:#f96\n\n\n\n\n(b) ANN\n\n\n\n\n\n\n\n\n\nFigure 3.2: 퍼셉트론과 ANN의 비교\n\n\n\nFigure 3.2 에는 잘 나타나 있지 않지만 Perceptron의 경우 입력신호를 받아 y를 바로 출력하지만, ANN의 경우 입력신호와 가중치를 곱하여 총합을 산출하는 함수와 이 산출값을 이용하여 조건 분기의 동작(0을 넘으면 1을 출력하고 그렇지 않으면 0을 출력)을 나타내는 함수로 구성되어 있으며 이를 구현한 산식은 Equation 3.1 과 같이 나타낼 수 있다.\n\n\\begin{align}\n&y = h(b + w_{1}x_{1} + w_{2}x_{2}) \\\\ \\\\\n&h(x) =\n  \\begin{cases}\n  0 & (x \\leq 0) \\\\\n  1 & (x &gt; 1)\n  \\end{cases}\n\\end{align}\n\\tag{3.1}\n\n\n\n\n\n\n펴셉트론과 Deeplearning의 차이\n\n\n\n\n퍼셉트론에 사용되는 선형판별식에 가중치 및 임계치의 조합은 무수히 많고, 가중치 및 임계치는 인간이 설정해야 함. 결국 Domain Knowledge를 갖고 있어야 한다는 의미임\nDeeplearning의 경우 가중치 및 임계치를 컴퓨터가 학습하여 설정해게 됨\n또한. Activation Function의 경우 미분가능해야 하고, Loss Function의 결과 Back propagation의 활용하여 \\omega를 최적화하는 절차가 존재함",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Artificial Neural Networks</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html",
    "href": "ANN-activation.html",
    "title": "4  Activation Function",
    "section": "",
    "text": "4.1 Sigmoid Function\n시그모이드 함수(sigmoid function)는 계단함수와 달리 ’S자 모양’으로 Non-linear한 함수이고 그 식은 아래와 같습니다.\n\\begin{align}\nh(x) = \\frac{1}{1+exp(-x)}\n\\end{align}\n시그모이드 함수를 python 코드로 아래와 같이 간다하게 구현할 수 있습니다. 이를 활용하여 시그모이드 함수를 실행하면 ?fig-annAct1 와 같은 그래프를 볼 수 있습니다.\ndef sigmoid(x):\n  return 1 / (1 + np.exp(-x))\nFigure 4.2: Plot of Sigmoid Function",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html#relu-function",
    "href": "ANN-activation.html#relu-function",
    "title": "4  Activation Function",
    "section": "4.2 ReLU Function",
    "text": "4.2 ReLU Function\n**ReLU 함수(Rectified Linear Unit funcion)는 시그모이드를 넘어 최근에 많이 사용되는 함수 입니다. 입력값을 0을 넘으면 그 입력값을 그대로 출력하고 그 이하이면 0을 출력하는 함수로 그 식은 아래와 같습니다.\n\n\\begin{align}\nh(x) =\n\\begin{cases}\nx & (x &gt; 0) \\\\\n0 & (x \\leq 0)\n\\end{cases}\n\\end{align}\n\nReLU 함수를 python 코드로 아래와 같이 간다하게 구현할 수 있습니다. 이를 활용하여 시그모이드 함수를 실행하면 ?fig-annAct2 와 같은 그래프를 볼 수 있습니다.\n\ndef relu(x):\n  return np.maximum(0, x)\n\n\n\n\n\n\n\n\n\nFigure 4.3: Plot of ReLU Function",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-activation.html#others",
    "href": "ANN-activation.html#others",
    "title": "4  Activation Function",
    "section": "4.3 others",
    "text": "4.3 others\n위에 소개한 활성화 함수 외에도 많은 종류의 활성화 함수가 존재합니다. 이에 대하여 자세한 사항은 Wiki페이지를 참고하시기 바랍니다.\n학습을 진행하는 과정에서 필요한 내용들을 지속적으로 업데이트 할 예정입니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Activation Function</span>"
    ]
  },
  {
    "objectID": "ANN-forward.html",
    "href": "ANN-forward.html",
    "title": "5  Forward Propagation",
    "section": "",
    "text": "5.1 Layer-by-Layer signaling\n3층 신경망의 신호 전달과정은 아래와 같이 Weighted Sum에 기반하며 그 값을 다시 화성화 함수(가령 Sigmoid)를 통하여 노드의 값이 최종 산출됩니다.\n또한, 이전층의 값들을 받아 산출된 값은 다시 입력값으로 하여 다음층으로 전달되는 과정을 거쳐 최종적으로 출력층까지 이 과정을 반복하게 됩니다. 이 과정이 신호 전달 또는 Forward propagation 입니다.\ninput to hidden\n최초 입력층(0층)의 신호 전달 체계는 입력값(노드)은 2개인 1차원 배열이고 다음의 은닉층(1층)은 노드 3계로 이루어진 1차원 배열입니다. 2개의 노드 값을 받아 3개의 노드로 전달해야 하므로 노드간의 간선은 총 6개(6 = 2 \\times 3)입니다.\n입력값 및 편향값을 a에 전달하고 a값을 활성화 함수(Sigmoid 함수를 사용) h()를 이용하여 신호 z를 산출하도록 합니다. 결과적으로 은닉층(1층)에 해당하는 3개의 노드의 신호를 확인할 수 있습닏.\n# 입력값, 편향, 가중치\nX  = np.array([1.0, 0.5])\nB1 = np.array([0.1,0.2,0.3])\nW1 = np.array([[0.1,0.3,0.5], [0.2,0.4,0.6]])\n\n# Weighted Sum\nA1 = np.dot(X, W1) + B1\n\n# Activation Function\nZ1 = sigmoid(A1)\n\nprint(A1)\nprint(Z1)\n\n[0.3 0.7 1.1]\n[0.57444252 0.66818777 0.75026011]\nhidden to hidden\n은닉층(1층)이 다시 입력층으로 하여 다음의 은닉층(2층)으로 신호를 전달하도록 해야 합니다. 앞서 진행한 신호 전달 과정과 동일합니다.\n다만, 입력 노드가 편향을 포함하여 4개가 다음 층인 2개의 노드로 전달됨에 따라 이전 과정과 달리 간선은 총 8개 입니다. 편향은 2개 간선을 갖고 가중치는 입력 노드별 2개 총 6개로 이루어 집니다.\n# 편향, 가중치\nB2 = np.array([0.1,0.2])\nW2 = np.array([[0.1,0.4], [0.2,0.5], [0.3,0.6]])\n\n# Weighted Sum & Activation Function\nA2 = np.dot(Z1, W2) + B2\nZ2 = sigmoid(A2)\n\nprint(A2)\nprint(Z2)\n\n[0.51615984 1.21402696]\n[0.62624937 0.7710107 ]\nhidden to output\n은닉층(2층)이 다시 입력층으로 하여 다음의 출력층(3층)으로 신호를 전달하도록 해야 합니다. 앞서 진행한 신호 전달 과정과 동일합니다.\n주의할 것은 출력층의 경우 해결하고자 하는 문제의 성질에 맞게 설정되어야 합니다. 여기서는 입력되는 값을 그대로 출력하는 항등함수(Identity Function)알 사용하도록 하겠습니다.\n# 항등함수\ndef identity_function(x):\n  return x\n\n# 편향, 가중치\nB3 = np.array([0.1,0.2])\nW3 = np.array([[0.1,0.3], [0.2,0.4]])\n\n# Weighted Sum & Activation Function\nA3 = np.dot(Z2, W3) + B3\nY  = identity_function(A3) # Y = A3\n\nprint(Y)\n\n[0.31682708 0.69627909]\nWrap-up\n앞서 정리한 내용을 하나의 모듈로 작성하도록 하겠습니다. 이 신경망의 신호 전달 과정은 순방향의 연산 과정만을 익히기 위함이고 가장 처음에 실행되는 과정입니다.\n1def init_network():\n  network = {}\n  network['W1'] = np.array([[0.1,0.3,0.5], [0.2,0.4,0.6]]) # 입력2 출력3\n  network['b1'] = np.array([0.1,0.2,0.3])\n  network['W2'] = np.array([[0.1,0.4], [0.2,0.5], [0.3,0.6]]) # 입력3, 출력2\n  network['b2'] = np.array([0.1,0.2])\n  network['W3'] = np.array([[0.1,0.3], [0.2,0.4]]) # 입력2, 출력2\n  network['b3'] = np.array([0.1,0.2])\n\n  return network\n\n2def forward(network, x):\n  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n\n  a1 = np.dot(x, W1) + b1\n  z1 = sigmoid(a1)\n  a2 = np.dot(z1, W2) + b2\n  z2 = sigmoid(a2)\n  a3 = np.dot(z2, W3) + b3\n  y  = identity_function(a3)\n\n  return Y\n\nnetwork = init_network()\nx = np.array([1.0,5.0])\ny = forward(network, x)\n\nprint(y)\n\n\n1\n\n가중치와 편향을 초기화하고 이들을 닉셔너리 변수인 network에 저장\n\n2\n\n입력신호를 출력으로 변환하는 처리과정\n\n\n\n\n[0.31682708 0.69627909]",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-forward.html#layer-by-layer-signaling",
    "href": "ANN-forward.html#layer-by-layer-signaling",
    "title": "5  Forward Propagation",
    "section": "",
    "text": "(a) input-hidden\n\n\n\n\n\n\n\n\n\n\n\n(b) hidden-hidden\n\n\n\n\n\n\n\n\n\n\n\n(c) hidden-output\n\n\n\n\n\n\n\nFigure 5.2: Process of Forward Propagation(souce: Deeplearning from Scratch)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n출력층의 활성화 함수\n\n\n\n\n출력층의 활성화 함수는 문제의 성질에 맞춰야 한다고 하였습니다.\n문제의 성질은 크게 2가지로 나누어 볼 수 있는데 하나는 분류(classfication), 다른 하나나는 회귀(regression)입니다.\n각각의 문제에 맞는 활성화 함수는 다양하며 자세한 사항은 지속적으로 Chapter 4 에 내용을 추가하도록 하겠습니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-forward.html#disign-output-layer",
    "href": "ANN-forward.html#disign-output-layer",
    "title": "5  Forward Propagation",
    "section": "5.2 Disign Output layer",
    "text": "5.2 Disign Output layer\n신경망의 경우 통상 회귀의 경우 항등 함수를, 분류의 경우는 소프트맥스 함수(softmax function)를 사용합니다. 소프트맥스 함수의 식은 아래와 같습니다.\n\ny_k = \\frac{exp(a_k)}{\\sum^{n}_{i=1}exp(a_i)}\n\\tag{5.2}\n위 식에서 exp(x)는 e^x를 지수함수를 의미하며, n은 출력층의 뉴런수, y_k는 출력노드 중 k번째를 의미합니다. 분자는 k번째 출력노드의 값을 분모는 전체 출력노드의 합을 의미합니다.\n\n\n\n\n\nflowchart LR\n  subgraph h [\"sigma()\"]\n    direction LR\n    a1((a1)) & a2((a2)) & a3((a3))\n    y1((y1)) & y2((y2)) & y3((y3))\n  end\n\n  a1 & a2 & a3 ---&gt; y1 & y2 & y3\n\n\n\n\n\n\nCautions for implementing the Softmax function\nEquation 5.2 식을 코드로 구현하기 이전에 주의할 사항이 필요합니다.\n하나는 오퍼플로(overflow), 즉 컴퓨터의 특성상 너무 큰 수의 경우 Inf가 나오게 된다는 점입니다.\n이러한 문제를 해결하기 위하여 참고한 자료에는 임의 상수 C를 분모와 분자에 모두 곱해주는 방식으로 이 문제를 해결 할수 있다고 하며 C는 다시 exp의 지수항으로 옮기고 C'로 변경할 수 있습니다.\n\n\\begin{align}\ny_k = \\frac{exp(a_k)}{\\sum^{n}_{i=1}exp(a_i)} &= \\frac{C\\,exp(a_k)}{C\\,\\sum^{n}_{i=1}exp(a_i)} \\\\\n&= \\frac{exp(a_k+log C)}{\\sum^{n}_{i=1}exp(a_i+log C)} \\\\\n&= \\frac{exp(a_k+C')}{\\sum^{n}_{i=1}exp(a_i+C')}\n\\end{align}\n\\tag{5.3}\n위의 식에 따라 출력층에 사용할 소프트맥스 함수를 아래와 같이 구현할 수 있으며, 개선된 식의 C는 통상 입력값의 최대값으로 설정하도록 하겠습니다.\n\ndef softmax(a):\n  c = np.max(a)\n  exp_a = np.exp(a-c)\n  sum_exp_a = np.sum(exp_a)\n  y = exp_a / sum_exp_a\n\n  return y\n\na = np.array([0.3, 2.9, 4.0])\ny = softmax(a)\n\nprint(y)\n\nnp.sum(y)\n\n[0.01821127 0.24519181 0.73659691]\n\n\n1.0\n\n\n위이 함수를 실행하면 출력값의 총합은 1임을 알 수 있습니다. 이것은 출력된 개별 값들을 확률로 해석할 수 있음을 의미합니다. 다만, 지수합수인 exp()계산시 자원이 많이 소비됨에 따라 추론 단계에서는 소프트맥스 함수를 생랙하기도 한다고 합니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-forward.html#lab-number-recognition-with-mnist",
    "href": "ANN-forward.html#lab-number-recognition-with-mnist",
    "title": "5  Forward Propagation",
    "section": "5.3 Lab : Number recognition with MNIST",
    "text": "5.3 Lab : Number recognition with MNIST\n현재 우리가 진행하고 있는 과정은 학습과 추론 중 추론(inference)에 해당하는 순전파(forward propagation)입니다. 학습의 경우 역전파(back propagation)를 통하여 가중치를 업데이트 하나 추론의 경우는 설정된 가중치를 이용하여 문제를 해결하는 과정입니다.\n\n\n\n\n\n\nMNIST 데이터셋\n\n\n\nMNIST1 데이터셋은 기계 학습 분야에서 널리 사용되는 손으로 쓴 숫자 이미지 데이터셋입니다. 이 데이터셋은 0부터 9까지의 숫자를 손으로 쓴 28x28 픽셀 크기의 이미지로 구성되어 있습니다. 주로 숫자 인식 및 분류 알고리즘의 테스트 및 훈련에 사용됩니다.\n\n크기: 28x28 픽셀\n포맷: 흑백 이미지(1채널)\n이미지 개수: - 훈련 데이터: 60,000개 - 테스트 데이터: 10,000개\n픽셀 값 범위: 0부터 255까지\n\n\n\n1 ANN 및 CNN 까지 다양한 예제에 활용될 예정\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nimport numpy as np\nfrom dataset.mnist import load_mnist\nfrom PIL import Image\n\n# MNIST 데이터셋 로드\n(x_train, t_train), (x_test, t_test) = \\\n  load_mnist(\n1    flatten = True,\n2    normalize = False,\n3    one_hot_label = False\n    ) \n\ndef img_show(img):\n    pil_img = Image.fromarray(np.uint8(img))\n    pil_img.show()\n\nimg = x_train[0]\nlabel = t_train[0]\nprint(label)  # 5\n\nprint(img.shape)  # (784,)\nimg = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\nprint(img.shape)  # (28, 28)\n\nimg_show(img)\n\n\n1\n\nflatten은 28x28의 2D-배열을 784x1 1D배열로 만들지 말지 결정하는 변수\n\n2\n\nnormalize는 픽셀값의 범위를 기존 [0, 255]에서 [0.0, 1.0]으로 변환할지 말지를 결정하는 변수\n\n3\n\none_hot_label은 레이블의 값을 정수(False, 예:5)로 할지, 한 원소만을 1로 갖는 배열(True, 예:[0,0,0,0,0,1,0,0,0,0,0])로 할지 결정하는 변수\n\n\n\n\n5\n(784,)\n(28, 28)\n\n\n\n5.3.1 Inference processing\nANN을 활용하여 MNIST 데이터셋을 가지고 추론과정을 신경망으로 구현하면 아래와 같습니다. 입력층의 뉴런은 28\\times28의 데이터를 받아 Fully-conneted하게 784개의 뉴런으로 갖도록 합니다. 그리고 출력층의 뉴런은 0~9까지 10개로 분류해야 하므로 10개의 뉴런을 갖도록 합니다.\n입력과 출력사이의 은닉층은 2개의 층으로 구성하도록 하고 각각 50개 100개의 뉴런을 갖도록 합니다. 은닉층의 뉴런의 갯수는 임의로 정한 것이고 본 사전에 학습된 \\omega 를 사용하여 추론의 정확도를 평가해 보도록 하겠습니다.\n\n# coding: utf-8\nimport sys, os\nsys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\nimport numpy as np\nimport pickle\nfrom dataset.mnist import load_mnist\nfrom common.functions import sigmoid, softmax\n\n\ndef get_data():\n    (x_train, t_train), (x_test, t_test) = load_mnist(\n4      normalize=True,\n      flatten=True, \n      one_hot_label=False)\n    return x_test, t_test\n\n\ndef init_network():\n    with open(\"dataset/sample_weight.pkl\", 'rb') as f:\n        network = pickle.load(f)\n    return network\n\n\ndef predict(network, x):\n    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n\n    a1 = np.dot(x, W1) + b1\n    z1 = sigmoid(a1)\n    a2 = np.dot(z1, W2) + b2\n    z2 = sigmoid(a2)\n    a3 = np.dot(z2, W3) + b3\n    y = softmax(a3)\n\n    return y\n\n\nx, t = get_data()\nnetwork = init_network()\naccuracy_cnt = 0\n1for i in range(len(x)):\n    y = predict(network, x[i])\n2    p= np.argmax(y)\n3    if p == t[i]:\n        accuracy_cnt += 1\n\nprint(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))\n\n\n1\n\nfor문 안에서 이미지 1장씩 꺼내어 predict()함수로 분류(0~9)를 실행하여 레이블의 확률을 Numpy 배열로 반환\n\n2\n\nnp.argmax로 반환된 레이블 배열에서 가장 높은 값(확률)의 인덱스를 산출\n\n3\n\n정답 레이블과 산출 레이블의 비교하여 일치하면 accuracy_cnt로 정답 갯수 업데이트\n\n4\n\nload_mnist함수의 인자 중 normalize가 True는 데이터를 0~1사이의 값으로 정규화 한다는 의미\n\n\n\n\nAccuracy:0.9352\n\n\n위의 과정을 통해 분류의 정확도는 93.52%임을 확인 할 수 있습니다. 이후에 이 정확도를 향상시키기 위한 신경망의 학습 등에 대하여 살펴볼 예정입니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forward Propagation</span>"
    ]
  },
  {
    "objectID": "ANN-learning.html",
    "href": "ANN-learning.html",
    "title": "6  Learning process of ANN",
    "section": "",
    "text": "6.1 Loss Function\n손실함수는 ANN에 입력되어 산출되는 값과 실제 값을 비교하여 정확도를 측정하는 하나의 지표라고 할 수 있다. ANN은 이러한 지표를 기준으로 최적의 가중치를 탐색하여 하나의 모델을 구성하게 됩니다.\n손실함수로는 일반적으로 오차제곱합(SSE, sum of squares for error)과 교차 엔트로피 오차(CEE, cross entropy error)를 사용합니다.",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Learning process of ANN</span>"
    ]
  },
  {
    "objectID": "ANN-learning.html#loss-function",
    "href": "ANN-learning.html#loss-function",
    "title": "6  Learning process of ANN",
    "section": "",
    "text": "6.1.1 SSE(sum of squares for error)\n오차제곱합(Equation 6.1 )은 신경말의 출력값(y_k)과 실제값(t_k) 사이의 차이인 오차를 계산하고 이 오차를 제곱하여 모두 더한 값을 말하며 이 값이 작아질 수록 모델이 더 좋은 예측능력을 보유한다고 판단합니다.\n\nE = \\frac{1}{2}\\sum^{}_{k}(y_k - t_k)^2\n\\tag{6.1}\n원-핫 인코딩을 통하여\n\n\n6.1.2 CEE(cross entropy error)",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Learning process of ANN</span>"
    ]
  },
  {
    "objectID": "ANN-learning.html#gradient-descent",
    "href": "ANN-learning.html#gradient-descent",
    "title": "6  Learning process of ANN",
    "section": "6.2 Gradient Descent",
    "text": "6.2 Gradient Descent",
    "crumbs": [
      "ANN",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Learning process of ANN</span>"
    ]
  }
]