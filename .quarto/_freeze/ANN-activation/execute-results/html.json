{
  "hash": "48bf4a8e535f3add4356d613264425ac",
  "result": {
    "engine": "jupyter",
    "markdown": "# Activation Function {#sec-actANN}\n\n---\n\n\n\n앞서 살펴본 $h(x)$ 라는 함수가  **활성화 함수**(Activation function)입니다. 이는 입력신호의 총합(Weighted Sum)을 입력값으로 받아 다음 뉴런이 활성화 정도를 결정하는 함수로 이해할 수 있습니다.\n\n이러한 활성화 함수가 포함된 ANN의 기본적인 모형은 다음과 같습니다. `a`는 입력신호의 총합을 의미하고, `h()`는 이를 다양한 활성화 함수를 이용하여 다음 뉴런의 활성정도인 `y`를 출력합니다.\n\n``` {mermaid}\n%%| label: fig-egANN\n%%| fig-cap: \"Processing of the activation function\"\n\ngraph LR\n  subgraph h [\"h()\"]\n    direction LR\n    a((a)) & y((y))\n  end\n\n  x0((1)):::bias --b---> a\n  x1((x1))  --w1---> a\n  x2((x2))  --w2---> a\n  a --> y\n  classDef bias fill:#f96\n```\n\n퍼셉트론에서는 활성화 함수로 **계단함수**(Sign function)를 사용하였느나, ANN에서는 활성화 함수로 **미분가능한 함수**들을 사용합니다. 다음은 ANN에서 사용하는 활성화 함수에 대하여 소개하겠습니다.\n\n## Sigmoid Function\n\n**시그모이드 함수**(sigmoid function)는 계단함수와 달리 '*S자 모양*'으로 Non-linear한 함수이고 그 식은 아래와 같습니다.\n\n$$\n\\begin{align}\nh(x) = \\frac{1}{1+exp(-x)}\n\\end{align}\n$$\n\n시그모이드 함수를 `python` 코드로 아래와 같이 간다하게 구현할 수 있습니다. 이를 활용하여 시그모이드 함수를 실행하면 아래와 같은 그래프(@fig-annAct1 )를 볼 수 있습니다.\n\n::: {#a3fdd6b2 .cell execution_count=2}\n``` {.python .cell-code}\ndef sigmoid(x):\n  return 1 / (1 + np.exp(-x))\n```\n:::\n\n\n![Plot of Sigmoid Function](image/annAct1.png){#fig-annAct1}\n\n\n## ReLU Function\n\n**ReLU 함수**(Rectified Linear Unit funcion)는 시그모이드를 넘어 최근에 많이 사용되는 함수 입니다. 입력값을 0을 넘으면 그 입력값을 그대로 출력하고 그 이하이면 0을 출력하는 함수로 그 식은 아래와 같습니다.\n\n$$\n\\begin{align}\nh(x) =\n\\begin{cases}\nx & (x > 0) \\\\\n0 & (x \\leq 0)\n\\end{cases}\n\\end{align}\n$$\n\nReLU 함수를 `python` 코드로 아래와 같이 간다하게 구현할 수 있습니다. 이를 활용하여 시그모이드 함수를 실행하면 아래와 같은 그래프(@fig-annAct2 )를 볼 수 있습니다.\n\n::: {#2524a157 .cell execution_count=4}\n``` {.python .cell-code}\ndef relu(x):\n  return np.maximum(0, x)\n```\n:::\n\n\n![Plot of ReLU Function](image/annAct2.png){#fig-annAct2}\n\n\n## others\n\n위에 소개한 활성화 함수 외에도 많은 종류의 활성화 함수가 존재합니다. 이에 대하여 자세한 사항은 [Wiki](https://en.wikipedia.org/wiki/Activation_function)페이지를 참고하시기 바랍니다.\n\n학습을 진행하는 과정에서 필요한 내용들을 지속적으로 업데이트 할 예정입니다.\n\n",
    "supporting": [
      "ANN-activation_files"
    ],
    "filters": [],
    "includes": {}
  }
}