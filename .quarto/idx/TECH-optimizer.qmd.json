{"title":"Optimaizer","markdown":{"headingText":"Optimaizer","containsRefs":false,"markdown":"---\n\n지금가지 신경망(ANN)에 대하여 전반적인 내용을 살펴 보았습니다. 이제 학습의 효율 또는 정확성을 높일 수 있는 방법 또는 기법에 대하여 학습하고자 합니다.\n\n먼저 신경망 학습의 목적은 손실함수 값을 최소화하는데 있습니다. 어떠한 값을 최소화 또는 최대화하는 문제는 **최적화**(optimaization)이라 합니다. 다만, 신경망의 경우 벡터로 표현되는 매개변수의 공간이 매우 넓고 복잡하여 간단하게 수식으로 정의하는 것은 매우 어려운 문제입니다.\n\n이러한 복잡한 최적화의 문제는 매개변수를 어떻게 업데이트 할 것인가, 또는 매개변수의 초깃값을 어떻게 설정 할 것인가의 관점에서 접근해볼 수 있습니다.\n\n## Methodologies for updating parameters\n\n신경망의 매개변수 최적화를 위해 우리는 기울기(편미분)를 시용하여 배개변수 값을 지속적으로 갱신하는 **확률적 경사하강법**(SGD)을 사용하였습니다. \n\n우리는 여기서 SGD의 장단점을 살펴보고 매개변수를 업데이트 하는 다른 최적화 기법들에 대하여 살펴 보도록 하겠습니다.\n\n### Stochastic Gradient Descent(SGD)\n\nSGD의 수식은 다음과 같습니다, 여기서 $\\textbf{w}$는 갱신할 가중치이고 $\\frac{\\partial{L}}{\\partial{\\textbf{W}}}$는  $\\textbf{w}$의 손실함수에 대한 기울기 입니다. $\\eta$는 학습률^[학습률의 Step size를 어떻게 정하냐에 따라 Overshotting 또는 trapping의 문제가 발생할 수 있습니다.]로 가중치를 기울기로 업데이트 하는 크기를 의미합니다.\n\n$$\n\\textbf{W} \\leftarrow \\textbf{W} - \\eta\\frac{\\partial{L}}{\\partial{\\textbf{W}}}\n$$\n\n위의 식을 간단한 클래스로 구현하도록 하겠습니다.\n\n``` {python}\n#| echo: True\n#| eval: False\nclass SGD:\n  def __init__(self, lr=0.01):\n    self.lr = lr\n\n  def update(self, params, grads):\n    for kye in params.keys():\n      params[key] -= self.lr * grads[key] # <1>\n\nnetwork = TwolayerNet(...)\noptimizer = SGD() # <2>\n\nfor i in range(10000):\n  ...\n  x_batch, t_batch = get_mini_batch(...)\n  grads = network.gradient(x_batch, t_batch)\n  params = network.params\n  optimizer.update(params, grads) # <2>\n  ...\n```\n\nSGD의 경우 위와 같이 구현이 쉽다는 장점이 있습니다. 다만, 경우에 따라 비효율적일 때가 있기 때문에, 매개변수를 갱신하는 다른 최적화 기법들이 필요한 것입니다.\n\n먼저 $f(x, y) = \\frac{1}{20}x^2+y^2$의 합수를 이용하여 최소값을 구하는 문제를 살펴보겠습니다. 이 함수는 아래의 그림(@fig-tech_Opt1 )과 같이 그릇을 X축의 방향으로 늘인 타원과 같습니다.\n\n![Graphs and contour lines](image/fig-tech_Opt1.png){#fig-tech_Opt1}\n\n등고선을 살펴보면 y축방향으로 가파르나 x축 방향으로는 완만한 거의 `0`에 가깝다는 것을 알 수 있습니다. 이러한 함수에 SGD를 적용하면 지그재그로 움직이는 비효율적인 모습을 보여줍니다. 이를 SGD의 단점 **비등방성**이라 하고 학습의 효율을 하락시키게 되는 것입니다.\n\n![Update path for SGD](image/fig-techOpt2.png){#fig-techOpt2}\n\n이는 기울기의 반대방향으로 매개변수인 가중치를 갱신하는 단순성에서 나오는 문제로 이를 개선해주는 방법으로 Momentum, AdaGrad, Adam 등이 있으며 이를 살펴보도록 하겠습니다.\n\n### Momentum\n\n**모멘텀**은 '운동량'을 뜻하는 단어로 그 수식은 아래와 같습니다. \n\n$$\n\\begin{align}\n\\textbf{v} &\\leftarrow \\alpha\\textbf{v}-\\eta\\frac{\\partial{l}}{\\partial{\\textbf{W}}} \\\\\n\\textbf{W} &\\leftarrow \\textbf{W} + \\textbf{v}\n\\end{align}\n$$\n\nSGD와 가장 큰 차이점은 $\\textbf{v}$(velocity)가 등장하여 기울기 방향으로 힘을 받아 물체가 가속되는 물리법칙을 의미합니다. 또 하나는 $\\alpha\\textbf{v}$항 아무런 힘이 영향을 주지 않을 때 운동량을 약화 시키는(저항에 해당) 역할을 한다는 것입니다.\n\n이러한 모멘텀 클래스를 구현하면 아래와 같습니다.\n\n``` {python}\nclass Momentum:\n  def __init__(self, lr=0.01, momentum=0.9):\n    self.lr = lr\n    self.momentum = momentum\n    self.v = None\n\n  def update(self, params, grads):\n    if self.v is None: # <1>\n      self.v = {}\n      for key in params.items():\n          self.v[key] = np.zeros_like(val)\n    \n    for key in params.keys():\n      self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n      params[key] += self.v[key]\n```\n1. `v` 인스턴스변수는 초기 아무값도 담지 않고, `update()` 호출시 매개변수와 같은 구조의 딕셔너리 변수로 저장\n\n모멘텀을 이용하는 방식을 사용하는 경우 SGD에 비하여 가중치를 갱신하는 경우 지그재그로 움직이는 정도가 줄어 들었음을 확인 할 수 있습니다.\n\n![Update path for Momentum](image/fig-techOpt3.png){#fig-techOpt3}\n\n### AdaGrad\n\n**AdaGrad**는 신경망 학습에서 학습률을 정하는 기술로 그 수식은 아래와 같습니다. \n\n$$\n\\begin{align}\n\\textbf{h} &\\leftarrow \\textbf{h}+\\frac{\\partial{L}}{\\partial{\\textbf{W}}} \\odot \\frac{\\partial{L}}{\\partial{\\textbf{W}}} \\\\\n\\textbf{W} &\\leftarrow \\textbf{W} + \\eta\\frac{1}{\\sqrt{\\textbf{h}}}\\frac{\\partial{L}}{\\partial{\\textbf{W}}}\n\\end{align}\n$$\n\n즉, 초기에는 학습률을 크게 하고 학습이 진행됨에 따라 학습률을 작게 하는 신경망 학습 방법입니다. 이때 학습률을 낮추는 방법은 매개변수 각각에 맞는(적응하는) 학습률을 정하는 방법입니다. \n\n여기서 $\\textbf{h}$가 등장합니다. 이 값은 기울기를 제곱하여 계속 더해주게 됩니다. 그리고 매개변수인 가중치를 갱신할 때 $\\frac{1}{\\sqrt{\\textbf{h}}}$를 곱하여 학습률을 조정해 줍니다. \n\n이는 이전 스텝에서 크게 갱신된 매개변수(가중치)는 이번 스텝에서 낮은 학습률을 적용하여 원소마다 상이한 학습률을 갖도록 한다는 것으로 이해할 수 있습니다.\n\n이러한 AdaGrad 클래스를 구현하면 아래와 같습니다.\n\n``` {python}\nclass AdaGrad:\n  def __init__(self, lr=0.01):\n    self.lr = lr\n    self.h = None\n\n  def update(self, params, grads):\n    if self.h is None:\n      self.h = {}\n      for key, val in params.items():\n        self.h[key] = np.zeros_like(val)\n\n    for key in params.keys():\n      self.h[key] += grads[key] * grads[key]\n      params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n\n```\n\nAdaGrad를 이용한 합습경로를 보면 최솟값을 향해 효율적으로 움직이는 것을 확인할 수 있습니다.\n\n![Update path for AdaGrad](image/fig-techOpt4.png){#fig-techOpt4}\n\n::: {.callout-note}\n## RMSProp(=EWMA)\n-   AdaGrad는 이전의 기울기 값들이 지속적으로 제곱하여 더해가는 방법론입니다. 이로인해 학습을 진행할수록 학습률은 0에 근접하여 갱신이 이루어지지 않을 수 있는 문제를 내포하고 있습니다.\n-   이러한 문제를 개선하고자 고안된 방벙이 **RMSProp**입니다. 이는 과거의 모든 기울기를 균일하게 더하는 것이 아니라 먼 과거의 기울기를 서서히 잊고 새로운 기울기 정보를 크게 반영하는 방법입니다.\n:::\n\n### Adam\n\n**Adam**은 정확하지는 않지만 직관적으로 모멘텀과 AdaGrad를 융합한듯한 방법입니다. 이 두 이점을 조합했다고 단순히 이해할 수 있습니다.^[Adam에 대하여 보다 자세하게 이해하기 위하여는 [Adam](http://arxiv.org/abs/1412.6980v8)논문을 읽어 보시기 바랍니다.]\n\n이러한 Adam 클래스를 구현하면 아래와 같습니다.\n\n``` {python}\nclass Adam:\n    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n        self.lr = lr\n        self.beta1 = beta1\n        self.beta2 = beta2\n        self.iter = 0\n        self.m = None\n        self.v = None\n        \n    def update(self, params, grads):\n        if self.m is None:\n            self.m, self.v = {}, {}\n            for key, val in params.items():\n                self.m[key] = np.zeros_like(val)\n                self.v[key] = np.zeros_like(val)\n        \n        self.iter += 1\n        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         \n        \n        for key in params.keys():\n            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])            \n            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\n```\n\nAdam을 이용한 합습경로를 보면 앞서 설명한 바와 같이 모멘텀 및 AdaGrad가 혼합된 형태로 최솟값을 향해 효율적으로 움직이는 것을 확인할 수 있습니다.\n\n![Update path for Adam](image/fig-techOpt5.png){#fig-techOpt5}\n\n::: {.callout-note}\n## Adam의 하이퍼파라미터\nAdam에는 3개의 하이퍼파라미터를 설정해야 합니다. \n\n-   $\\alpha$: 매개변수 업데이트 정도인 학습률\n-   $\\beta_1$: 1차 모멘텀 계수로 논문에서는 0.9를 기본값으로 설정\n-   $\\beta_2$: 2차 모멘텀 계수로 논문에서는 0.999를 기본값으로 설정\n:::\n\n## Comparing Methodologies for Updating Parameters\n\n우리가 살펴본 4가지의 모델 중 과연 어떠한 모델이 좋을까요? 이런 물음에 대한 답은 아직까지는 없다 입니다. 이는 문제의 성격에 따라 모델별로 잘 푸는 문제가 따로 있기 때문입니다.\n\n이러한 모델의 비교는 성능을 측정하여 우월성을 판단하기 위한 것이 아니라 모델별 성격에 따라 학습의 진도가 어떻게 다른지 이해하기 위함합니다.\n\n먼저 MNIST 데이터 셋을 이용하여 손글씨 인식문제의 학습진도를 비교해 보도록 하겠습니다.\n\n![Training progress by model on the MNIST dataset](image/fig-techOpt6.png){#fig-techOpt6}\n\n위 비교에 사용된 신경망은 각층이 100개의 뉴런으로 구성된 5층 신경망에 ReLU를 활성화 함수로 사용한 결과 입니다. SGD의 학습 진도가 가장느리고 나머지 3가지 모델은 학습 진도가 매우 유사합니다. \n\n이러한 결과는 일반적인 결과이고 나머지 3개의 모델은 학습률 등 하이퍼파라미터의 설정 또는 신경망의 구조에 따라 결과가 달리 나올수 있다는 점만 이해하도록 하겠습니다.","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","html-math-method":"katex","reference-location":"margin","output-file":"TECH-optimizer.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.551","bibliography":["references.bib"],"grid":{"sidebar-width":"300px","body-width":"900px","margin-width":"300px","gutter-width":"1.5rem"},"mermaid":{"theme":"neutral"},"theme":"lumen","fig-cap-location":"bottom","tbl-cap-location":"bottom","citation-location":"margin"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}